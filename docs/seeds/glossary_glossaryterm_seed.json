[
  {
    "model": "glossary.glossaryterm",
    "pk": 1,
    "fields": {
      "term": "Künstliche Intelligenz (AI)",
      "slug": "kunstliche-intelligenz-ai",
      "short_definition": "Kernbegriff: Maschinen, die Aufgaben mit kognitiven Fähigkeiten lösen.",
      "long_definition": "<strong>Künstliche Intelligenz (AI)</strong> umfasst Methoden, die Maschinen befähigen, wahrzunehmen, zu schlussfolgern und zu handeln. <ul><li><strong>Spektrum:</strong> Von fest verdrahteten Regeln bis zu datengetriebenem Lernen.</li><li><strong>Aufgaben:</strong> Klassifizieren, Vorhersagen, Planen, Generieren.</li><li><strong>Grenzen:</strong> Daten- und Modellbias, Erklärbarkeit, Robustheit, Sicherheitsfragen.</li><li><strong>Praxis:</strong> Erfolg hängt von Datenqualität, sauberer Evaluierung und verantwortungsvoller Nutzung ab.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.552670 +00:00",
      "updated_at": "2025-11-01 13:12:03.552677 +00:00",
      "translation_group": "bc941c0f-499a-4fd4-b38a-6b3931d9fc4d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 131,
    "fields": {
      "term": "AI-as-a-Service (AIaaS)",
      "slug": "ai-as-a-service-aiaas",
      "short_definition": "KI-Funktionen als Cloud-Dienst.",
      "long_definition": "<strong>AIaaS</strong> stellt KI-Funktionen über APIs/SDKs bereit. <ul><li><strong>Vorteile:</strong> schnelle Integration, Skalierung, Managed Security, Monitoring.</li><li><strong>Nachteile:</strong> Kosten, Datenabfluss, Lock-in, begrenzte Anpassbarkeit.</li><li><strong>Auswahl:</strong> SLA, Datenschutz, Region, Explainability-Features, Exit-Strategien.</li></ul>",
      "category": "Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.782584 +00:00",
      "updated_at": "2025-11-01 13:12:03.782587 +00:00",
      "translation_group": "46d98c14-0b79-4a77-b329-0ecd33e99eac"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 92,
    "fields": {
      "term": "Alignment",
      "slug": "alignment",
      "short_definition": "Ausrichtung von KI auf menschliche Werte/Ziele.",
      "long_definition": "<strong>Alignment</strong> bezeichnet das Bestreben, sicherzustellen, dass die Ziele und Handlungen von KI-Systemen mit menschlichen Werten und Absichten übereinstimmen. Es ist ein zentrales Forschungsfeld der KI-Sicherheit. <ul><li><strong>Arten:</strong> Technisches Alignment (Verhalten), normatives Alignment (Werte), institutionelles Alignment (Regeln).</li><li><strong>Herausforderung:</strong> Umgang mit Zielabweichungen bei autonomen Systemen.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.708665 +00:00",
      "updated_at": "2025-11-01 13:12:03.708669 +00:00",
      "translation_group": "c66c7a9c-ff71-4cb5-ae0c-aaf09ea25190"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 229,
    "fields": {
      "term": "Anonymization",
      "slug": "anonymization",
      "short_definition": "Removing identifying features from data.",
      "long_definition": "<strong>Anonymization</strong> is the process of modifying data so that individuals can no longer be identified, even with additional information. <ul><li><strong>Goal:</strong> Protect privacy and comply with legal standards.</li><li><strong>Techniques:</strong> Aggregation, masking, noise addition, generalization.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.695218 +00:00",
      "updated_at": "2025-11-01 13:12:03.695221 +00:00",
      "translation_group": "f2ee8213-6936-4ffd-9f80-decc4895d77c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 225,
    "fields": {
      "term": "Model Compression",
      "slug": "model-compression",
      "short_definition": "Reducing model size and complexity.",
      "long_definition": "<strong>Model compression</strong> reduces the size and computational cost of neural networks while preserving accuracy. <ul><li><strong>Techniques:</strong> Pruning, quantization, knowledge distillation.</li><li><strong>Applications:</strong> Mobile AI, embedded systems, edge devices.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.674955 +00:00",
      "updated_at": "2025-11-01 13:12:03.674959 +00:00",
      "translation_group": "8b9fae5a-6b58-40a4-9af0-0770ea694afe"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 243,
    "fields": {
      "term": "API (Application Programming Interface)",
      "slug": "api-application-programming-interface",
      "short_definition": "Interface for communication between software components.",
      "long_definition": "An <strong>API</strong> defines how software components interact. In AI, APIs are used to access models, data services, or analytics tools. <ul><li><strong>Types:</strong> REST, GraphQL, WebSocket.</li><li><strong>Benefit:</strong> Simplifies integration and reusability of AI systems.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.731310 +00:00",
      "updated_at": "2025-11-01 13:12:03.731322 +00:00",
      "translation_group": "4e8711a0-d9da-4a81-b873-d5b36f52cd9f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 144,
    "fields": {
      "term": "Artificial Intelligence (AI)",
      "slug": "artificial-intelligence-ai",
      "short_definition": "Core concept: machines performing tasks that require cognitive abilities.",
      "long_definition": "<strong>Artificial Intelligence (AI)</strong> encompasses methods that enable machines to perceive, reason, and act autonomously. <ul><li><strong>Scope:</strong> From rule-based systems to data-driven learning approaches.</li><li><strong>Tasks:</strong> Classification, prediction, planning, generation.</li><li><strong>Limitations:</strong> Data and model bias, interpretability, robustness, safety.</li><li><strong>In practice:</strong> Success depends on data quality, sound evaluation, and responsible use.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.526346 +00:00",
      "updated_at": "2025-11-01 13:12:03.526771 +00:00",
      "translation_group": "bc941c0f-499a-4fd4-b38a-6b3931d9fc4d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 25,
    "fields": {
      "term": "Attention-Mechanismus",
      "slug": "attention-mechanismus",
      "short_definition": "Gewichtet relevante Teile der Eingabe.",
      "long_definition": "<strong>Attention</strong> berechnet gewichtete Kombinationen von Repräsentationen, um relevante Informationen zu fokussieren. <ul><li><strong>Typen:</strong> Self-, Cross-, Causal-Attention.</li><li><strong>Nutzen:</strong> bessere Kontextverarbeitung, Erklärbarkeit via Aufmerksamkeitskarten (mit Vorsicht).</li><li><strong>Kosten:</strong> quadratische Komplexität bei vollem Self-Attention (Long-Context-Kniffe nötig).</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.572700 +00:00",
      "updated_at": "2025-11-01 13:12:03.572703 +00:00",
      "translation_group": "3b762932-c28f-4e5a-8590-0f2cd24ee98e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 54,
    "fields": {
      "term": "Audioanalyse",
      "slug": "audioanalyse",
      "short_definition": "Erkennung/Extraktion von Mustern in Audiodaten.",
      "long_definition": "<strong>Audioanalyse</strong> umfasst Verfahren zur automatischen Erkennung, Klassifikation und Auswertung akustischer Signale. Sie kann Sprache, Musik, Umweltgeräusche oder Maschinenklänge analysieren. <ul><li><strong>Anwendungen:</strong> Sprachassistenten, Musikempfehlungssysteme, Störgeräuscherkennung.</li><li><strong>Techniken:</strong> Fourier-Transformation, Mel-Spektrogramme, neuronale Netze.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.628903 +00:00",
      "updated_at": "2025-11-01 13:12:03.628908 +00:00",
      "translation_group": "2e07b742-a47c-4ddc-bc29-f911be4ec775"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 112,
    "fields": {
      "term": "Automatisierung",
      "slug": "automatisierung",
      "short_definition": "Verlagerung von Aufgaben von Menschen auf Maschinen.",
      "long_definition": "<strong>Automatisierung</strong> beschreibt das systematische Übertragen wiederkehrender oder komplexer Arbeitsschritte auf Software, Robotik oder KI-Modelle. <ul><li><strong>Arten:</strong> Regelbasiert (If-This-Then-That), statistisch (Vorhersagemodelle), generativ (Assistenz, Entwurf, Code).</li><li><strong>Wertbeitrag:</strong> geringere Durchlaufzeiten, konsistente Qualität, Skalierbarkeit, 24/7-Betrieb.</li><li><strong>Grenzen:</strong> Datenqualität, Fehlerfortpflanzung, Erklärbarkeit, Wartung von Pipelines und Ausnahmeregeln.</li><li><strong>Arbeitswelt:</strong> Aufgaben werden umverteilt (z.B. vom manuellen Abarbeiten zu Überwachung, Steuerung, Kreativarbeit); Qualifizierung und Mitbestimmung sind zentral.</li><li><strong>Compliance & Recht:</strong> Dokumentationspflichten, Datenschutz, Haftung für Fehlentscheidungen, Branchenstandards.</li><li><strong>Best Practices:</strong> Messbare Ziele, schrittweises Einführen (Pilot → Rollout), Monitoring, Human-in-the-Loop und klare Eskalationspfade.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.743415 +00:00",
      "updated_at": "2025-11-01 13:12:03.743418 +00:00",
      "translation_group": "8b245d70-185d-43b4-bec3-98612697bf6a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 202,
    "fields": {
      "term": "Autonomous Driving",
      "slug": "autonomous-driving",
      "short_definition": "Vehicles perceiving their environment and driving autonomously.",
      "long_definition": "<strong>Autonomous driving</strong> refers to vehicles that use sensors, cameras, and AI to perceive their environment and make driving decisions independently. <ul><li><strong>Core components:</strong> Perception, decision-making, motion planning.</li><li><strong>Technologies:</strong> Computer vision, sensor fusion, deep reinforcement learning.</li><li><strong>Goals:</strong> Safety, comfort, reduction of human error.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.656243 +00:00",
      "updated_at": "2025-11-01 13:12:03.656246 +00:00",
      "translation_group": "103fba6c-3a8f-40df-b332-9e3706b2c84e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 142,
    "fields": {
      "term": "Menschliche Kontrolle",
      "slug": "menschliche-kontrolle",
      "short_definition": "Menschen behalten Entscheidungshoheit.",
      "long_definition": "<strong>Human-in-the-Loop</strong> stellt sicher, dass kritische Schritte überprüft, korrigiert oder freigegeben werden. <ul><li><strong>Gestaltung:</strong> Schwellenwerte, Freigabe-Workflows, Undo, Eskalation.</li><li><strong>Einsatz:</strong> Medizin, Recht, Finanzen, Sicherheitskritisches.</li><li><strong>Ziel:</strong> Risiken mindern und Verantwortung klar zuordnen.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.802130 +00:00",
      "updated_at": "2025-11-01 13:12:03.802135 +00:00",
      "translation_group": "32d7f162-2c41-448a-9025-0dff40c0f25b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 143,
    "fields": {
      "term": "Kreative Nutzung",
      "slug": "kreative-nutzung",
      "short_definition": "Ideenfindung, Schreiben, Design mit KI-Unterstützung.",
      "long_definition": "<strong>Kreative Nutzung</strong> beschreibt den Einsatz von KI zur Inspiration und Beschleunigung kreativer Prozesse. <ul><li><strong>Beispiele:</strong> Ideen sammeln, Texte gliedern, Stile variieren, Skizzen generieren.</li><li><strong>Best Practices:</strong> Iteratives Prompting, Referenzen angeben, Urheber-/Lizenzfragen prüfen.</li><li><strong>Hinweis:</strong> KI ist ein Werkzeug – finale Verantwortung und Auswahl bleiben beim Menschen.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.803013 +00:00",
      "updated_at": "2025-11-01 13:12:03.803019 +00:00",
      "translation_group": "26c544b1-ee95-4b28-bb01-bd98a1800d6a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 145,
    "fields": {
      "term": "Machine Learning (ML)",
      "slug": "machine-learning-ml",
      "short_definition": "Algorithms that learn patterns from data instead of being explicitly programmed.",
      "long_definition": "<strong>Machine Learning</strong> optimizes model parameters so that predictions generalize from examples. <ul><li><strong>Main types:</strong> Supervised, unsupervised, and reinforcement learning.</li><li><strong>Workflow:</strong> Data preparation → training → validation → testing/monitoring.</li><li><strong>Risks:</strong> Overfitting, data leakage, distribution shifts (data/concept drift).</li><li><strong>Best practices:</strong> Proper data splits, baselines, reproducible pipelines, and task-appropriate metrics.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.531649 +00:00",
      "updated_at": "2025-11-01 13:12:03.531657 +00:00",
      "translation_group": "bd4ab9b3-595b-40f9-8fae-8d8342fe1abd"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 146,
    "fields": {
      "term": "Deep Learning",
      "slug": "deep-learning",
      "short_definition": "Learning with deep neural networks containing many parameters.",
      "long_definition": "<strong>Deep Learning</strong> uses multiple layers of nonlinear transformations to capture complex patterns in text, images, audio, or multimodal data. <ul><li><strong>Strengths:</strong> High performance with large datasets, automatic feature extraction.</li><li><strong>Weaknesses:</strong> Data- and compute-intensive, hard to interpret, potentially vulnerable.</li><li><strong>Common architectures:</strong> CNNs, RNNs/LSTMs, Transformers.</li><li><strong>Practice:</strong> Transfer learning and fine-tuning reduce cost and data requirements.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.532794 +00:00",
      "updated_at": "2025-11-01 13:12:03.532801 +00:00",
      "translation_group": "0a3addc8-33f4-4a72-8489-c88b53dfb70d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 147,
    "fields": {
      "term": "Neural Network",
      "slug": "neural-network",
      "short_definition": "Connected layers of artificial neurons for pattern recognition.",
      "long_definition": "<strong>Neural networks</strong> consist of weighted connections (neurons) that process inputs and pass signals forward. <ul><li><strong>Building blocks:</strong> Layers (input/hidden/output), activation functions, weights/bias.</li><li><strong>Learning:</strong> Gradient descent minimizes a loss function.</li><li><strong>Variants:</strong> Feedforward, recurrent, convolutional, transformer-based.</li><li><strong>Challenges:</strong> Over/underfitting, hyperparameter tuning, generalization.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.533827 +00:00",
      "updated_at": "2025-11-01 13:12:03.533831 +00:00",
      "translation_group": "619965c5-ee7d-4aae-ba5a-cff906109425"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 148,
    "fields": {
      "term": "Supervised Learning",
      "slug": "supervised-learning",
      "short_definition": "Training with labeled examples (input → target).",
      "long_definition": "<strong>Supervised learning</strong> uses input–target pairs to learn a mapping function. <ul><li><strong>Tasks:</strong> Classification (category), regression (numeric value), ranking.</li><li><strong>Key factors:</strong> Label quality, class balance, appropriate metrics.</li><li><strong>Risks:</strong> Data leakage, overfitting, distribution shifts in deployment.</li><li><strong>Practice:</strong> Cross-validation, regularization, early stopping, data augmentation.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.534720 +00:00",
      "updated_at": "2025-11-01 13:12:03.534724 +00:00",
      "translation_group": "984ad7dd-16a7-42da-a282-ffca3c9094f1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 149,
    "fields": {
      "term": "Unsupervised Learning",
      "slug": "unsupervised-learning",
      "short_definition": "Finding structure in unlabeled data (e.g., clustering).",
      "long_definition": "<strong>Unsupervised learning</strong> discovers patterns without predefined labels. <ul><li><strong>Types:</strong> Clustering, dimensionality reduction, density estimation, anomaly detection.</li><li><strong>Applications:</strong> Exploratory analysis, preprocessing, recommender pretraining.</li><li><strong>Risks:</strong> Subjective interpretation, sensitivity to parameters and distance metrics.</li><li><strong>Practice:</strong> Visualization, stability checks, incorporation of domain knowledge.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.535741 +00:00",
      "updated_at": "2025-11-01 13:12:03.535746 +00:00",
      "translation_group": "c53e11f3-d888-4d6d-8168-582ed98de7b6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 150,
    "fields": {
      "term": "Reinforcement Learning (RL)",
      "slug": "reinforcement-learning-rl",
      "short_definition": "Agents learn by receiving rewards in an environment.",
      "long_definition": "<strong>Reinforcement Learning</strong> optimizes an agent’s policy by interacting with an environment and receiving rewards. <ul><li><strong>Core elements:</strong> States, actions, rewards, transition dynamics.</li><li><strong>Methods:</strong> Value-based (Q-learning), policy gradient, actor-critic approaches.</li><li><strong>Challenges:</strong> Exploration vs. exploitation, stability, transfer from simulation.</li><li><strong>Practice:</strong> Reward design, safety constraints, off-policy evaluation.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.536724 +00:00",
      "updated_at": "2025-11-01 13:12:03.536730 +00:00",
      "translation_group": "c89010fc-b4ef-4480-af77-1c23598012d5"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 151,
    "fields": {
      "term": "Training Data",
      "slug": "training-data",
      "short_definition": "Data used for model learning.",
      "long_definition": "<strong>Training data</strong> determine a model’s capabilities and limitations. <ul><li><strong>Quality criteria:</strong> Representativeness, low noise, accurate labels, sufficient coverage.</li><li><strong>Risks:</strong> Bias, duplicates/leakage, inappropriate content.</li><li><strong>Practice:</strong> Curate, deduplicate, balance, and document datasets (data cards).</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.537428 +00:00",
      "updated_at": "2025-11-01 13:12:03.537432 +00:00",
      "translation_group": "338532a5-eecb-492b-bfd1-e1d224817669"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 152,
    "fields": {
      "term": "Validation Data",
      "slug": "validation-data",
      "short_definition": "Data used for model tuning (e.g., hyperparameters).",
      "long_definition": "<strong>Validation data</strong> are used to select models and hyperparameters without touching the final test set. <ul><li><strong>Purpose:</strong> Estimate generalization during development.</li><li><strong>Best practices:</strong> Keep separate from training/test data, ensure same distribution, use meaningful metrics.</li><li><strong>Risk:</strong> <em>Overfitting to validation data</em> through repeated tuning.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.538153 +00:00",
      "updated_at": "2025-11-01 13:12:03.538158 +00:00",
      "translation_group": "2cd8e73e-060c-4284-ab59-0d9c8868d291"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 153,
    "fields": {
      "term": "Test Data",
      "slug": "test-data",
      "short_definition": "Untouched data for objective performance evaluation.",
      "long_definition": "<strong>Test data</strong> are used only at the end to measure true generalization. <ul><li><strong>Requirements:</strong> Clean holdout, representative of deployment, no data leakage.</li><li><strong>Metrics:</strong> Task-appropriate (e.g., F1 instead of accuracy for imbalanced data).</li><li><strong>Practice:</strong> Report with confidence intervals, error analysis, and limitation notes.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.539042 +00:00",
      "updated_at": "2025-11-01 13:12:03.539046 +00:00",
      "translation_group": "4c44eaed-60e5-4c3f-8006-45034b5d49ae"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 154,
    "fields": {
      "term": "Model",
      "slug": "model",
      "short_definition": "Parameterized function mapping inputs to outputs.",
      "long_definition": "A <strong>model</strong> is a parameterized function f(x; θ) whose parameters θ are learned from data. <ul><li><strong>Types:</strong> Linear models, decision trees, neural networks, probabilistic models.</li><li><strong>Training:</strong> Minimizing a loss function via optimization.</li><li><strong>Evaluation:</strong> Appropriate metrics, robustness and fairness checks.</li><li><strong>Lifecycle:</strong> Versioning, monitoring, retraining after drift.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.539748 +00:00",
      "updated_at": "2025-11-01 13:12:03.539752 +00:00",
      "translation_group": "88881b68-3eb3-42a9-b2c5-cc1e604c44dc"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 155,
    "fields": {
      "term": "Feature",
      "slug": "feature",
      "short_definition": "Measurable input attribute used by a model.",
      "long_definition": "<strong>Features</strong> are transformed inputs that make relevant structure visible to a model. <ul><li><strong>Types:</strong> Numerical, categorical, text/image representations, embeddings.</li><li><strong>Engineering:</strong> Scaling, encoding, interactions, domain expertise.</li><li><strong>Risks:</strong> Leakage (e.g., time features), correlation vs. causation.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.540352 +00:00",
      "updated_at": "2025-11-01 13:12:03.540355 +00:00",
      "translation_group": "9d8dcfb2-a63b-4edf-a020-1cf3cba1b233"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 156,
    "fields": {
      "term": "Label (Target Value)",
      "slug": "label-target-value",
      "short_definition": "Expected output in supervised learning.",
      "long_definition": "<strong>Labels</strong> are the target values a model learns to predict. <ul><li><strong>Properties:</strong> Accuracy, consistency, annotation quality.</li><li><strong>Variants:</strong> Weak labels, multiple labels, noisy labels.</li><li><strong>Practice:</strong> Clear annotation guidelines, label audits, quality metrics.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.541073 +00:00",
      "updated_at": "2025-11-01 13:12:03.541077 +00:00",
      "translation_group": "588235b5-ce47-4dbe-b2b8-126ce39856cb"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 157,
    "fields": {
      "term": "Overfitting",
      "slug": "overfitting",
      "short_definition": "Model memorizes noise; performance drops on new data.",
      "long_definition": "<strong>Overfitting</strong> occurs when a model learns random patterns in the training data instead of general ones. <ul><li><strong>Symptoms:</strong> Large gap between training and test performance.</li><li><strong>Mitigation:</strong> Regularization, data augmentation, early stopping, more data.</li><li><strong>Diagnostics:</strong> Learning curves, error analysis, ablation studies.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.541841 +00:00",
      "updated_at": "2025-11-01 13:12:03.541845 +00:00",
      "translation_group": "25a832df-e14b-4741-b15c-d774c349d6da"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 158,
    "fields": {
      "term": "Underfitting",
      "slug": "underfitting",
      "short_definition": "Model is too simple to capture patterns.",
      "long_definition": "<strong>Underfitting</strong> occurs when a model lacks the capacity or proper features to capture underlying patterns. <ul><li><strong>Symptoms:</strong> Poor performance on both training and test data.</li><li><strong>Solutions:</strong> More complex models, better features, longer training, hyperparameter tuning.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.542502 +00:00",
      "updated_at": "2025-11-01 13:12:03.542505 +00:00",
      "translation_group": "30e2f9cd-3e34-4456-a4f0-e4c6a4c78681"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 159,
    "fields": {
      "term": "Bias",
      "slug": "bias",
      "short_definition": "Systematic deviation in data or model behavior.",
      "long_definition": "<strong>Bias</strong> refers to systematic errors that lead to unfair or inaccurate results. <ul><li><strong>Sources:</strong> Unbalanced data, sampling artifacts, faulty labels, model assumptions.</li><li><strong>Consequences:</strong> Group disadvantages, poor generalization.</li><li><strong>Mitigation:</strong> Data audits, fairness metrics, rebalancing, explainable models.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.543379 +00:00",
      "updated_at": "2025-11-01 13:12:03.543384 +00:00",
      "translation_group": "e3209f05-d2dc-44d2-a5b0-7c58da4e0db3"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 160,
    "fields": {
      "term": "Fairness in AI",
      "slug": "fairness-in-ai",
      "short_definition": "Principle that models should not discriminate against groups.",
      "long_definition": "<strong>Fairness</strong> aims to minimize unjustified differences in model predictions or decisions. <ul><li><strong>Perspectives:</strong> Individual vs. group fairness.</li><li><strong>Metrics:</strong> Demographic parity, equalized odds, predictive parity.</li><li><strong>Practice:</strong> Make trade-offs transparent, include affected stakeholders, monitor continuously.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.544450 +00:00",
      "updated_at": "2025-11-01 13:12:03.544455 +00:00",
      "translation_group": "9440b28d-0f34-4e83-aef6-14ce4e964670"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 161,
    "fields": {
      "term": "Interpretability / Explainability (XAI)",
      "slug": "interpretability-explainability-xai",
      "short_definition": "Understanding how and why a model makes decisions.",
      "long_definition": "<strong>Explainable AI (XAI)</strong> makes model behavior understandable to humans. <ul><li><strong>Approaches:</strong> Intrinsically interpretable models (e.g., trees) and post-hoc methods (SHAP, LIME, Grad-CAM).</li><li><strong>Goals:</strong> Trust, debugging, compliance, safety.</li><li><strong>Limitations:</strong> Approximations can mislead; explanations must fit the target audience.</li></ul>",
      "category": "Fundamentals",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.545350 +00:00",
      "updated_at": "2025-11-01 13:12:03.545354 +00:00",
      "translation_group": "bb74e31c-9014-4df8-a887-b45fdd1243eb"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 162,
    "fields": {
      "term": "Perceptron",
      "slug": "perceptron",
      "short_definition": "The simplest neural network with a linear decision boundary.",
      "long_definition": "The <strong>Perceptron</strong> is a single artificial neuron that computes a weighted sum and classifies via a threshold function. <ul><li><strong>Characteristics:</strong> Can only solve linearly separable problems.</li><li><strong>Training:</strong> Perceptron learning rule; converges if data are linearly separable.</li><li><strong>Significance:</strong> Historical foundation for modern neural networks.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.582122 +00:00",
      "updated_at": "2025-11-01 13:12:03.582128 +00:00",
      "translation_group": "246a04e3-431f-49e6-a03a-06855b583f86"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 163,
    "fields": {
      "term": "Feedforward Network",
      "slug": "feedforward-network",
      "short_definition": "Layers without feedback; data flow only forward.",
      "long_definition": "<strong>Feedforward networks</strong> (multilayer perceptrons) transmit information from input to output without feedback loops. <ul><li><strong>Components:</strong> Linear projections and nonlinear activations.</li><li><strong>Applications:</strong> Classification, regression, tabular data.</li><li><strong>Design aspects:</strong> Depth vs. width, regularization, initialization.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.582946 +00:00",
      "updated_at": "2025-11-01 13:12:03.582950 +00:00",
      "translation_group": "c5bfe396-9855-43e2-b8c2-6c685297c2a6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 164,
    "fields": {
      "term": "Convolutional Neural Network (CNN)",
      "slug": "convolutional-neural-network-cnn",
      "short_definition": "Architecture for images and signals using convolution layers.",
      "long_definition": "<strong>CNNs</strong> use convolutions and pooling operations to detect local patterns efficiently. <ul><li><strong>Strengths:</strong> Translation invariance, parameter sharing.</li><li><strong>Applications:</strong> Image and video analysis, detection, segmentation.</li><li><strong>Design choices:</strong> Kernel size, depth, residual connections.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.584073 +00:00",
      "updated_at": "2025-11-01 13:12:03.584077 +00:00",
      "translation_group": "5099526d-d3f2-4010-a4b6-c6e9a5e81b7c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 165,
    "fields": {
      "term": "Recurrent Neural Network (RNN)",
      "slug": "recurrent-neural-network-rnn",
      "short_definition": "Sequence models with recurrent connections.",
      "long_definition": "<strong>RNNs</strong> process sequences step by step, sharing internal states across time steps. <ul><li><strong>Variants:</strong> LSTM, GRU—mitigating vanishing/exploding gradients.</li><li><strong>Applications:</strong> Time series, speech, basic dialogue systems.</li><li><strong>Limitations:</strong> Long dependencies, serial computation, latency.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.584766 +00:00",
      "updated_at": "2025-11-01 13:12:03.584770 +00:00",
      "translation_group": "cceada42-e7a8-4d6f-a4b3-3d2d9a8ef81f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 166,
    "fields": {
      "term": "Long Short-Term Memory (LSTM)",
      "slug": "long-short-term-memory-lstm",
      "short_definition": "RNN variant with gating to prevent forgetting.",
      "long_definition": "<strong>LSTMs</strong> use input, output, and forget gates to retain information over long sequences. <ul><li><strong>Advantages:</strong> More stable gradients than vanilla RNNs.</li><li><strong>Applications:</strong> Speech, music, time series forecasting.</li><li><strong>Trade-offs:</strong> Higher computational cost than GRUs.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.585400 +00:00",
      "updated_at": "2025-11-01 13:12:03.585404 +00:00",
      "translation_group": "f51cdcaa-342f-4bf1-a637-5ae261d01fe2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 167,
    "fields": {
      "term": "Transformer",
      "slug": "transformer",
      "short_definition": "Sequence model using attention instead of recurrence or convolution.",
      "long_definition": "The <strong>Transformer</strong> relies on self-attention to capture long-range dependencies efficiently. <ul><li><strong>Advantages:</strong> Parallel processing, scalability, state-of-the-art performance in NLP and multimodal tasks.</li><li><strong>Components:</strong> Multi-head attention, positional embeddings, feedforward blocks, residuals, normalization.</li><li><strong>Considerations:</strong> Context window, compute requirements, optimization/memory tricks.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.586124 +00:00",
      "updated_at": "2025-11-01 13:12:03.586150 +00:00",
      "translation_group": "108e42b6-b6e5-4dcc-93b4-067fa4749137"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 168,
    "fields": {
      "term": "Attention Mechanism",
      "slug": "attention-mechanism",
      "short_definition": "Weights relevant parts of the input dynamically.",
      "long_definition": "<strong>Attention</strong> computes weighted combinations of representations to focus on important information. <ul><li><strong>Types:</strong> Self-, cross-, and causal attention.</li><li><strong>Benefits:</strong> Better context handling and potential interpretability (attention maps).</li><li><strong>Costs:</strong> Quadratic complexity in full self-attention; long-context optimizations are needed.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.586910 +00:00",
      "updated_at": "2025-11-01 13:12:03.586915 +00:00",
      "translation_group": "3b762932-c28f-4e5a-8590-0f2cd24ee98e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 169,
    "fields": {
      "term": "Autoencoder",
      "slug": "autoencoder",
      "short_definition": "Unsupervised model for compression and reconstruction.",
      "long_definition": "<strong>Autoencoders</strong> learn a latent representation by reconstructing their input data. <ul><li><strong>Applications:</strong> Dimensionality reduction, denoising, pretraining.</li><li><strong>Variants:</strong> Convolutional, denoising, sparse, variational (VAE).</li><li><strong>Considerations:</strong> Latent space quality, reconstruction loss, overfitting.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.587477 +00:00",
      "updated_at": "2025-11-01 13:12:03.587480 +00:00",
      "translation_group": "0ed43038-c392-4d1e-a721-1be2a7b0e233"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 170,
    "fields": {
      "term": "Variational Autoencoder (VAE)",
      "slug": "variational-autoencoder-vae",
      "short_definition": "Probabilistic autoencoder for generative modeling.",
      "long_definition": "<strong>VAEs</strong> model a probability distribution in latent space, allowing new samples to be drawn. <ul><li><strong>Core idea:</strong> Evidence Lower Bound (ELBO) combining reconstruction and KL divergence terms.</li><li><strong>Strengths:</strong> Smooth latent space, probabilistic interpretation.</li><li><strong>Weaknesses:</strong> May produce blurrier samples than GANs.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.588064 +00:00",
      "updated_at": "2025-11-01 13:12:03.588067 +00:00",
      "translation_group": "a2048835-459d-40fc-9edf-686e5e689f26"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 171,
    "fields": {
      "term": "Generative Adversarial Network (GAN)",
      "slug": "generative-adversarial-network-gan",
      "short_definition": "Generator and discriminator in adversarial training.",
      "long_definition": "<strong>GANs</strong> train two networks in competition: a generator that produces data and a discriminator that distinguishes real from fake. <ul><li><strong>Strengths:</strong> Capable of producing extremely realistic images or signals.</li><li><strong>Challenges:</strong> Training instability, mode collapse, sensitivity to hyperparameters.</li><li><strong>Variants:</strong> DCGAN, WGAN, StyleGAN, CycleGAN.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.588760 +00:00",
      "updated_at": "2025-11-01 13:12:03.588765 +00:00",
      "translation_group": "4a23e2b2-d9eb-4b79-9ff8-539aeee25fbc"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 172,
    "fields": {
      "term": "Large Language Model (LLM)",
      "slug": "large-language-model-llm",
      "short_definition": "Very large language model with billions of parameters.",
      "long_definition": "<strong>Large Language Models (LLMs)</strong> are transformer-based models trained to predict the next token, enabling text understanding and generation. <ul><li><strong>Capabilities:</strong> Summarization, translation, planning, coding assistance.</li><li><strong>Limitations:</strong> Hallucinations, context window limits, outdated knowledge, security risks.</li><li><strong>Extensions:</strong> Tool use, retrieval-augmented generation (RAG), agents, fine-tuning/adapters.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.589583 +00:00",
      "updated_at": "2025-11-01 13:12:03.589588 +00:00",
      "translation_group": "e7b01f8d-2a45-4a2e-81a9-cb1aa988786b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 173,
    "fields": {
      "term": "Multimodal Model",
      "slug": "multimodal-model",
      "short_definition": "Processes multiple data types such as text, images, and audio.",
      "long_definition": "<strong>Multimodal models</strong> combine representations from different data modalities. <ul><li><strong>Architectures:</strong> Early/late fusion, cross-attention, shared embedding spaces.</li><li><strong>Applications:</strong> Image captioning, visual question answering, audio-video analysis.</li><li><strong>Challenges:</strong> Modality alignment, annotation quality, compute cost.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.590150 +00:00",
      "updated_at": "2025-11-01 13:12:03.590153 +00:00",
      "translation_group": "d2858b7e-c66e-492c-93e4-e1c1175a7c73"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 174,
    "fields": {
      "term": "Embedding",
      "slug": "embedding",
      "short_definition": "Numerical vector representation of tokens or objects.",
      "long_definition": "<strong>Embeddings</strong> map words, sentences, images, or items into dense vector spaces where semantically similar entities are close. <ul><li><strong>Uses:</strong> Search/retrieval, clustering, recommendation systems, model features.</li><li><strong>Training:</strong> Self-supervised (e.g., contrastive learning) or labeled.</li><li><strong>Practice:</strong> Dimension selection, distance metric, normalization, drift monitoring.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.590649 +00:00",
      "updated_at": "2025-11-01 13:12:03.590652 +00:00",
      "translation_group": "6f172f9e-da4a-4a17-9ecd-25ae924f58c7"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 175,
    "fields": {
      "term": "Tokenization",
      "slug": "tokenization",
      "short_definition": "Splitting text into tokens (processing units).",
      "long_definition": "<strong>Tokenization</strong> divides text into units (e.g., subwords) that a model can process. <ul><li><strong>Methods:</strong> BPE, WordPiece, Unigram; language- and domain-specific variants.</li><li><strong>Impact:</strong> Affects context length, OOV handling, and efficiency.</li><li><strong>Practice:</strong> Consistent preprocessing pipelines and vocabulary versioning.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.591145 +00:00",
      "updated_at": "2025-11-01 13:12:03.591148 +00:00",
      "translation_group": "b3fb4d9f-207f-4aa6-9b48-7e910d02f655"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 176,
    "fields": {
      "term": "Context Window",
      "slug": "context-window",
      "short_definition": "Maximum number of tokens a model can process at once.",
      "long_definition": "The <strong>context window</strong> defines how many tokens from the input or conversation history a model can attend to. <ul><li><strong>Effects:</strong> Determines memory span and output quality in long tasks.</li><li><strong>Trade-offs:</strong> Memory/compute vs. range; long-context methods include sliding windows and sparse attention.</li><li><strong>Practice:</strong> Chunking, retrieval (RAG), summarization, structured prompts.</li></ul>",
      "category": "Models & Architectures",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.591611 +00:00",
      "updated_at": "2025-11-01 13:12:03.591614 +00:00",
      "translation_group": "e0e7ec3f-6bb9-4e9b-bf90-8c765d334138"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 177,
    "fields": {
      "term": "Natural Language Processing (NLP)",
      "slug": "natural-language-processing-nlp",
      "short_definition": "Processing and analyzing human language with computers.",
      "long_definition": "<strong>Natural Language Processing (NLP)</strong> covers methods that allow computers to understand, analyze, and generate human language. It combines linguistics, statistics, and machine learning. <ul><li><strong>Tasks:</strong> Text classification, translation, summarization, question answering.</li><li><strong>Techniques:</strong> Tokenization, embeddings, transformer models.</li><li><strong>Goal:</strong> Enable machines to interpret and generate natural language meaningfully.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.595308 +00:00",
      "updated_at": "2025-11-01 13:12:03.595314 +00:00",
      "translation_group": "84e694a5-8bd1-4d5d-be8f-bf8e8cbbd46d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 178,
    "fields": {
      "term": "Natural Language Understanding (NLU)",
      "slug": "natural-language-understanding-nlu",
      "short_definition": "Semantic understanding of meaning and intent.",
      "long_definition": "<strong>Natural Language Understanding (NLU)</strong> focuses on identifying meaning, intent, and relationships in text. <ul><li><strong>Examples:</strong> Intent detection in chatbots, entity extraction.</li><li><strong>Methods:</strong> Syntax analysis, semantic modeling, intent classification.</li><li><strong>Goal:</strong> Teach machines to comprehend human language contextually.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.596141 +00:00",
      "updated_at": "2025-11-01 13:12:03.596145 +00:00",
      "translation_group": "107bf345-e240-4276-939c-86bfade61013"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 179,
    "fields": {
      "term": "Natural Language Generation (NLG)",
      "slug": "natural-language-generation-nlg",
      "short_definition": "Automatic creation of coherent text.",
      "long_definition": "<strong>Natural Language Generation (NLG)</strong> refers to generating fluent, meaningful text from data or prompts. <ul><li><strong>Applications:</strong> Report generation, chatbots, summarization.</li><li><strong>Models:</strong> Sequence-to-sequence architectures, transformers.</li><li><strong>Challenges:</strong> Coherence, factual accuracy, stylistic control.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.596792 +00:00",
      "updated_at": "2025-11-01 13:12:03.596796 +00:00",
      "translation_group": "c341f4b5-383a-475f-a35b-a80a3bc10c50"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 180,
    "fields": {
      "term": "Named Entity Recognition (NER)",
      "slug": "named-entity-recognition-ner",
      "short_definition": "Identification of named entities (person, place, organization).",
      "long_definition": "<strong>Named Entity Recognition (NER)</strong> identifies and classifies proper names in text, such as people, locations, and companies. <ul><li><strong>Use:</strong> Structuring unstructured text for search and analytics.</li><li><strong>Methods:</strong> Sequence labeling, CRFs, BiLSTM-CRF, transformer-based models.</li><li><strong>Examples:</strong> Extracting company names from news articles.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.597565 +00:00",
      "updated_at": "2025-11-01 13:12:03.597571 +00:00",
      "translation_group": "ebd0eb03-6cb6-4ba6-b0f7-b492b81ca9b7"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 181,
    "fields": {
      "term": "Sentiment Analysis",
      "slug": "sentiment-analysis",
      "short_definition": "Evaluation of sentiment and opinion in text.",
      "long_definition": "<strong>Sentiment analysis</strong> determines whether a text expresses a positive, negative, or neutral attitude. <ul><li><strong>Applications:</strong> Product reviews, social media, market research.</li><li><strong>Techniques:</strong> Lexicon-based, machine learning, transformer models.</li><li><strong>Challenges:</strong> Irony, context dependence, ambiguity.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.598561 +00:00",
      "updated_at": "2025-11-01 13:12:03.598567 +00:00",
      "translation_group": "6f76be82-6fc4-4112-b2a3-688a83d68250"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 182,
    "fields": {
      "term": "Retrieval-Augmented Generation (RAG)",
      "slug": "retrieval-augmented-generation-rag",
      "short_definition": "Combines information retrieval with text generation.",
      "long_definition": "<strong>Retrieval-Augmented Generation (RAG)</strong> links a retrieval system with a language model to produce fact-based text. <ul><li><strong>Workflow:</strong> Retrieve relevant documents → insert into prompt → generate response.</li><li><strong>Advantages:</strong> Improved factuality and up-to-date knowledge.</li><li><strong>Examples:</strong> Knowledge-grounded chatbots, Q&A systems.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.599592 +00:00",
      "updated_at": "2025-11-01 13:12:03.599600 +00:00",
      "translation_group": "1574457d-e258-4b9a-95e0-bf70f2cc2b46"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 183,
    "fields": {
      "term": "Prompt Engineering",
      "slug": "prompt-engineering",
      "short_definition": "Designing effective inputs for language models.",
      "long_definition": "<strong>Prompt engineering</strong> is the practice of crafting model inputs to achieve specific, accurate, and consistent outputs. <ul><li><strong>Techniques:</strong> Zero-shot, few-shot, chain-of-thought, role prompts.</li><li><strong>Goal:</strong> Control output quality, tone, and structure.</li><li><strong>Practice:</strong> Iterative testing and structured prompt templates.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.600526 +00:00",
      "updated_at": "2025-11-01 13:12:03.600530 +00:00",
      "translation_group": "559a8454-25d0-48f4-8fe8-c558a4ec82d6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 184,
    "fields": {
      "term": "Few-Shot Learning",
      "slug": "few-shot-learning",
      "short_definition": "Learning from only a few examples.",
      "long_definition": "<strong>Few-shot learning</strong> enables a model to solve new tasks with just a few examples. The model leverages its prior knowledge and generalization capabilities. <ul><li><strong>Examples:</strong> Classifying new categories, translating with limited examples.</li><li><strong>Methods:</strong> In-context learning, fine-tuning, meta-learning.</li><li><strong>Benefit:</strong> Efficient adaptation to small datasets.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.601097 +00:00",
      "updated_at": "2025-11-01 13:12:03.601100 +00:00",
      "translation_group": "fe5aba40-569f-4bb9-a4f4-d95ed8c287e4"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 185,
    "fields": {
      "term": "Zero-Shot Learning",
      "slug": "zero-shot-learning",
      "short_definition": "Solving new tasks without examples.",
      "long_definition": "<strong>Zero-shot learning</strong> allows a model to perform unseen tasks using only instructions and general world knowledge. <ul><li><strong>Example:</strong> Answering domain-specific questions without prior training data.</li><li><strong>Advantages:</strong> Flexibility, no data collection required.</li><li><strong>Challenges:</strong> Errors from ambiguous prompts or unknown concepts.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.601742 +00:00",
      "updated_at": "2025-11-01 13:12:03.601746 +00:00",
      "translation_group": "dc162a59-a9b6-4d99-a836-af5c4f76c50b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 186,
    "fields": {
      "term": "Token (NLP)",
      "slug": "token-nlp",
      "short_definition": "Smallest processing unit for language models.",
      "long_definition": "A <strong>token</strong> is the smallest unit of text a model processes, often a word piece or symbol. <ul><li><strong>Types:</strong> Words, subwords, punctuation marks.</li><li><strong>Impact:</strong> Tokenization affects context length and model efficiency.</li><li><strong>Example:</strong> 'ChatGPT' may be split into 'Chat' and 'GPT'.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.602977 +00:00",
      "updated_at": "2025-11-01 13:12:03.602983 +00:00",
      "translation_group": "512febcf-8b8d-47c8-8d73-d8ff92f6703a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 187,
    "fields": {
      "term": "Temperature (Sampling)",
      "slug": "temperature-sampling",
      "short_definition": "Controls the randomness of generated text.",
      "long_definition": "<strong>Temperature</strong> is a parameter that adjusts how deterministic or creative a model’s output is. <ul><li><strong>Effect:</strong> High values → more diverse outputs; low values → focused and predictable responses.</li><li><strong>Applications:</strong> Text generation, storytelling, dialogue systems.</li><li><strong>Tip:</strong> Common range is 0.2–0.9 depending on use case.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.603692 +00:00",
      "updated_at": "2025-11-01 13:12:03.603696 +00:00",
      "translation_group": "0ec50b58-e38e-4fdf-ba83-1553a33e094c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 188,
    "fields": {
      "term": "System Prompt",
      "slug": "system-prompt",
      "short_definition": "Initial instruction defining model behavior and tone.",
      "long_definition": "A <strong>system prompt</strong> is the base instruction that defines how a language model should behave, including tone, constraints, and perspective. <ul><li><strong>Examples:</strong> “You are a helpful assistant.” or “Respond only with facts.”</li><li><strong>Purpose:</strong> Ensure consistent responses and persona alignment.</li><li><strong>Usage:</strong> Common in APIs and chatbot configurations.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.604502 +00:00",
      "updated_at": "2025-11-01 13:12:03.604506 +00:00",
      "translation_group": "cc8aac38-de57-4068-841d-1322c66965ec"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 189,
    "fields": {
      "term": "Hallucination",
      "slug": "hallucination",
      "short_definition": "Plausible but incorrect or fabricated model output.",
      "long_definition": "<strong>Hallucination</strong> refers to the tendency of a model to produce false or fabricated information that sounds convincing. <ul><li><strong>Causes:</strong> Lack of context, outdated knowledge, probabilistic text generation.</li><li><strong>Risks:</strong> Misinformation, loss of trust, ethical and legal issues.</li><li><strong>Mitigation:</strong> Retrieval grounding, source citation, and fact-checking layers.</li></ul>",
      "category": "NLP & Language Models",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.605246 +00:00",
      "updated_at": "2025-11-01 13:12:03.605253 +00:00",
      "translation_group": "5b620e5f-3ff7-41ca-af55-98b7eff26b67"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 190,
    "fields": {
      "term": "Computer Vision",
      "slug": "computer-vision",
      "short_definition": "Automated image and video analysis by computers.",
      "long_definition": "<strong>Computer Vision</strong> is a field of artificial intelligence that enables computers to interpret and analyze digital images and videos. Systems detect, classify, and understand visual content. <ul><li><strong>Applications:</strong> Face recognition, traffic analysis, quality inspection, medical imaging.</li><li><strong>Goal:</strong> Replicate or augment human visual perception.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.633813 +00:00",
      "updated_at": "2025-11-01 13:12:03.633819 +00:00",
      "translation_group": "e60ae44b-9719-403e-89e1-c1592161fd27"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 191,
    "fields": {
      "term": "Image Classification",
      "slug": "image-classification",
      "short_definition": "Assigning one or more labels to an image.",
      "long_definition": "<strong>Image classification</strong> refers to assigning a category label to an image, such as 'cat' or 'car'. Convolutional Neural Networks (CNNs) are often used to detect visual patterns. <ul><li><strong>Examples:</strong> Medical diagnosis, product categorization, wildlife monitoring.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.634750 +00:00",
      "updated_at": "2025-11-01 13:12:03.634755 +00:00",
      "translation_group": "2616ba98-9e3f-4125-8c3f-519044834f2d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 192,
    "fields": {
      "term": "Object Detection",
      "slug": "object-detection",
      "short_definition": "Locating and classifying objects within an image.",
      "long_definition": "<strong>Object detection</strong> extends image classification by identifying object positions within an image, typically using bounding boxes. <ul><li><strong>Examples:</strong> Pedestrian detection in autonomous vehicles, product counting, surveillance.</li><li><strong>Models:</strong> YOLO, Faster R-CNN, SSD.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.635456 +00:00",
      "updated_at": "2025-11-01 13:12:03.635460 +00:00",
      "translation_group": "37f179bc-df59-42be-bd70-4647c540779d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 193,
    "fields": {
      "term": "Image Segmentation",
      "slug": "image-segmentation",
      "short_definition": "Pixel-level division of an image into regions or classes.",
      "long_definition": "<strong>Image segmentation</strong> divides an image into meaningful regions, assigning a label to each pixel — for instance, road, building, or person. <ul><li><strong>Types:</strong> Semantic, instance, and panoptic segmentation.</li><li><strong>Use cases:</strong> Medical imaging, robotics, autonomous driving.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.636191 +00:00",
      "updated_at": "2025-11-01 13:12:03.636197 +00:00",
      "translation_group": "01b87818-69ca-4ce6-9acb-9d3cf455995a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 194,
    "fields": {
      "term": "Text-to-Image",
      "slug": "text-to-image",
      "short_definition": "Generating images from text descriptions.",
      "long_definition": "<strong>Text-to-image generation</strong> uses generative models to create new, realistic images from text prompts. Modern systems such as DALL·E, Midjourney, or Stable Diffusion rely on diffusion or transformer architectures. <ul><li><strong>Example:</strong> “A fox wearing sunglasses in the style of Van Gogh.”</li><li><strong>Note:</strong> Prompts require clarity and respect for copyright boundaries.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.636954 +00:00",
      "updated_at": "2025-11-01 13:12:03.636958 +00:00",
      "translation_group": "df66eed3-dc0a-4e15-855d-a6079cc45851"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 195,
    "fields": {
      "term": "Deepfake",
      "slug": "deepfake",
      "short_definition": "AI-generated or manipulated realistic media.",
      "long_definition": "<strong>Deepfakes</strong> are images, videos, or audio clips generated or altered using AI to convincingly imitate real people. They often use deep learning architectures like GANs. <ul><li><strong>Applications:</strong> Film production, entertainment, but also disinformation.</li><li><strong>Risks:</strong> Privacy invasion, misuse, loss of trust in digital media.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.637624 +00:00",
      "updated_at": "2025-11-01 13:12:03.637628 +00:00",
      "translation_group": "08c81bc7-53f7-4c13-b716-8551ac355731"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 196,
    "fields": {
      "term": "Text-to-Video",
      "slug": "text-to-video",
      "short_definition": "Video generation from text prompts.",
      "long_definition": "<strong>Text-to-video</strong> models create short video clips from written descriptions by modeling motion and temporal consistency. <ul><li><strong>Example:</strong> “A bird flying across the sunset over the ocean.”</li><li><strong>Popular models:</strong> Runway Gen-2, Pika Labs, Sora (OpenAI).</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.638219 +00:00",
      "updated_at": "2025-11-01 13:12:03.638222 +00:00",
      "translation_group": "01f9e164-8bdb-48bc-b388-ca10bc0b4dbc"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 197,
    "fields": {
      "term": "Audio Analysis",
      "slug": "audio-analysis",
      "short_definition": "Detecting and extracting patterns in audio data.",
      "long_definition": "<strong>Audio analysis</strong> involves automatically recognizing, classifying, and interpreting acoustic signals such as speech, music, or environmental noise. <ul><li><strong>Applications:</strong> Voice assistants, music recommendations, noise detection.</li><li><strong>Techniques:</strong> Fourier transforms, mel-spectrograms, neural networks.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.639004 +00:00",
      "updated_at": "2025-11-01 13:12:03.639008 +00:00",
      "translation_group": "2e07b742-a47c-4ddc-bc29-f911be4ec775"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 198,
    "fields": {
      "term": "Automatic Speech Recognition (ASR)",
      "slug": "automatic-speech-recognition-asr",
      "short_definition": "Conversion of spoken language into text.",
      "long_definition": "<strong>Automatic Speech Recognition (ASR)</strong> converts spoken audio into text using acoustic and linguistic models. Modern systems use deep learning architectures such as transformers and RNNs. <ul><li><strong>Applications:</strong> Dictation, voice control, meeting transcription.</li><li><strong>Challenges:</strong> Dialects, background noise, multilinguality.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.639675 +00:00",
      "updated_at": "2025-11-01 13:12:03.639680 +00:00",
      "translation_group": "e6f29b7d-2db3-4b01-be0b-514ec09a90b3"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 199,
    "fields": {
      "term": "Music Generation",
      "slug": "music-generation",
      "short_definition": "Creating new music using AI models.",
      "long_definition": "<strong>Music generation</strong> refers to composing melodies, harmonies, or full tracks automatically using AI. These models learn from large music datasets to generate new compositions. <ul><li><strong>Examples:</strong> Background music for games, AI composers like AIVA.</li><li><strong>Concerns:</strong> Copyright and artistic authenticity.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.640418 +00:00",
      "updated_at": "2025-11-01 13:12:03.640423 +00:00",
      "translation_group": "050ee9c3-3f64-4c70-9028-15cdba6ebc2c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 200,
    "fields": {
      "term": "Style Transfer",
      "slug": "style-transfer",
      "short_definition": "Transferring the artistic style of one image to another.",
      "long_definition": "<strong>Style transfer</strong> applies the artistic style of one image (e.g., a Van Gogh painting) to the content of another, producing a stylized new image. <ul><li><strong>Technique:</strong> Neural networks, especially convolutional architectures.</li><li><strong>Applications:</strong> Digital art, design, photography filters.</li></ul>",
      "category": "Image/Audio/Video",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.641099 +00:00",
      "updated_at": "2025-11-01 13:12:03.641103 +00:00",
      "translation_group": "07ab2515-4b84-4cfb-9738-a0f5f3a1565f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 201,
    "fields": {
      "term": "Recommender System",
      "slug": "recommender-system",
      "short_definition": "Personalized suggestions based on user behavior and preferences.",
      "long_definition": "<strong>Recommender systems</strong> analyze user behavior, preferences, and context to suggest relevant items such as movies, products, or content. <ul><li><strong>Methods:</strong> Collaborative filtering, content-based filtering, hybrid models.</li><li><strong>Examples:</strong> Netflix movie suggestions, Amazon product recommendations, Spotify playlists.</li><li><strong>Goal:</strong> Improve user experience and engagement through personalization.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.655375 +00:00",
      "updated_at": "2025-11-01 13:12:03.655382 +00:00",
      "translation_group": "1d748522-5574-451c-b5c1-bee8e9492091"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 203,
    "fields": {
      "term": "Robotics",
      "slug": "robotics",
      "short_definition": "Machines that interact intelligently with their environment.",
      "long_definition": "<strong>Robotics</strong> combines AI, mechanics, and control systems to create machines that can perform tasks autonomously or collaboratively with humans. <ul><li><strong>Applications:</strong> Industrial automation, medical robotics, service robots, logistics.</li><li><strong>AI role:</strong> Perception, decision-making, motion control.</li><li><strong>Trends:</strong> Human-robot collaboration, soft robotics, learning from demonstration.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.656811 +00:00",
      "updated_at": "2025-11-01 13:12:03.656814 +00:00",
      "translation_group": "41ff01fe-b582-4163-b189-2098bc0a2374"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 204,
    "fields": {
      "term": "Medical Diagnostics",
      "slug": "medical-diagnostics",
      "short_definition": "AI-assisted analysis and detection in healthcare.",
      "long_definition": "<strong>Medical diagnostics</strong> with AI assist doctors in detecting diseases, analyzing medical images, and estimating risks. <ul><li><strong>Examples:</strong> Tumor detection in X-rays, ECG analysis, skin lesion classification.</li><li><strong>Benefits:</strong> Faster results, higher accuracy, improved early detection.</li><li><strong>Challenges:</strong> Data privacy, bias, explainability, regulatory approval.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.657301 +00:00",
      "updated_at": "2025-11-01 13:12:03.657304 +00:00",
      "translation_group": "5e62b466-fffd-4fa1-baec-964b2b25b49b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 205,
    "fields": {
      "term": "Fraud Detection",
      "slug": "fraud-detection",
      "short_definition": "Detecting suspicious patterns in transactions using AI.",
      "long_definition": "<strong>Fraud detection</strong> systems use AI to recognize abnormal or fraudulent activities in financial, insurance, or e-commerce transactions. <ul><li><strong>Examples:</strong> Credit card fraud, insurance fraud, identity theft.</li><li><strong>Techniques:</strong> Anomaly detection, clustering, neural networks.</li><li><strong>Goal:</strong> Early detection and prevention of losses.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.657832 +00:00",
      "updated_at": "2025-11-01 13:12:03.657837 +00:00",
      "translation_group": "f7147ed8-0141-460b-be08-efbd7f685867"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 206,
    "fields": {
      "term": "Customer Support Chatbot",
      "slug": "customer-support-chatbot",
      "short_definition": "Automated conversational systems for customer service.",
      "long_definition": "<strong>Customer support chatbots</strong> automatically interact with users to answer common questions or solve problems. They rely on Natural Language Processing (NLP) to understand inputs and generate responses. <ul><li><strong>Examples:</strong> Website support chat, order tracking, FAQ automation.</li><li><strong>Goal:</strong> 24/7 assistance and reduction of manual support load.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.658563 +00:00",
      "updated_at": "2025-11-01 13:12:03.658566 +00:00",
      "translation_group": "08a61441-3302-4bed-9146-fe8b8c96c20f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 207,
    "fields": {
      "term": "Machine Translation",
      "slug": "machine-translation",
      "short_definition": "Automatic translation of text or speech between languages.",
      "long_definition": "<strong>Machine translation</strong> uses AI models to translate written or spoken language automatically. Modern systems use neural networks and transformer models to generate natural and context-aware translations. <ul><li><strong>Examples:</strong> DeepL, Google Translate, real-time interpreters.</li><li><strong>Technologies:</strong> Attention mechanisms, multilingual training, large language models.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.659102 +00:00",
      "updated_at": "2025-11-01 13:12:03.659105 +00:00",
      "translation_group": "5a568750-289e-4917-9306-ad674e3dd875"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 208,
    "fields": {
      "term": "Text and Image Generation",
      "slug": "text-and-image-generation",
      "short_definition": "Creating new content for creative or marketing purposes.",
      "long_definition": "<strong>Text and image generation</strong> refers to AI models that create new content — from text and images to videos and designs. These systems learn from large datasets to generate stylistically consistent outputs. <ul><li><strong>Examples:</strong> Blog posts, social media content, illustrations, ads.</li><li><strong>Models:</strong> GPT, DALL·E, Stable Diffusion.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.659594 +00:00",
      "updated_at": "2025-11-01 13:12:03.659597 +00:00",
      "translation_group": "3733f3b5-846f-494c-8753-2ba50a89f466"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 209,
    "fields": {
      "term": "Code Generation",
      "slug": "code-generation",
      "short_definition": "Automatic creation of programming code from descriptions or examples.",
      "long_definition": "<strong>Code generation</strong> uses AI to write, refactor, or debug code based on natural language instructions or partial functions. <ul><li><strong>Examples:</strong> GitHub Copilot, ChatGPT Code Interpreter, Amazon CodeWhisperer.</li><li><strong>Benefits:</strong> Increases productivity and reduces repetitive work.</li><li><strong>Considerations:</strong> Licensing, code quality, security.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.660716 +00:00",
      "updated_at": "2025-11-01 13:12:03.660722 +00:00",
      "translation_group": "6cde8783-66e5-4c25-bcb4-9d23f52eb7f4"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 210,
    "fields": {
      "term": "Predictive Maintenance",
      "slug": "predictive-maintenance",
      "short_definition": "Predicting equipment failures using sensor data.",
      "long_definition": "<strong>Predictive maintenance</strong> applies AI to monitor machine health and forecast failures before they occur. <ul><li><strong>Examples:</strong> Industrial machinery, wind turbines, vehicle fleets.</li><li><strong>Techniques:</strong> Time-series analysis, anomaly detection, predictive modeling.</li><li><strong>Goal:</strong> Reduce downtime and maintenance costs through data-driven planning.</li></ul>",
      "category": "Applications",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.661521 +00:00",
      "updated_at": "2025-11-01 13:12:03.661526 +00:00",
      "translation_group": "1efa4b5b-3f1d-48a9-bfbb-83caf59bf2cf"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 211,
    "fields": {
      "term": "Data Annotation",
      "slug": "data-annotation",
      "short_definition": "Labeling raw data for training AI models.",
      "long_definition": "<strong>Data annotation</strong> is the process of labeling raw data such as text, images, or audio with meaningful tags so that supervised learning models can be trained effectively. <ul><li><strong>Examples:</strong> Image bounding boxes, text sentiment labels, speech transcriptions.</li><li><strong>Importance:</strong> Annotation quality directly affects model accuracy.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.664963 +00:00",
      "updated_at": "2025-11-01 13:12:03.664969 +00:00",
      "translation_group": "fb01c20d-5154-466f-81d7-50225333917b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 212,
    "fields": {
      "term": "Data Quality",
      "slug": "data-quality",
      "short_definition": "Accuracy, completeness, and relevance of data.",
      "long_definition": "<strong>Data quality</strong> describes how reliable and representative training data are. High-quality data are accurate, consistent, complete, and unbiased. <ul><li><strong>Dimensions:</strong> Accuracy, consistency, timeliness, fairness.</li><li><strong>Impact:</strong> Poor data lead to unreliable or biased models.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.665985 +00:00",
      "updated_at": "2025-11-01 13:12:03.665992 +00:00",
      "translation_group": "3f5d7e6e-f6b2-43a8-88b6-ec1bedec5e0f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 213,
    "fields": {
      "term": "Feature Engineering",
      "slug": "feature-engineering",
      "short_definition": "Transforming raw data into informative model inputs.",
      "long_definition": "<strong>Feature engineering</strong> is the process of selecting, transforming, or combining raw data into meaningful input features that improve model performance. <ul><li><strong>Goal:</strong> Provide models with relevant, interpretable, and discriminative features.</li><li><strong>Examples:</strong> Normalization, one-hot encoding, PCA, derived metrics.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.666869 +00:00",
      "updated_at": "2025-11-01 13:12:03.666874 +00:00",
      "translation_group": "fbe41ed3-0d25-4934-8eb3-eb3b951f4950"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 214,
    "fields": {
      "term": "Batch / Epoch",
      "slug": "batch-epoch",
      "short_definition": "Training subsets and full dataset passes.",
      "long_definition": "A <strong>batch</strong> is a subset of training data processed at once, while an <strong>epoch</strong> refers to one complete pass over the dataset. <ul><li><strong>Purpose:</strong> Reduce memory load and stabilize learning.</li><li><strong>Note:</strong> Multiple epochs are required for convergence.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.667571 +00:00",
      "updated_at": "2025-11-01 13:12:03.667575 +00:00",
      "translation_group": "93ae2564-8b57-468c-88e2-0d70d171df27"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 215,
    "fields": {
      "term": "Loss Function",
      "slug": "loss-function",
      "short_definition": "Measures model error during training.",
      "long_definition": "<strong>Loss functions</strong> quantify how far model predictions deviate from true labels. The training process minimizes this error. <ul><li><strong>Examples:</strong> Mean Squared Error (MSE), Cross-Entropy, Hinge Loss.</li><li><strong>Importance:</strong> The choice of loss influences convergence and final accuracy.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.668494 +00:00",
      "updated_at": "2025-11-01 13:12:03.668500 +00:00",
      "translation_group": "9b192a0b-809d-4170-950d-0d2d07af9fda"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 216,
    "fields": {
      "term": "Optimizer",
      "slug": "optimizer",
      "short_definition": "Algorithm adjusting parameters to minimize loss.",
      "long_definition": "<strong>Optimizers</strong> update model parameters during training to reduce loss based on gradient information. <ul><li><strong>Examples:</strong> SGD, Adam, RMSprop.</li><li><strong>Goal:</strong> Efficient, stable, and fast convergence.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.669253 +00:00",
      "updated_at": "2025-11-01 13:12:03.669258 +00:00",
      "translation_group": "bccbb1f7-3930-4be6-9a70-81062c4a8c12"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 217,
    "fields": {
      "term": "Gradient Descent",
      "slug": "gradient-descent",
      "short_definition": "Iterative method to minimize the loss function.",
      "long_definition": "<strong>Gradient Descent</strong> is an optimization method that adjusts model parameters in the direction of the steepest descent of the loss. <ul><li><strong>Variants:</strong> Batch, Stochastic, Mini-batch.</li><li><strong>Parameters:</strong> Learning rate controls step size and stability.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.670048 +00:00",
      "updated_at": "2025-11-01 13:12:03.670054 +00:00",
      "translation_group": "a7ad9336-5218-42fb-8ee8-8ccc52d2c176"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 218,
    "fields": {
      "term": "Activation Function",
      "slug": "activation-function",
      "short_definition": "Introduces non-linearity into neural networks.",
      "long_definition": "<strong>Activation functions</strong> allow neural networks to model complex, non-linear relationships. Without them, networks would behave like linear models. <ul><li><strong>Examples:</strong> ReLU, Sigmoid, Tanh, Softmax.</li><li><strong>Impact:</strong> Affects training stability and representational power.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.670764 +00:00",
      "updated_at": "2025-11-01 13:12:03.670767 +00:00",
      "translation_group": "ba73794c-6bda-4645-94e4-463f5c794f63"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 219,
    "fields": {
      "term": "Regularization",
      "slug": "regularization",
      "short_definition": "Techniques to prevent overfitting.",
      "long_definition": "<strong>Regularization</strong> comprises methods that reduce overfitting by penalizing model complexity or augmenting training data. <ul><li><strong>Examples:</strong> L1/L2 penalties, dropout, data augmentation.</li><li><strong>Goal:</strong> Achieve balance between accuracy and generalization.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.671357 +00:00",
      "updated_at": "2025-11-01 13:12:03.671360 +00:00",
      "translation_group": "92a5555c-cd7d-4105-bbd5-e4022813cf14"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 220,
    "fields": {
      "term": "Evaluation Metrics",
      "slug": "evaluation-metrics",
      "short_definition": "Measures for assessing model performance.",
      "long_definition": "<strong>Evaluation metrics</strong> quantify model performance using specific criteria. <ul><li><strong>Examples:</strong> Accuracy, Precision, Recall, F1-score, ROC-AUC.</li><li><strong>Use:</strong> Different metrics suit different tasks (classification, regression, clustering).</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.672109 +00:00",
      "updated_at": "2025-11-01 13:12:03.672114 +00:00",
      "translation_group": "34b6135a-ab45-4df3-a473-680dae48bd27"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 221,
    "fields": {
      "term": "Cross-Validation",
      "slug": "cross-validation",
      "short_definition": "Repeated train/test splits for robust estimation.",
      "long_definition": "<strong>Cross-validation</strong> evaluates model performance by repeatedly splitting data into training and test sets. <ul><li><strong>Variants:</strong> k-fold, leave-one-out, stratified CV.</li><li><strong>Benefit:</strong> Produces a more reliable performance estimate.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.672763 +00:00",
      "updated_at": "2025-11-01 13:12:03.672767 +00:00",
      "translation_group": "bee16fca-5bdf-4030-8499-3d6c38349bb1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 222,
    "fields": {
      "term": "Hyperparameter",
      "slug": "hyperparameter",
      "short_definition": "External parameter controlling model training.",
      "long_definition": "<strong>Hyperparameters</strong> are settings that influence how a model learns but are not learned themselves. <ul><li><strong>Examples:</strong> Learning rate, batch size, number of layers, regularization strength.</li><li><strong>Tuning:</strong> Grid search, random search, Bayesian optimization.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.673391 +00:00",
      "updated_at": "2025-11-01 13:12:03.673394 +00:00",
      "translation_group": "f771ee69-ffc7-4144-9c14-752fb5d04232"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 223,
    "fields": {
      "term": "Transfer Learning",
      "slug": "transfer-learning",
      "short_definition": "Reusing knowledge from one task for another.",
      "long_definition": "<strong>Transfer learning</strong> adapts a model pre-trained on a large dataset to a new, related task with less data. <ul><li><strong>Example:</strong> Using a pretrained ResNet for medical image classification.</li><li><strong>Advantage:</strong> Reduces training time and data requirements.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.673926 +00:00",
      "updated_at": "2025-11-01 13:12:03.673929 +00:00",
      "translation_group": "a9fe3918-d725-4662-89dd-006d87a5191b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 224,
    "fields": {
      "term": "Fine-Tuning",
      "slug": "fine-tuning",
      "short_definition": "Further training a pre-trained model on new data.",
      "long_definition": "<strong>Fine-tuning</strong> continues training of a pre-trained model on a smaller, task-specific dataset. <ul><li><strong>Purpose:</strong> Adapt a general model to a specialized domain.</li><li><strong>Example:</strong> Adjusting a language model to legal or medical texts.</li></ul>",
      "category": "Data / Training / Evaluation",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.674428 +00:00",
      "updated_at": "2025-11-01 13:12:03.674431 +00:00",
      "translation_group": "45b2476b-8cca-4eb2-adbf-e8b67ab260af"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 226,
    "fields": {
      "term": "AI Ethics",
      "slug": "ai-ethics",
      "short_definition": "Guidelines for the responsible use and development of AI.",
      "long_definition": "<strong>AI ethics</strong> addresses moral, social, and legal questions surrounding the development and use of artificial intelligence. It ensures that systems are aligned with human values, rights, and accountability principles. <ul><li><strong>Focus areas:</strong> Fairness, transparency, accountability, harm prevention.</li><li><strong>Goal:</strong> Build trustworthy, socially acceptable AI systems.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.692286 +00:00",
      "updated_at": "2025-11-01 13:12:03.692293 +00:00",
      "translation_group": "29d96a66-69c4-4fb6-a285-5dd7274cf29f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 227,
    "fields": {
      "term": "Transparency",
      "slug": "transparency",
      "short_definition": "Making data, models, and decisions understandable and traceable.",
      "long_definition": "<strong>Transparency</strong> means that the inner workings, decisions, and data sources of an AI system can be understood and audited. It is essential for accountability and public trust. <ul><li><strong>Implementation:</strong> Documentation, explainable models, disclosure of limitations.</li><li><strong>Benefit:</strong> Enables auditing, debugging, and responsible deployment.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.693443 +00:00",
      "updated_at": "2025-11-01 13:12:03.693449 +00:00",
      "translation_group": "9ac7e24b-0e49-4611-ae06-3655429317b4"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 228,
    "fields": {
      "term": "Data Protection (GDPR)",
      "slug": "data-protection-gdpr",
      "short_definition": "Protection of personal data under EU law.",
      "long_definition": "<strong>Data protection</strong> under the GDPR safeguards personal data from misuse or unlawful processing. Organizations must ensure legal basis, purpose limitation, data minimization, and user rights. <ul><li><strong>Principles:</strong> Transparency, security, accountability.</li><li><strong>Rights:</strong> Access, deletion, objection, portability.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.694505 +00:00",
      "updated_at": "2025-11-01 13:12:03.694511 +00:00",
      "translation_group": "c495eb9a-afd3-421b-9a1e-fb0fce44a19a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 230,
    "fields": {
      "term": "Consent",
      "slug": "consent",
      "short_definition": "Voluntary and informed approval for data processing.",
      "long_definition": "<strong>Consent</strong> is a key concept in data protection, describing an individual's explicit and informed agreement to process their data. <ul><li><strong>Requirements:</strong> Clear, purpose-bound, and revocable at any time.</li><li><strong>Example:</strong> Agreeing to share voice data for model training.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.695758 +00:00",
      "updated_at": "2025-11-01 13:12:03.695761 +00:00",
      "translation_group": "4c17f853-04ca-4293-b328-e5b8040244f2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 231,
    "fields": {
      "term": "Explainable AI (XAI)",
      "slug": "explainable-ai-xai",
      "short_definition": "Making AI decisions understandable to humans.",
      "long_definition": "<strong>Explainable AI (XAI)</strong> refers to methods that make the inner workings and decisions of complex models transparent and interpretable. <ul><li><strong>Techniques:</strong> SHAP, LIME, feature importance visualization.</li><li><strong>Goal:</strong> Improve trust, accountability, and model reliability.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.696248 +00:00",
      "updated_at": "2025-11-01 13:12:03.696251 +00:00",
      "translation_group": "a8edd1ce-ee34-422e-81ad-8fda41c295c8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 232,
    "fields": {
      "term": "Responsible AI",
      "slug": "responsible-ai",
      "short_definition": "Practices for safe, fair, and robust AI deployment.",
      "long_definition": "<strong>Responsible AI</strong> involves developing and deploying AI systems ethically, safely, and transparently. It combines technical, legal, and organizational safeguards. <ul><li><strong>Principles:</strong> Fairness, safety, governance, continuous monitoring.</li><li><strong>Goal:</strong> Minimize risk and maximize social benefit.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.696814 +00:00",
      "updated_at": "2025-11-01 13:12:03.696818 +00:00",
      "translation_group": "a4c9967f-813d-4b26-ac3e-514cc50e8e82"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 233,
    "fields": {
      "term": "EU AI Act",
      "slug": "eu-ai-act",
      "short_definition": "European regulation defining risk-based AI categories.",
      "long_definition": "The <strong>EU AI Act</strong> is the first comprehensive European law regulating artificial intelligence. It classifies AI systems by risk level and defines obligations for developers and users. <ul><li><strong>Risk levels:</strong> Unacceptable, high, limited, minimal risk.</li><li><strong>Goal:</strong> Ensure safety, transparency, and protection of fundamental rights.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.697399 +00:00",
      "updated_at": "2025-11-01 13:12:03.697402 +00:00",
      "translation_group": "d6408cbf-d030-4df1-9564-63be650b71fa"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 234,
    "fields": {
      "term": "Safety",
      "slug": "safety",
      "short_definition": "Preventing harmful outcomes and system failures.",
      "long_definition": "<strong>Safety</strong> refers to measures that prevent AI systems from causing harm or making dangerous errors. It includes robustness, monitoring, and fallback mechanisms. <ul><li><strong>Aspects:</strong> Fault tolerance, redundancy, adversarial robustness.</li><li><strong>Goal:</strong> Avoid physical, digital, and societal harm.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.697881 +00:00",
      "updated_at": "2025-11-01 13:12:03.697884 +00:00",
      "translation_group": "f6678c3d-04cc-427c-8a27-718f01645898"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 235,
    "fields": {
      "term": "Alignment",
      "slug": "alignment",
      "short_definition": "Ensuring AI systems follow human values and goals.",
      "long_definition": "<strong>Alignment</strong> aims to ensure that the objectives and behavior of AI systems remain consistent with human intentions and ethics. <ul><li><strong>Types:</strong> Technical (behavior), normative (values), institutional (rules).</li><li><strong>Challenge:</strong> Prevent goal drift and unintended actions in autonomous systems.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.698354 +00:00",
      "updated_at": "2025-11-01 13:12:03.698357 +00:00",
      "translation_group": "c66c7a9c-ff71-4cb5-ae0c-aaf09ea25190"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 236,
    "fields": {
      "term": "AI Governance",
      "slug": "ai-governance",
      "short_definition": "Frameworks and processes to control AI systems.",
      "long_definition": "<strong>AI governance</strong> defines organizational and regulatory frameworks for overseeing AI systems across their lifecycle. It ensures responsibility, risk management, and compliance. <ul><li><strong>Elements:</strong> Policies, roles, audits, risk assessments.</li><li><strong>Goal:</strong> Transparent and accountable AI management.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.698811 +00:00",
      "updated_at": "2025-11-01 13:12:03.698814 +00:00",
      "translation_group": "08b87cb4-493f-41db-ae94-6b87904638c8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 237,
    "fields": {
      "term": "Green AI",
      "slug": "green-ai",
      "short_definition": "Environmentally sustainable artificial intelligence.",
      "long_definition": "<strong>Green AI</strong> promotes the development and use of AI systems that minimize energy consumption and environmental impact. <ul><li><strong>Approaches:</strong> Efficient algorithms, hardware optimization, renewable energy.</li><li><strong>Goal:</strong> Balance technological progress with ecological responsibility.</li></ul>",
      "category": "Ethics / Safety / Privacy",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.699278 +00:00",
      "updated_at": "2025-11-01 13:12:03.699281 +00:00",
      "translation_group": "c06c76da-61c3-454e-b824-83f47795d46e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 238,
    "fields": {
      "term": "Python",
      "slug": "python",
      "short_definition": "Primary language for data science and machine learning ecosystems.",
      "long_definition": "<strong>Python</strong> is the most widely used programming language for machine learning, data analysis, and AI development. Its simplicity and large ecosystem enable both rapid prototyping and production-scale solutions. <ul><li><strong>Key libraries:</strong> NumPy, pandas, TensorFlow, PyTorch, scikit-learn.</li><li><strong>Strengths:</strong> Readability, community support, integration with MLOps and cloud tools.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.727509 +00:00",
      "updated_at": "2025-11-01 13:12:03.727516 +00:00",
      "translation_group": "4b853ae9-59f1-400b-8212-5435950c92bd"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 239,
    "fields": {
      "term": "TensorFlow",
      "slug": "tensorflow",
      "short_definition": "Open-source deep learning framework from Google.",
      "long_definition": "<strong>TensorFlow</strong> is a framework for machine learning and deep learning that supports model training, optimization, and deployment on various platforms including mobile and web. <ul><li><strong>Components:</strong> Keras API, TensorBoard, TensorFlow Lite, TensorFlow Serving.</li><li><strong>Applications:</strong> Image recognition, NLP, time-series analysis.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.728399 +00:00",
      "updated_at": "2025-11-01 13:12:03.728404 +00:00",
      "translation_group": "6014c7eb-1dd1-405d-b5eb-cf430860b37e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 240,
    "fields": {
      "term": "PyTorch",
      "slug": "pytorch",
      "short_definition": "Flexible deep learning framework for research and production.",
      "long_definition": "<strong>PyTorch</strong> is a popular open-source deep learning framework developed by Meta, offering dynamic computation graphs for flexible model development. <ul><li><strong>Advantages:</strong> Simplicity, Pythonic syntax, strong integration with Hugging Face and ONNX.</li><li><strong>Use cases:</strong> Computer vision, NLP, reinforcement learning.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.729074 +00:00",
      "updated_at": "2025-11-01 13:12:03.729078 +00:00",
      "translation_group": "cd142fe3-f0e6-43ec-bb8e-66737dc9b0ea"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 241,
    "fields": {
      "term": "Scikit-learn",
      "slug": "scikit-learn",
      "short_definition": "Machine learning library for classical algorithms.",
      "long_definition": "<strong>scikit-learn</strong> is a Python library offering tools for data preprocessing, classical machine learning models, and model evaluation. <ul><li><strong>Algorithms:</strong> Regression, classification, clustering, PCA.</li><li><strong>Strength:</strong> Easy to use and integrate with other data science tools.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.729680 +00:00",
      "updated_at": "2025-11-01 13:12:03.729684 +00:00",
      "translation_group": "401bfe08-0083-4304-b290-30c4ace3a3ac"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 242,
    "fields": {
      "term": "Jupyter Notebook",
      "slug": "jupyter-notebook",
      "short_definition": "Interactive development environment for data science.",
      "long_definition": "<strong>Jupyter Notebooks</strong> allow combining code, text, visualizations, and outputs in one interactive document. They are widely used for research, teaching, and prototyping. <ul><li><strong>Format:</strong> .ipynb files executable in browsers.</li><li><strong>Use cases:</strong> Experimentation, tutorials, collaborative reports.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.730192 +00:00",
      "updated_at": "2025-11-01 13:12:03.730195 +00:00",
      "translation_group": "13627ef0-bde4-4e2a-a2e6-988a1020ea1f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 244,
    "fields": {
      "term": "GPU / TPU",
      "slug": "gpu-tpu",
      "short_definition": "Specialized hardware for fast AI training and inference.",
      "long_definition": "<strong>GPUs</strong> (Graphics Processing Units) and <strong>TPUs</strong> (Tensor Processing Units) are processors optimized for parallel computation, essential for deep learning. <ul><li><strong>GPU:</strong> Flexible and widely used for AI workloads.</li><li><strong>TPU:</strong> Custom chip by Google optimized for TensorFlow.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.732377 +00:00",
      "updated_at": "2025-11-01 13:12:03.732384 +00:00",
      "translation_group": "3df377c8-43c2-4a3f-b38e-a25afc5a6904"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 245,
    "fields": {
      "term": "Cloud Computing",
      "slug": "cloud-computing",
      "short_definition": "On-demand scalable computing resources via the internet.",
      "long_definition": "<strong>Cloud computing</strong> provides scalable infrastructure, storage, and services over the internet. In AI, it enables large-scale model training and deployment. <ul><li><strong>Examples:</strong> AWS SageMaker, Google Vertex AI, Azure ML.</li><li><strong>Benefits:</strong> Scalability, flexibility, cost control.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.733321 +00:00",
      "updated_at": "2025-11-01 13:12:03.733327 +00:00",
      "translation_group": "33260707-dbad-4a69-9819-68f1404515d3"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 246,
    "fields": {
      "term": "Edge AI",
      "slug": "edge-ai",
      "short_definition": "Running AI models directly on local devices or sensors.",
      "long_definition": "<strong>Edge AI</strong> processes data locally on devices instead of sending it to the cloud, reducing latency and preserving privacy. <ul><li><strong>Advantages:</strong> Offline capability, real-time processing, data security.</li><li><strong>Examples:</strong> Smart cameras, IoT sensors, mobile assistants.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.734106 +00:00",
      "updated_at": "2025-11-01 13:12:03.734110 +00:00",
      "translation_group": "f2b36d78-f98a-4a10-b124-60767747620c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 247,
    "fields": {
      "term": "Model Deployment",
      "slug": "model-deployment",
      "short_definition": "Process of bringing trained models into production.",
      "long_definition": "<strong>Model deployment</strong> includes all steps required to make a trained model available in a production environment for real-time or batch predictions. <ul><li><strong>Key aspects:</strong> Containerization, APIs, scalability, monitoring.</li><li><strong>Goal:</strong> Ensure reliable and efficient AI operations.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.734863 +00:00",
      "updated_at": "2025-11-01 13:12:03.734868 +00:00",
      "translation_group": "1e96024d-c4f1-4a01-ba0b-3fc6c61d78a1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 248,
    "fields": {
      "term": "Inference",
      "slug": "inference",
      "short_definition": "Using a trained model to make predictions on new data.",
      "long_definition": "<strong>Inference</strong> is the process of applying a trained AI model to unseen data to generate predictions or classifications. <ul><li><strong>Examples:</strong> Speech recognition, image labeling, text generation.</li><li><strong>Optimization:</strong> Batch inference, quantization, hardware acceleration.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.735522 +00:00",
      "updated_at": "2025-11-01 13:12:03.735527 +00:00",
      "translation_group": "5a9a4e38-9a8b-4dce-9afd-d9069f562e51"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 249,
    "fields": {
      "term": "Hugging Face",
      "slug": "hugging-face",
      "short_definition": "Open platform for AI models, datasets, and tools.",
      "long_definition": "<strong>Hugging Face</strong> is an open community hub for AI models, datasets, and frameworks. It provides tools to train, share, and deploy state-of-the-art models. <ul><li><strong>Main components:</strong> Transformers, Datasets, Tokenizers, Model Hub.</li><li><strong>Goal:</strong> Democratize access to AI technologies.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.736355 +00:00",
      "updated_at": "2025-11-01 13:12:03.736361 +00:00",
      "translation_group": "b0c5e6d8-a550-494b-8a7b-561b0018fba0"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 250,
    "fields": {
      "term": "MLOps",
      "slug": "mlops",
      "short_definition": "Operational practices for managing machine learning lifecycle.",
      "long_definition": "<strong>MLOps</strong> combines DevOps principles with machine learning workflows. It covers automation, version control, and monitoring for model lifecycle management. <ul><li><strong>Components:</strong> CI/CD pipelines, model registry, feature store, monitoring.</li><li><strong>Goal:</strong> Ensure reproducible, reliable, and scalable AI systems.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.737206 +00:00",
      "updated_at": "2025-11-01 13:12:03.737211 +00:00",
      "translation_group": "feee8d2a-ab90-41c0-91de-31f0234447de"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 251,
    "fields": {
      "term": "Data Pipeline",
      "slug": "data-pipeline",
      "short_definition": "Automated flow from data collection to delivery.",
      "long_definition": "<strong>Data pipelines</strong> automate the process of collecting, cleaning, transforming, and delivering data for analysis or training. <ul><li><strong>Tools:</strong> Apache Airflow, Prefect, Luigi.</li><li><strong>Goal:</strong> Ensure reproducibility, scalability, and data quality.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.737949 +00:00",
      "updated_at": "2025-11-01 13:12:03.737952 +00:00",
      "translation_group": "c5333f28-0250-4ae3-ba99-b7d4e532376b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 252,
    "fields": {
      "term": "Model Versioning",
      "slug": "model-versioning",
      "short_definition": "Tracking and managing different model versions.",
      "long_definition": "<strong>Model versioning</strong> keeps track of model artifacts, configurations, and training data to ensure reproducibility and rollback capability. <ul><li><strong>Tools:</strong> MLflow, DVC, Weights & Biases.</li><li><strong>Goal:</strong> Transparency and control over the AI model lifecycle.</li></ul>",
      "category": "Tech & Tools",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.738652 +00:00",
      "updated_at": "2025-11-01 13:12:03.738683 +00:00",
      "translation_group": "2edbf073-9c57-45d1-99c2-e42227f4b961"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 253,
    "fields": {
      "term": "Artificial General Intelligence (AGI)",
      "slug": "artificial-general-intelligence-agi",
      "short_definition": "Hypothetical AI with human-like general intelligence.",
      "long_definition": "<strong>AGI</strong> denotes hypothetical systems that can flexibly acquire, transfer, and apply knowledge across domains like humans. <ul><li><strong>Contrast:</strong> Unlike narrow AI (e.g., translation), AGI would learn and plan <em>across</em> domains.</li><li><strong>Core abilities:</strong> Language and world understanding, long-term planning, transfer learning, self-monitoring.</li><li><strong>Status:</strong> No widely accepted AGI exists; today’s systems are powerful but narrow or narrowly generalized.</li><li><strong>Opportunities:</strong> Automating complex knowledge work, accelerating research, new tools for education and medicine.</li><li><strong>Risks:</strong> Misaligned incentives, control problems, safety issues, power concentration, societal disruption.</li><li><strong>Governance:</strong> Safety standards, audits, evaluations, access controls, and accountability duties.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.753378 +00:00",
      "updated_at": "2025-11-01 13:12:03.753384 +00:00",
      "translation_group": "8cd04d26-11be-474d-82f2-6634e24b3c0d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 254,
    "fields": {
      "term": "Artificial Superintelligence (ASI)",
      "slug": "artificial-superintelligence-asi",
      "short_definition": "AI that surpasses humans across all cognitive domains.",
      "long_definition": "<strong>ASI</strong> is a speculative concept for systems that <em>exceed humans in virtually all cognitive tasks</em>. <ul><li><strong>Potential traits:</strong> Superhuman problem solving, strategic planning, rapid knowledge growth.</li><li><strong>Debate:</strong> Opportunities (medical breakthroughs) vs. risks (loss of safety and control).</li><li><strong>Current research focuses:</strong> Robustness, alignment, interpretability, emergency shutdown mechanisms, and governance models.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.754511 +00:00",
      "updated_at": "2025-11-01 13:12:03.754516 +00:00",
      "translation_group": "1a535b0d-9f32-4dfb-82a8-a0ecf840c38f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 255,
    "fields": {
      "term": "Automation",
      "slug": "automation",
      "short_definition": "Shifting tasks from humans to machines.",
      "long_definition": "<strong>Automation</strong> is the systematic transfer of repetitive or complex tasks to software, robotics, or AI models. <ul><li><strong>Types:</strong> Rule-based (if-this-then-that), statistical (prediction models), generative (assistance, drafting, code).</li><li><strong>Value:</strong> Lower cycle times, consistent quality, scalability, 24/7 operation.</li><li><strong>Limits:</strong> Data quality, error propagation, explainability, pipeline maintenance and exceptions.</li><li><strong>Workplace:</strong> Tasks shift (from manual execution to monitoring, control, creative work); upskilling and worker participation are key.</li><li><strong>Compliance & law:</strong> Documentation duties, data protection, liability, industry standards.</li><li><strong>Best practices:</strong> Measurable goals, phased rollout (pilot → production), monitoring, human-in-the-loop, clear escalation paths.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.755367 +00:00",
      "updated_at": "2025-11-01 13:12:03.755372 +00:00",
      "translation_group": "8b245d70-185d-43b4-bec3-98612697bf6a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 256,
    "fields": {
      "term": "Human–Machine Interaction (HMI)",
      "slug": "human-machine-interaction-hmi",
      "short_definition": "Designing collaboration between humans and systems.",
      "long_definition": "<strong>Human–Machine Interaction (HMI)</strong> covers user-centered design of interfaces to (AI) systems. <ul><li><strong>Goals:</strong> Efficiency, safety, trust, traceability.</li><li><strong>Design principles:</strong> Clear feedback, explanations (<em>why</em> a result?), controllable automation levels, accessibility.</li><li><strong>Examples:</strong> Explainable recommendations in dashboards, suggestions with justifications, easily reversible actions.</li><li><strong>Risks:</strong> Automation bias (blind trust), overload from too many options, dark patterns.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.756046 +00:00",
      "updated_at": "2025-11-01 13:12:03.756050 +00:00",
      "translation_group": "b0c29b40-4392-4967-9ee3-9cd8bfcf0603"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 257,
    "fields": {
      "term": "Digital Transformation",
      "slug": "digital-transformation",
      "short_definition": "Deep organizational change through digital technologies.",
      "long_definition": "<strong>Digital transformation</strong> is the long-term redesign of processes, products, and culture using digital technologies. <ul><li><strong>Dimensions:</strong> Business models (e.g., subscriptions), processes (automation, data flows), organization (roles, skills), technology (cloud, APIs, AI).</li><li><strong>Success factors:</strong> Clear vision, iteration, data strategy, change management, security.</li><li><strong>Pitfalls:</strong> Tool-centricity over outcomes, poor data quality, silos, “PoC graveyards” without rollout.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.756683 +00:00",
      "updated_at": "2025-11-01 13:12:03.756686 +00:00",
      "translation_group": "8d92dc75-7ce6-4e08-bddd-b59bca6d18d9"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 258,
    "fields": {
      "term": "Copyright and AI",
      "slug": "copyright-and-ai",
      "short_definition": "Rights in AI input/output and training data.",
      "long_definition": "<strong>Copyright & AI</strong> concerns the use of protected works in training, rights in generated outputs, and licensing/liability questions. <ul><li><strong>Training:</strong> Depending on jurisdiction, exceptions/consent apply (e.g., text- and data-mining rules); rights holders may restrict use.</li><li><strong>Output:</strong> Protectability often depends on human contribution; purely machine-generated content may not be protected.</li><li><strong>Licensing:</strong> Model and dataset licenses (open-source or model-specific) include conditions (purpose limits, attribution, usage restrictions).</li><li><strong>Compliance:</strong> Document sources, opt-out signals, terms of use, and rights chains.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.757176 +00:00",
      "updated_at": "2025-11-01 13:12:03.757179 +00:00",
      "translation_group": "1021ac33-fcb7-41a9-ae4a-e8d5c8d814c8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 259,
    "fields": {
      "term": "Liability for AI Decisions",
      "slug": "liability-for-ai-decisions",
      "short_definition": "Legal responsibility for faulty AI outcomes.",
      "long_definition": "<strong>Liability</strong> clarifies who is accountable for harm caused by AI-assisted decisions. <ul><li><strong>Angles:</strong> Product/manufacturer liability, operator duties, due care in selection and oversight.</li><li><strong>Proof:</strong> Logs, explanations, audit trails, and data retention support evidence.</li><li><strong>Prevention:</strong> Risk assessments, testing/V&V, human-in-the-loop, emergency procedures, periodic re-certification.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.757658 +00:00",
      "updated_at": "2025-11-01 13:12:03.757661 +00:00",
      "translation_group": "98336326-57cc-4178-9243-35fd729f91e8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 260,
    "fields": {
      "term": "Open-Source AI",
      "slug": "open-source-ai",
      "short_definition": "Openly licensed models, datasets, and tools.",
      "long_definition": "<strong>Open-Source AI</strong> comprises freely licensed models, datasets, and tools. <ul><li><strong>Benefits:</strong> Transparency, verifiability, community innovation, cost control, portability.</li><li><strong>Attention:</strong> License terms (e.g., MIT, Apache-2.0, model-specific), trademarks, responsible use.</li><li><strong>Practice:</strong> Reproducible train/eval pipelines, model cards, data cards, security reviews.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.758196 +00:00",
      "updated_at": "2025-11-01 13:12:03.758200 +00:00",
      "translation_group": "13c3dc5e-f9ed-4814-ab77-16e16a50c364"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 261,
    "fields": {
      "term": "Commercial AI",
      "slug": "commercial-ai",
      "short_definition": "Proprietary models, services, and platforms.",
      "long_definition": "<strong>Commercial AI</strong> refers to proprietary offerings with support, SLAs, and integrations. <ul><li><strong>Pros:</strong> Availability, scale, security, ecosystems/plugins, liability frameworks.</li><li><strong>Cons:</strong> Cost, vendor lock-in, lower transparency.</li><li><strong>Decision criteria:</strong> Data protection, data residency, price/performance, resilience, export/portability paths.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.758754 +00:00",
      "updated_at": "2025-11-01 13:12:03.758757 +00:00",
      "translation_group": "e7f5ec07-0e6b-4369-8e3a-6d7b890cf937"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 262,
    "fields": {
      "term": "AI Research",
      "slug": "ai-research",
      "short_definition": "Scientific development of new methods and applications.",
      "long_definition": "<strong>AI research</strong> ranges from fundamentals (learning, representation, optimization) to applications (medicine, education, industry). <ul><li><strong>Methods:</strong> New architectures, training schemes, evaluation metrics, safety approaches.</li><li><strong>Transfer:</strong> Open-source models, benchmarks, responsible disclosure.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.759350 +00:00",
      "updated_at": "2025-11-01 13:12:03.759354 +00:00",
      "translation_group": "177a200c-3213-4d9d-a76f-28837f6e16a6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 263,
    "fields": {
      "term": "Technological Singularity",
      "slug": "technological-singularity",
      "short_definition": "Hypothetical point of rapid, uncontrollable progress.",
      "long_definition": "The <strong>technological singularity</strong> is a scenario where improvement of intelligent systems accelerates itself and fundamentally changes society. <ul><li><strong>Arguments for:</strong> Positive feedback from AI-driven research, exponential trends.</li><li><strong>Arguments against:</strong> Physical/economic limits, data/energy/safety bottlenecks, governance constraints.</li><li><strong>Practical value today:</strong> As a thought model, it raises awareness of scaling and safety issues.</li></ul>",
      "category": "Society & Law",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.760014 +00:00",
      "updated_at": "2025-11-01 13:12:03.760018 +00:00",
      "translation_group": "eace0b2b-c5ce-4267-bb8f-f40eba62755d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 264,
    "fields": {
      "term": "AI Agent",
      "slug": "ai-agent",
      "short_definition": "Model with autonomy, goals, and tool usage.",
      "long_definition": "<strong>AI agents</strong> combine models with planning, perception, tool access, and feedback loops to pursue goals independently. <ul><li><strong>Core components:</strong> Goal decomposition, API calls, memory, evaluation and correction cycles.</li><li><strong>Applications:</strong> Research workflows, data pipelines, customer support automation, DevOps routines.</li><li><strong>Controls:</strong> Permission limits, cost monitoring, validation rules, human approval steps.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.763941 +00:00",
      "updated_at": "2025-11-01 13:12:03.763947 +00:00",
      "translation_group": "80875e2c-c524-4499-96ab-d3afac83ca88"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 265,
    "fields": {
      "term": "Multi-Agent System",
      "slug": "multi-agent-system",
      "short_definition": "Populations of cooperating or competing agents.",
      "long_definition": "<strong>Multi-agent systems</strong> coordinate multiple specialized agents with defined roles (e.g., planner, reviewer, executor). <ul><li><strong>Coordination:</strong> Negotiation, blackboard or message bus, voting mechanisms.</li><li><strong>Advantages:</strong> Task distribution, fault tolerance, peer review leading to better quality.</li><li><strong>Challenges:</strong> Costs, latency, stability, role drift.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.764698 +00:00",
      "updated_at": "2025-11-01 13:12:03.764702 +00:00",
      "translation_group": "56aae976-d8d4-4710-86b0-49fef8939ded"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 266,
    "fields": {
      "term": "Tool Use",
      "slug": "tool-use",
      "short_definition": "Integrating external tools (APIs) into model chains.",
      "long_definition": "<strong>Tool use</strong> extends models by connecting them to functions such as search, databases, or actuators. <ul><li><strong>Benefits:</strong> Access to up-to-date information, execution of external actions, computational offloading.</li><li><strong>Risks:</strong> Security clearance, cost control, correctness of external results.</li><li><strong>Best practices:</strong> Whitelisting, sandboxing, logs and receipts, rate limiting.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.765331 +00:00",
      "updated_at": "2025-11-01 13:12:03.765334 +00:00",
      "translation_group": "b1b703fb-1030-4f22-b0da-14bc754d62c4"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 267,
    "fields": {
      "term": "Chain-of-Thought",
      "slug": "chain-of-thought",
      "short_definition": "Explicit reasoning steps for problem-solving.",
      "long_definition": "<strong>Chain-of-Thought (CoT)</strong> means models produce visible intermediate reasoning steps (e.g., calculations, explanations). <ul><li><strong>Advantages:</strong> Better accuracy on complex tasks, improved verifiability.</li><li><strong>Caution:</strong> Can unintentionally reveal sensitive information—often used internally only.</li><li><strong>Alternatives:</strong> Structured plans, scratchpads, program-aided reasoning.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.766018 +00:00",
      "updated_at": "2025-11-01 13:12:03.766021 +00:00",
      "translation_group": "6172df28-7a34-4ca1-9ef0-25430ab929dc"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 268,
    "fields": {
      "term": "Self-Consistency",
      "slug": "self-consistency",
      "short_definition": "Sampling multiple answers to reach consensus.",
      "long_definition": "<strong>Self-consistency</strong> generates multiple candidate solutions and selects the most consistent one through comparison or voting. <ul><li><strong>Benefit:</strong> Reduces random variation and increases reliability.</li><li><strong>Trade-off:</strong> Requires more computation and time.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.766573 +00:00",
      "updated_at": "2025-11-01 13:12:03.766577 +00:00",
      "translation_group": "9a737ee4-ee74-4c78-82bd-2766127c1012"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 269,
    "fields": {
      "term": "Planning / Reasoning",
      "slug": "planning-reasoning",
      "short_definition": "Structured planning and logical reasoning across steps.",
      "long_definition": "<strong>Planning and reasoning</strong> break tasks into subproblems and link intermediate results through logic. <ul><li><strong>Techniques:</strong> Task trees, goal decomposition, search algorithms, verification.</li><li><strong>Applications:</strong> Workflow orchestration, debugging, data preprocessing, decision support.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.767313 +00:00",
      "updated_at": "2025-11-01 13:12:03.767318 +00:00",
      "translation_group": "c5adfb4a-d477-4e3c-9218-d8e6ddae1fe8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 270,
    "fields": {
      "term": "Long-Term Memory",
      "slug": "long-term-memory",
      "short_definition": "Persistent storage of context and preferences.",
      "long_definition": "<strong>Long-term memory</strong> stores information beyond single sessions, such as project data, user preferences, or facts. <ul><li><strong>Implementation:</strong> Vector databases, note repositories, user profiles.</li><li><strong>Privacy:</strong> Purpose limitation, deletion concepts, transparency and opt-out options.</li><li><strong>Quality:</strong> Versioning, aging, and validating entries with feedback loops.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.767950 +00:00",
      "updated_at": "2025-11-01 13:12:03.767954 +00:00",
      "translation_group": "de6bfe57-33c9-478a-8336-a64f0badfcd5"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 271,
    "fields": {
      "term": "RAG Pipeline",
      "slug": "rag-pipeline",
      "short_definition": "Process: Index → Retrieval → Generation.",
      "long_definition": "<strong>Retrieval-Augmented Generation (RAG)</strong> combines information retrieval with text generation. <ul><li><strong>Steps:</strong> Vectorize documents → retrieve relevant chunks → provide as context → generate an answer.</li><li><strong>Strengths:</strong> Factual grounding, up-to-date knowledge, reduced hallucination.</li><li><strong>Best practices:</strong> Index hygiene, chunking, citation strategy, recall/precision evaluation.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.768606 +00:00",
      "updated_at": "2025-11-01 13:12:03.768611 +00:00",
      "translation_group": "aac1d41c-093d-4100-afff-b9debc057085"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 272,
    "fields": {
      "term": "Vector Database",
      "slug": "vector-database",
      "short_definition": "Index for similarity search in embedding spaces.",
      "long_definition": "<strong>Vector databases</strong> store embeddings and enable fast similarity searches. <ul><li><strong>Index structures:</strong> HNSW, IVF-PQ, DiskANN, etc.</li><li><strong>Parameters:</strong> Dimensionality, distance metrics, recall/speed trade-offs.</li><li><strong>Practice:</strong> Deduplication, metadata filtering, re-indexing, observability.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.769271 +00:00",
      "updated_at": "2025-11-01 13:12:03.769276 +00:00",
      "translation_group": "64cb27a1-1543-4542-b7d4-568d2632971a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 273,
    "fields": {
      "term": "Semantic Search",
      "slug": "semantic-search",
      "short_definition": "Search based on meaning instead of keywords.",
      "long_definition": "<strong>Semantic search</strong> compares meanings (embeddings) rather than exact keywords. <ul><li><strong>Advantages:</strong> Robust to synonyms, typos, and context variations.</li><li><strong>Limitations:</strong> Domain-specific terms require specialized data or models.</li><li><strong>Quality assurance:</strong> Offline benchmarks, A/B tests, manual review, explanations and citations.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.770218 +00:00",
      "updated_at": "2025-11-01 13:12:03.770223 +00:00",
      "translation_group": "e4c55c4b-af0b-4cc8-b0d4-3ebf18418b20"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 274,
    "fields": {
      "term": "AI-as-a-Service (AIaaS)",
      "slug": "ai-as-a-service-aiaas",
      "short_definition": "Providing AI capabilities as cloud services.",
      "long_definition": "<strong>AI-as-a-Service (AIaaS)</strong> delivers AI functionalities through APIs or SDKs. <ul><li><strong>Advantages:</strong> Fast integration, scalability, managed security, and monitoring.</li><li><strong>Disadvantages:</strong> Cost, data exposure, vendor lock-in, limited customization.</li><li><strong>Selection criteria:</strong> SLA, privacy, region, explainability features, exit strategies.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.770878 +00:00",
      "updated_at": "2025-11-01 13:12:03.770882 +00:00",
      "translation_group": "46d98c14-0b79-4a77-b329-0ecd33e99eac"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 275,
    "fields": {
      "term": "Continual Learning",
      "slug": "continual-learning",
      "short_definition": "Learning continuously without forgetting past knowledge.",
      "long_definition": "<strong>Continual learning</strong> enables models to learn over time while retaining previously acquired knowledge. <ul><li><strong>Approaches:</strong> Regularization (e.g., EWC), rehearsal/replay, dynamic architectures.</li><li><strong>Challenges:</strong> Catastrophic forgetting, data availability, version-to-version validation.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.771638 +00:00",
      "updated_at": "2025-11-01 13:12:03.771655 +00:00",
      "translation_group": "8d68c2e3-1dae-4391-a910-969e15fcbd6f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 276,
    "fields": {
      "term": "Federated Learning",
      "slug": "federated-learning",
      "short_definition": "Decentralized training across devices with privacy protection.",
      "long_definition": "<strong>Federated learning</strong> trains locally on user devices or sites and aggregates only model updates centrally. <ul><li><strong>Advantages:</strong> Better data privacy and ownership, reduced raw data transfer.</li><li><strong>Add-ons:</strong> Secure aggregation, differential privacy, management of device heterogeneity.</li><li><strong>Use cases:</strong> Mobile devices, healthcare, industrial IoT.</li></ul>",
      "category": "Trends & Concepts",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.772907 +00:00",
      "updated_at": "2025-11-01 13:12:03.772913 +00:00",
      "translation_group": "3ed472fc-642d-408b-a1a4-8def5375ca82"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 277,
    "fields": {
      "term": "Algorithm",
      "slug": "algorithm",
      "short_definition": "Step-by-step procedure for solving a problem.",
      "long_definition": "<strong>Algorithm</strong> is a precise sequence of instructions that transforms inputs into results. <ul><li><strong>Characteristics:</strong> Finite, reproducible, and deterministic.</li><li><strong>Examples:</strong> Sorting lists, route calculation, spam detection.</li><li><strong>Role in AI:</strong> Training, search, and optimization methods are built on numerous algorithms.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.787067 +00:00",
      "updated_at": "2025-11-01 13:12:03.787073 +00:00",
      "translation_group": "44343d60-3e16-4683-8c68-d901be9f962f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 278,
    "fields": {
      "term": "Data",
      "slug": "data",
      "short_definition": "Raw information from which models learn.",
      "long_definition": "<strong>Data</strong> includes numbers, text, images, audio, or logs representing real-world phenomena. <ul><li><strong>Quality aspects:</strong> Completeness, accuracy, relevance, timeliness, low bias.</li><li><strong>Preparation:</strong> Cleaning, enrichment, labeling, anonymization.</li><li><strong>Impact:</strong> Poor data → poor models; high-quality data is the strongest performance driver.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.788020 +00:00",
      "updated_at": "2025-11-01 13:12:03.788025 +00:00",
      "translation_group": "745480b6-94b0-473f-8ce2-9314e413f48f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 279,
    "fields": {
      "term": "Chatbot",
      "slug": "chatbot",
      "short_definition": "Program that interacts with humans via text or voice.",
      "long_definition": "<strong>Chatbots</strong> conduct dialogues, answer questions, and complete tasks. <ul><li><strong>Types:</strong> Rule-based (predefined flows) and AI-based (generation and understanding).</li><li><strong>Functions:</strong> FAQs, support tickets, booking assistants, workplace helpers.</li><li><strong>Important:</strong> Clear escalation to humans, logging, and transparent data use notices.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.788929 +00:00",
      "updated_at": "2025-11-01 13:12:03.788934 +00:00",
      "translation_group": "e479af54-5a64-4afb-9f38-f1d2426cd395"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 280,
    "fields": {
      "term": "Model Training",
      "slug": "model-training",
      "short_definition": "Adjusting a model’s weights to match data.",
      "long_definition": "<strong>Training</strong> adjusts model parameters so prediction errors decrease. <ul><li><strong>Process:</strong> Data → prediction → error measurement → weight update.</li><li><strong>Concepts:</strong> Learning rate, overfitting, validation, test set, checkpoints.</li><li><strong>Practice:</strong> Good data splits, metric monitoring, reproducible pipelines.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.789608 +00:00",
      "updated_at": "2025-11-01 13:12:03.789612 +00:00",
      "translation_group": "78a5398d-8ab7-4f68-8508-ecf6b37a0177"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 281,
    "fields": {
      "term": "Prompt",
      "slug": "prompt",
      "short_definition": "Input instruction for a model.",
      "long_definition": "<strong>Prompt</strong> is the task description given to a model. <ul><li><strong>Elements:</strong> Role/goal, context/examples, formatting, criteria.</li><li><strong>Tips:</strong> Be specific, include examples, define output format, specify quality criteria.</li><li><strong>Variants:</strong> Zero-/Few-shot, system vs. user prompts, tool-augmented prompts.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.790160 +00:00",
      "updated_at": "2025-11-01 13:12:03.790164 +00:00",
      "translation_group": "68ac43fc-1ddc-477b-b8f3-2359649eb462"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 282,
    "fields": {
      "term": "AI Tool",
      "slug": "ai-tool",
      "short_definition": "Application that provides AI functions.",
      "long_definition": "<strong>AI tools</strong> are applications or services that generate text, images, code, or predictions. <ul><li><strong>Categories:</strong> Assistants, image/audio generators, analytics tools, low-code integrations.</li><li><strong>Selection:</strong> Cost, security, data residency, usability, export/integration options.</li><li><strong>Implementation:</strong> Start small pilots, gather feedback, define governance.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.790784 +00:00",
      "updated_at": "2025-11-01 13:12:03.790788 +00:00",
      "translation_group": "1c858a87-3088-4d14-96ad-7430ba5cbaa2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 283,
    "fields": {
      "term": "Transparency (General)",
      "slug": "transparency-general",
      "short_definition": "Clear disclosure of functionality and limitations.",
      "long_definition": "<strong>Transparency</strong> makes it understandable <em>how</em> a system works and <em>where</em> its limits are. <ul><li><strong>Tools:</strong> Data/model cards, explanations, uncertainty notes, usage logs.</li><li><strong>Benefits:</strong> Builds trust, aids debugging, supports compliance.</li><li><strong>Balance:</strong> Protect trade secrets while ensuring adequate user information.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.791428 +00:00",
      "updated_at": "2025-11-01 13:12:03.791431 +00:00",
      "translation_group": "1df570dc-540a-4ad1-bd0b-cbd4c24e1dae"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 284,
    "fields": {
      "term": "Human Oversight",
      "slug": "human-oversight",
      "short_definition": "Humans retain ultimate decision authority.",
      "long_definition": "<strong>Human-in-the-loop</strong> ensures critical steps are reviewed, corrected, or approved by humans. <ul><li><strong>Design:</strong> Thresholds, approval workflows, undo options, escalation paths.</li><li><strong>Use cases:</strong> Medicine, law, finance, safety-critical domains.</li><li><strong>Goal:</strong> Reduce risks and assign accountability clearly.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.792003 +00:00",
      "updated_at": "2025-11-01 13:12:03.792007 +00:00",
      "translation_group": "f685135b-d624-451e-8090-81d459626484"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 285,
    "fields": {
      "term": "Creative Use",
      "slug": "creative-use",
      "short_definition": "Using AI for idea generation, writing, or design.",
      "long_definition": "<strong>Creative use</strong> describes leveraging AI for inspiration and acceleration in creative workflows. <ul><li><strong>Examples:</strong> Brainstorming, outlining texts, varying styles, generating sketches.</li><li><strong>Best practices:</strong> Iterative prompting, citing references, checking authorship and licensing.</li><li><strong>Reminder:</strong> AI is a tool – humans remain responsible for the final outcome.</li></ul>",
      "category": "Beginner-Friendly Additions",
      "language": "en",
      "created_at": "2025-11-01 13:12:03.792924 +00:00",
      "updated_at": "2025-11-01 13:12:03.792932 +00:00",
      "translation_group": "ce3a94b5-1865-4b29-845e-08d4dd085c60"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 2,
    "fields": {
      "term": "Maschinelles Lernen (ML)",
      "slug": "maschinelles-lernen-ml",
      "short_definition": "Algorithmen, die aus Daten Muster lernen statt fest programmiert zu sein.",
      "long_definition": "<strong>Maschinelles Lernen</strong> optimiert Modellparameter so, dass aus Beispielen verallgemeinerbare Vorhersagen entstehen. <ul><li><strong>Hauptarten:</strong> Überwacht, unüberwacht, bestärkend.</li><li><strong>Workflow:</strong> Datenaufbereitung → Training → Validierung → Test/Monitoring.</li><li><strong>Risiken:</strong> Overfitting, Datenleckage, Verteilungsverschiebungen (Data/Concept Drift).</li><li><strong>Good Practices:</strong> saubere Splits, Baselines, reproduzierbare Pipelines, Metriken passend zur Aufgabe.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.553839 +00:00",
      "updated_at": "2025-11-01 13:12:03.553844 +00:00",
      "translation_group": "e6577abe-2276-4a5e-8f18-f87289c05e4e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 3,
    "fields": {
      "term": "Deep Learning",
      "slug": "deep-learning",
      "short_definition": "Lernen mit tiefen neuronalen Netzen und vielen Parametern.",
      "long_definition": "<strong>Deep Learning</strong> nutzt Schichten nichtlinearer Transformationen, um komplexe Muster in Text, Bild, Audio oder Multimodalität zu erfassen. <ul><li><strong>Stärken:</strong> Leistungsfähig bei großen Datenmengen, automatische Merkmalsbildung.</li><li><strong>Schwächen:</strong> Daten-/Rechenhunger, schwierige Erklärbarkeit, potenzielle Vulnerabilitäten.</li><li><strong>Typische Architekturen:</strong> CNNs, RNNs/LSTMs, Transformer.</li><li><strong>Praxis:</strong> Transfer Learning und Feintuning reduzieren Kosten und Datenbedarf.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.554638 +00:00",
      "updated_at": "2025-11-01 13:12:03.554643 +00:00",
      "translation_group": "71184f24-50bd-428a-afd5-46452c427e88"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 4,
    "fields": {
      "term": "Neuronales Netz",
      "slug": "neuronales-netz",
      "short_definition": "Vernetzte Schichten aus künstlichen Neuronen zur Mustererkennung.",
      "long_definition": "<strong>Neuronale Netze</strong> bestehen aus gewichteten Verbindungen (Neuronen), die Eingaben verarbeiten und Signale weitergeben. <ul><li><strong>Bausteine:</strong> Schichten (Input/Hidden/Output), Aktivierungsfunktionen, Gewichte/Bias.</li><li><strong>Lernen:</strong> Gradientenabstieg minimiert eine Verlustfunktion.</li><li><strong>Varianten:</strong> Feedforward, rekurrent, konvolutional, Transformer-basiert.</li><li><strong>Herausforderungen:</strong> Über-/Unteranpassung, Hyperparameterwahl, Generalisierung.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.555614 +00:00",
      "updated_at": "2025-11-01 13:12:03.555621 +00:00",
      "translation_group": "e8b6dd3e-b728-4479-b5e5-fb291015f469"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 5,
    "fields": {
      "term": "Überwachtes Lernen",
      "slug": "uberwachtes-lernen",
      "short_definition": "Training mit gelabelten Beispielen (Eingabe→Zielwert).",
      "long_definition": "<strong>Überwachtes Lernen</strong> nutzt Eingabe-Ziel-Paare, um eine Abbildungsfunktion zu erlernen. <ul><li><strong>Aufgaben:</strong> Klassifikation (Klasse), Regression (Zahl), Ranking.</li><li><strong>Qualitätstreiber:</strong> Labelgüte, Klassenbalance, geeignete Metriken.</li><li><strong>Gefahren:</strong> Datenleckage, Overfitting, verschobene Verteilungen im Einsatz.</li><li><strong>Praxis:</strong> Cross-Validation, Regularisierung, frühes Stoppen, Datenaugmentation.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.556541 +00:00",
      "updated_at": "2025-11-01 13:12:03.556546 +00:00",
      "translation_group": "b5f2e2a3-6212-4429-8cc3-92a639911985"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 6,
    "fields": {
      "term": "Unüberwachtes Lernen",
      "slug": "unuberwachtes-lernen",
      "short_definition": "Strukturen in unbeschrifteten Daten finden (z.B. Clustering).",
      "long_definition": "<strong>Unüberwachtes Lernen</strong> entdeckt Muster ohne Zielwerte. <ul><li><strong>Typen:</strong> Clustering, Dimensionsreduktion, Dichteschätzung, Anomalieerkennung.</li><li><strong>Einsatz:</strong> Explorative Analysen, Vorverarbeitung, Recommender-Vorstufen.</li><li><strong>Risiken:</strong> subjektive Interpretationen, Wahl von Parametern/Distanzmaßen.</li><li><strong>Praxis:</strong> Visualisierung, Stabilitätschecks, Domänenwissen einbinden.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.557372 +00:00",
      "updated_at": "2025-11-01 13:12:03.557376 +00:00",
      "translation_group": "c278eeb9-d0e1-40f1-9e67-0c03267a26b1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 7,
    "fields": {
      "term": "Bestärkendes Lernen (RL)",
      "slug": "bestarkendes-lernen-rl",
      "short_definition": "Agenten lernen durch Belohnung in einer Umgebung.",
      "long_definition": "<strong>Reinforcement Learning</strong> optimiert eine Strategie (Policy) eines Agenten durch Belohnungen in Interaktion mit einer Umgebung. <ul><li><strong>Kernelemente:</strong> Zustände, Aktionen, Belohnungen, Übergangsdynamik.</li><li><strong>Methoden:</strong> Wertfunktion (Q-Learning), Policy-Gradient, Actor-Critic.</li><li><strong>Herausforderungen:</strong> Exploration vs. Exploitation, Stabilität, Musterübertragung aus Simulation.</li><li><strong>Praxis:</strong> Reward-Design, Sicherheitsgrenzen, Off-Policy-Evaluation.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.558089 +00:00",
      "updated_at": "2025-11-01 13:12:03.558094 +00:00",
      "translation_group": "8faa1407-e225-4105-b22c-95287d9dce31"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 8,
    "fields": {
      "term": "Trainingsdaten",
      "slug": "trainingsdaten",
      "short_definition": "Daten, mit denen ein Modell lernt.",
      "long_definition": "<strong>Trainingsdaten</strong> bestimmen Kapazitäten und Grenzen eines Modells. <ul><li><strong>Qualitätsmerkmale:</strong> Repräsentativität, Rauscharmut, Labelgüte, Abdeckung.</li><li><strong>Risiken:</strong> Verzerrungen, Duplikate/Leckagen, unzulässige Inhalte.</li><li><strong>Praxis:</strong> Kuratieren, deduplizieren, balancieren, dokumentieren (Datenkarten).</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.558813 +00:00",
      "updated_at": "2025-11-01 13:12:03.558817 +00:00",
      "translation_group": "32dbf39a-a8b2-4775-bfd8-91b28f8c5f3e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 9,
    "fields": {
      "term": "Validierungsdaten",
      "slug": "validierungsdaten",
      "short_definition": "Daten zur Modellabstimmung (z.B. Hyperparameter).",
      "long_definition": "<strong>Validierungsdaten</strong> steuern Auswahl von Modellen/Hyperparametern ohne das finale Testset zu berühren. <ul><li><strong>Ziel:</strong> Generalisierungsschätzung während der Entwicklung.</li><li><strong>Good Practices:</strong> strikte Trennung zu Training/Test, same distribution, aussagekräftige Metriken.</li><li><strong>Gefahr:</strong> <em>Overfitting an die Validierung</em> durch wiederholtes Tuning.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.559378 +00:00",
      "updated_at": "2025-11-01 13:12:03.559381 +00:00",
      "translation_group": "38240e47-9223-48fd-9172-e2123f68fe48"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 10,
    "fields": {
      "term": "Testdaten",
      "slug": "testdaten",
      "short_definition": "Unberührte Daten zur objektiven Leistungsprüfung.",
      "long_definition": "<strong>Testdaten</strong> werden ausschließlich am Ende genutzt, um die echte Generalisierung zu messen. <ul><li><strong>Anforderungen:</strong> sauberer Hold-out, repräsentativ für den Einsatz, keine Datenleckagen.</li><li><strong>Metriken:</strong> aufgabengerecht (z.B. F1 statt Accuracy bei Ungleichgewichten).</li><li><strong>Praxis:</strong> Bericht mit Konfidenzen, Fehleranalyse und Limitationshinweisen.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.560135 +00:00",
      "updated_at": "2025-11-01 13:12:03.560140 +00:00",
      "translation_group": "a24ecc4c-9972-4cc6-aa3b-65e9b1c766e8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 11,
    "fields": {
      "term": "Modell",
      "slug": "modell",
      "short_definition": "Parametrisierte Funktion, die Eingaben in Ausgaben abbildet.",
      "long_definition": "Ein <strong>Modell</strong> ist eine parametrisierte Funktion f(x; θ), deren Parameter θ aus Daten gelernt werden. <ul><li><strong>Formen:</strong> Lineare Modelle, Entscheidungsbäume, neuronale Netze, probabilistische Modelle.</li><li><strong>Training:</strong> Minimierung einer Verlustfunktion mittels Optimierung.</li><li><strong>Bewertung:</strong> passende Metriken, Robustheits- und Fairnessprüfungen.</li><li><strong>Lifecycle:</strong> Versionierung, Monitoring, Retraining bei Drift.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.561232 +00:00",
      "updated_at": "2025-11-01 13:12:03.561237 +00:00",
      "translation_group": "69768aab-d95d-4715-a3b0-870bac9d32c1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 12,
    "fields": {
      "term": "Feature (Merkmal)",
      "slug": "feature-merkmal",
      "short_definition": "Messbare Eingabeeigenschaft für ein Modell.",
      "long_definition": "<strong>Features</strong> sind transformierte Eingaben, die relevante Struktur für ein Modell sichtbar machen. <ul><li><strong>Arten:</strong> numerisch, kategorisch, Text-/Bildrepräsentationen, Embeddings.</li><li><strong>Engineering:</strong> Skalierung, Kodierung, Interaktionen, Domänenwissen.</li><li><strong>Risiken:</strong> Leckage (z.B. Zeitmerkmale), Korrelation vs. Kausalität.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.561934 +00:00",
      "updated_at": "2025-11-01 13:12:03.561938 +00:00",
      "translation_group": "242c8278-ecf0-475f-b3cf-e5b9ff4f70f8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 13,
    "fields": {
      "term": "Label (Zielwert)",
      "slug": "label-zielwert",
      "short_definition": "Erwartete Ausgabe im überwachten Lernen.",
      "long_definition": "<strong>Labels</strong> sind Zielgrößen, gegen die ein Modell lernt. <ul><li><strong>Eigenschaften:</strong> Eindeutigkeit, Konsistenz, Qualität der Annotation.</li><li><strong>Besonderheiten:</strong> schwache Labels, multiple Labels, Rauschen.</li><li><strong>Praxis:</strong> klare Richtlinien, Audit der Labelprozesse, Qualitätsmetriken.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.562573 +00:00",
      "updated_at": "2025-11-01 13:12:03.562576 +00:00",
      "translation_group": "f396ffd3-da6a-41f5-9012-478133d85157"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 14,
    "fields": {
      "term": "Overfitting (Überanpassung)",
      "slug": "overfitting-uberanpassung",
      "short_definition": "Modell lernt Rauschen; Leistung auf neuen Daten sinkt.",
      "long_definition": "<strong>Overfitting</strong> entsteht, wenn ein Modell Trainingsidiosynkrasien statt allgemein gültiger Muster lernt. <ul><li><strong>Anzeichen:</strong> große Lücke zwischen Trainings- und Testleistung.</li><li><strong>Gegenmittel:</strong> Regularisierung, Datenaugmentation, frühzeitiges Stoppen, mehr Daten.</li><li><strong>Diagnostik:</strong> Lernkurven, abgeleitete Fehlertypen, ablation studies.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.563149 +00:00",
      "updated_at": "2025-11-01 13:12:03.563152 +00:00",
      "translation_group": "6df41ab2-b88f-40d5-87bb-fa0da621baf5"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 15,
    "fields": {
      "term": "Underfitting (Unteranpassung)",
      "slug": "underfitting-unteranpassung",
      "short_definition": "Modell ist zu simpel; erkennt Muster nicht.",
      "long_definition": "<strong>Underfitting</strong> liegt vor, wenn die Modellkapazität oder das Feature-Design nicht ausreicht, um Muster zu erfassen. <ul><li><strong>Anzeichen:</strong> schlechte Leistung auf Training <em>und</em> Test.</li><li><strong>Lösungen:</strong> komplexere Modelle, bessere Features, längeres Training, Hyperparameter-Tuning.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.563698 +00:00",
      "updated_at": "2025-11-01 13:12:03.563701 +00:00",
      "translation_group": "97dc7462-f434-4f0a-acec-5a7933f4ce36"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 16,
    "fields": {
      "term": "Bias (Verzerrung)",
      "slug": "bias-verzerrung",
      "short_definition": "Systematische Fehleinschätzung im Modell oder in Daten.",
      "long_definition": "<strong>Bias</strong> bezeichnet systematische Abweichungen, die zu unfairen oder falschen Ergebnissen führen können. <ul><li><strong>Quellen:</strong> unausgewogene Daten, Sammel-/Messartefakte, fehlerhafte Labels, Modellannahmen.</li><li><strong>Folgen:</strong> Benachteiligung von Gruppen, schlechte Generalisierung.</li><li><strong>Gegenmaßnahmen:</strong> Daten-Audits, Fairnessmetriken, rebalancing, erklärbare Modelle.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.564201 +00:00",
      "updated_at": "2025-11-01 13:12:03.564204 +00:00",
      "translation_group": "3660700d-88b1-40b4-b229-bd4c1d95b466"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 17,
    "fields": {
      "term": "Fairness (in KI)",
      "slug": "fairness-in-ki",
      "short_definition": "Grundsatz, nach dem Modelle Gruppen nicht benachteiligen sollen.",
      "long_definition": "<strong>Fairness</strong> zielt darauf, ungerechtfertigte Unterschiede in Vorhersagen oder Entscheidungen zu minimieren. <ul><li><strong>Perspektiven:</strong> individuelle vs. gruppenbasierte Fairness.</li><li><strong>Metriken:</strong> Demographic Parity, Equalized Odds, Predictive Parity.</li><li><strong>Praxis:</strong> Trade-offs transparent machen, Betroffene einbeziehen, kontinuierliches Monitoring.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.564680 +00:00",
      "updated_at": "2025-11-01 13:12:03.564683 +00:00",
      "translation_group": "9e7a004f-fe49-4199-928c-fb10b638ca1f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 18,
    "fields": {
      "term": "Interpretierbarkeit / Erklärbarkeit (XAI)",
      "slug": "interpretierbarkeit-erklarbarkeit-xai",
      "short_definition": "Nachvollziehbarkeit von Modellentscheidungen.",
      "long_definition": "<strong>XAI</strong> macht Modellverhalten für Menschen verständlich. <ul><li><strong>Ansätze:</strong> intrinsisch interpretable Modelle (z.B. Bäume) und Post-hoc-Methoden (SHAP, LIME, Grad-CAM).</li><li><strong>Ziele:</strong> Vertrauen, Fehlerdiagnose, Compliance, Sicherheit.</li><li><strong>Grenzen:</strong> Näherungen können irreführen; Erklärungen müssen auf die Zielgruppe zugeschnitten sein.</li></ul>",
      "category": "Grundlagen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.565148 +00:00",
      "updated_at": "2025-11-01 13:12:03.565151 +00:00",
      "translation_group": "b8eb6f74-1888-442c-b5f0-9b5e8a5c5052"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 19,
    "fields": {
      "term": "Perzeptron",
      "slug": "perzeptron",
      "short_definition": "Einfachstes neuronales Netz mit linearem Entscheidungsgrenzwert.",
      "long_definition": "Das <strong>Perzeptron</strong> ist ein einzelnes künstliches Neuron, das eine gewichtete Summe bildet und per Schwellwert klassifiziert. <ul><li><strong>Eigenschaften:</strong> nur linear trennbare Probleme lösbar.</li><li><strong>Training:</strong> Perzeptron-Lernregel; konvergiert bei linearer Trennbarkeit.</li><li><strong>Bedeutung:</strong> historischer Startpunkt für moderne Netze.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.568393 +00:00",
      "updated_at": "2025-11-01 13:12:03.568399 +00:00",
      "translation_group": "1c9e518a-3553-4ddf-84eb-4b8993b9ed5f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 20,
    "fields": {
      "term": "Feedforward-Netz",
      "slug": "feedforward-netz",
      "short_definition": "Schichten ohne Rückkopplung, Datenfluss nach vorn.",
      "long_definition": "<strong>Feedforward-Netze</strong> (Multilayer Perceptrons) leiten Signale nur von Eingabe zu Ausgabe. <ul><li><strong>Elemente:</strong> lineare Projektionen + nichtlineare Aktivierungen.</li><li><strong>Einsatz:</strong> Klassifikation, Regression, Tabulardaten.</li><li><strong>Aspekte:</strong> Tiefe vs. Breite, Regularisierung, Initialisierung.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.569253 +00:00",
      "updated_at": "2025-11-01 13:12:03.569259 +00:00",
      "translation_group": "cc9faa51-df14-4805-9a9a-1d49c8509509"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 21,
    "fields": {
      "term": "Convolutional Neural Network (CNN)",
      "slug": "convolutional-neural-network-cnn",
      "short_definition": "Architektur für Bilder/Signale mit Faltungsschichten.",
      "long_definition": "<strong>CNNs</strong> nutzen Faltungen und Pooling, um lokale Muster effizient zu erkennen. <ul><li><strong>Stärken:</strong> Translationseinvarianz, Parameterteilung.</li><li><strong>Typische Aufgaben:</strong> Bild-/Videoanalyse, Erkennung, Segmentierung.</li><li><strong>Design:</strong> Kernelgröße, Tiefe, Residualverbindungen.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.570134 +00:00",
      "updated_at": "2025-11-01 13:12:03.570141 +00:00",
      "translation_group": "faee5c9e-8b97-46e9-9d07-c4849e8cadde"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 22,
    "fields": {
      "term": "Recurrent Neural Network (RNN)",
      "slug": "recurrent-neural-network-rnn",
      "short_definition": "Sequenzmodelle mit Rückkopplungen.",
      "long_definition": "<strong>RNNs</strong> verarbeiten Sequenzen schrittweise und teilen Zustände über die Zeit. <ul><li><strong>Varianten:</strong> LSTM, GRU gegen Vanishing/Exploding Gradients.</li><li><strong>Einsatz:</strong> Zeitreihen, Sprache, einfache Dialogsysteme.</li><li><strong>Limits:</strong> lange Abhängigkeiten, serielle Berechnung, Latenz.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.570835 +00:00",
      "updated_at": "2025-11-01 13:12:03.570839 +00:00",
      "translation_group": "5786d46c-9dff-4b7d-b1b3-e67944cf1d39"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 23,
    "fields": {
      "term": "Long Short-Term Memory (LSTM)",
      "slug": "long-short-term-memory-lstm",
      "short_definition": "RNN-Variante mit Gates gegen Vergessen.",
      "long_definition": "<strong>LSTMs</strong> verwenden Eingangs-, Ausgangs- und Vergessens-Gates, um Informationen über lange Zeiträume zu speichern. <ul><li><strong>Vorteil:</strong> stabilere Gradienten als einfache RNNs.</li><li><strong>Einsatz:</strong> Sprache, Musik, Zeitreihenprognosen.</li><li><strong>Beachtung:</strong> höherer Rechenaufwand als GRU-Varianten.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.571403 +00:00",
      "updated_at": "2025-11-01 13:12:03.571406 +00:00",
      "translation_group": "cf37138b-0f6f-46bb-9b62-8963ac94f160"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 24,
    "fields": {
      "term": "Transformer",
      "slug": "transformer",
      "short_definition": "Sequenzmodell mit Attention statt Rekurrenz/Konvolution.",
      "long_definition": "Der <strong>Transformer</strong> nutzt Self-Attention, um Abhängigkeiten unabhängig von ihrer Distanz zu modellieren. <ul><li><strong>Vorteile:</strong> parallele Verarbeitung, skalierbar, State-of-the-Art in NLP/Multimodalität.</li><li><strong>Bauteile:</strong> Multi-Head-Attention, Positionsembeddings, Feedforward-Blöcke, Residual/Norm.</li><li><strong>Aspekte:</strong> Kontextfenster, Rechenbedarf, Optimierungs- und Speichertricks.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.572122 +00:00",
      "updated_at": "2025-11-01 13:12:03.572127 +00:00",
      "translation_group": "a73e0324-e4f1-4f4b-8ebe-62de804d4f64"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 27,
    "fields": {
      "term": "Variational Autoencoder (VAE)",
      "slug": "variational-autoencoder-vae",
      "short_definition": "Probabilistischer Autoencoder für Generierung.",
      "long_definition": "<strong>VAEs</strong> modellieren eine Verteilung im Latentraum und erlauben das Ziehen neuer Stichproben. <ul><li><strong>Kernidee:</strong> Evidence Lower Bound (ELBO) mit Rekonstruktions- und KL-Term.</li><li><strong>Stärken:</strong> glatter Latentraum, probabilistische Deutung.</li><li><strong>Schwächen:</strong> manchmal unschärfere Samples als GANs.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.573854 +00:00",
      "updated_at": "2025-11-01 13:12:03.573857 +00:00",
      "translation_group": "b9b887f6-fe09-4ee1-af22-e558295b3645"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 28,
    "fields": {
      "term": "Generative Adversarial Network (GAN)",
      "slug": "generative-adversarial-network-gan",
      "short_definition": "Generator vs. Diskriminator im Wettstreit.",
      "long_definition": "<strong>GANs</strong> trainieren zwei Netze im Wettstreit: Der Generator erzeugt Daten, der Diskriminator unterscheidet echt/fake. <ul><li><strong>Stärken:</strong> extrem realistische Bilder/Signale möglich.</li><li><strong>Schwierigkeiten:</strong> Trainingsinstabilität, Mode Collapse, Hyperparameter-Sensitivität.</li><li><strong>Varianten:</strong> DCGAN, WGAN, StyleGAN, CycleGAN.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.574358 +00:00",
      "updated_at": "2025-11-01 13:12:03.574361 +00:00",
      "translation_group": "6fb828ff-bcc2-46ab-97fc-6c62e7675b98"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 29,
    "fields": {
      "term": "Large Language Model (LLM)",
      "slug": "large-language-model-llm",
      "short_definition": "Sehr großes Sprachmodell mit Milliarden Parametern.",
      "long_definition": "<strong>LLMs</strong> sind auf Token-Vorhersage trainierte Transformer-Modelle, die Text verstehen und generieren. <ul><li><strong>Fähigkeiten:</strong> Zusammenfassen, Übersetzen, Planen, Code unterstützen.</li><li><strong>Grenzen:</strong> Halluzinationen, Kontextfenster, Aktualität, Sicherheitsrisiken.</li><li><strong>Erweiterungen:</strong> Tool-Use, RAG, Agenten, Feintuning/Adapters.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.574838 +00:00",
      "updated_at": "2025-11-01 13:12:03.574841 +00:00",
      "translation_group": "dd97a805-1743-4934-8427-8b581d856654"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 26,
    "fields": {
      "term": "Autoencoder",
      "slug": "autoencoder",
      "short_definition": "Unüberwachtes Modell zur Kompression/Rekonstruktion.",
      "long_definition": "<strong>Autoencoder</strong> lernen eine latente Repräsentation, indem sie Eingaben rekonstruieren. <ul><li><strong>Nutzung:</strong> Dimensionsreduktion, Denoising, Vortraining.</li><li><strong>Varianten:</strong> Convolutional, Denoising, Sparse, Variational (VAE).</li><li><strong>Beachtung:</strong> Latentraumqualität, Rekonstruktionsverlust, Überanpassung.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.573297 +00:00",
      "updated_at": "2025-11-01 13:12:03.573301 +00:00",
      "translation_group": "0ed43038-c392-4d1e-a721-1be2a7b0e233"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 30,
    "fields": {
      "term": "Multimodales Modell",
      "slug": "multimodales-modell",
      "short_definition": "Verarbeitet mehrere Modalitäten (Text, Bild, Audio).",
      "long_definition": "<strong>Multimodale Modelle</strong> koppeln Repräsentationen aus verschiedenen Datentypen. <ul><li><strong>Architekturen:</strong> späte/ frühe Fusion, Cross-Attention, gemeinsame Embedding-Räume.</li><li><strong>Einsatz:</strong> Bildbeschreibung, visuelle Frage-Antwort, Audio-Video-Analyse.</li><li><strong>Herausforderungen:</strong> Ausrichtung der Modalitäten, Daten/Annotationen, Rechenkosten.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.575570 +00:00",
      "updated_at": "2025-11-01 13:12:03.575575 +00:00",
      "translation_group": "c92b1edb-5c58-4b35-a951-4af9a011717d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 31,
    "fields": {
      "term": "Embedding",
      "slug": "embedding",
      "short_definition": "Numerische Vektordarstellung von Tokens/Objekten.",
      "long_definition": "<strong>Embeddings</strong> projizieren Wörter, Sätze, Bilder oder Items in dichte Vektorräume, in denen semantisch Ähnliches nahe liegt. <ul><li><strong>Verwendung:</strong> Suche/Retrieval, Clustering, Recommender, Features für Modelle.</li><li><strong>Training:</strong> selbstüberwacht (z.B. Contrastive Learning) oder mit Labels.</li><li><strong>Praxis:</strong> Dimensionswahl, Distanzmaß, Normalisierung, Drift-Monitoring.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.576119 +00:00",
      "updated_at": "2025-11-01 13:12:03.576122 +00:00",
      "translation_group": "a0e1709f-7697-400b-8245-3621af16416a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 32,
    "fields": {
      "term": "Tokenisierung",
      "slug": "tokenisierung",
      "short_definition": "Zerlegung von Text in Tokens (Einheiten).",
      "long_definition": "<strong>Tokenisierung</strong> zerlegt Text in Einheiten (z.B. Subwörter), die das Modell verarbeitet. <ul><li><strong>Verfahren:</strong> BPE, WordPiece, Unigram; sprach-/domänenspezifische Besonderheiten.</li><li><strong>Einfluss:</strong> Kontextlänge, OOV-Handhabung, Effizienz.</li><li><strong>Praxis:</strong> konsistente Preprocessing-Pipelines, Versionierung des Vokabulars.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.577145 +00:00",
      "updated_at": "2025-11-01 13:12:03.577152 +00:00",
      "translation_group": "5d9fff89-2daa-443f-81b2-078aa87597c6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 33,
    "fields": {
      "term": "Kontextfenster",
      "slug": "kontextfenster",
      "short_definition": "Maximale Anzahl Tokens, die ein Modell auf einmal nutzt.",
      "long_definition": "Das <strong>Kontextfenster</strong> begrenzt, wie viele Tokens aus Eingabe/Verlauf ein Modell berücksichtigen kann. <ul><li><strong>Auswirkungen:</strong> Gedächtnis über lange Dialoge, Qualität langer Antworten.</li><li><strong>Trade-offs:</strong> Speicher/Compute vs. Reichweite; Long-Context-Tricks (z.B. Sliding Window, Sparse Attention).</li><li><strong>Praxis:</strong> Chunking, Retrieval (RAG), Zusammenfassungen, strukturierte Prompts.</li></ul>",
      "category": "Modelle & Architekturen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.577984 +00:00",
      "updated_at": "2025-11-01 13:12:03.577988 +00:00",
      "translation_group": "9f117df2-4d13-498c-ac8d-4b4b682e67fe"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 34,
    "fields": {
      "term": "Natural Language Processing (NLP)",
      "slug": "natural-language-processing-nlp",
      "short_definition": "Verarbeitung und Analyse menschlicher Sprache durch Computer.",
      "long_definition": "<strong>Natural Language Processing (NLP)</strong> umfasst alle Methoden, mit denen Computer Sprache verstehen, analysieren oder erzeugen. Es kombiniert Linguistik, Statistik und maschinelles Lernen. <ul><li><strong>Aufgaben:</strong> Textklassifikation, Übersetzung, Zusammenfassung, Frage-Antwort-Systeme.</li><li><strong>Techniken:</strong> Tokenisierung, Embeddings, Transformer-Modelle.</li><li><strong>Ziel:</strong> Maschinen sollen natürliche Sprache sinnvoll interpretieren und produzieren können.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.608839 +00:00",
      "updated_at": "2025-11-01 13:12:03.608845 +00:00",
      "translation_group": "43e81eb1-0c34-4095-90fd-38aeafdca49e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 35,
    "fields": {
      "term": "Natural Language Understanding (NLU)",
      "slug": "natural-language-understanding-nlu",
      "short_definition": "Semantisches Verstehen von Bedeutung und Intention.",
      "long_definition": "<strong>Natural Language Understanding (NLU)</strong> konzentriert sich auf das Erfassen der Bedeutung, Absicht und Struktur eines Textes. <ul><li><strong>Beispiele:</strong> Erkennen von Benutzerintentionen in Chatbots, Extraktion von Entitäten.</li><li><strong>Methoden:</strong> Syntaxanalyse, Semantikmodelle, Intent-Erkennung.</li><li><strong>Ziel:</strong> Maschinen sollen den Sinn und Kontext menschlicher Sprache erfassen.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.609703 +00:00",
      "updated_at": "2025-11-01 13:12:03.609707 +00:00",
      "translation_group": "4266bb4d-6a11-415f-9a26-42b532958c35"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 36,
    "fields": {
      "term": "Natural Language Generation (NLG)",
      "slug": "natural-language-generation-nlg",
      "short_definition": "Automatische Erzeugung verständlicher Texte.",
      "long_definition": "<strong>Natural Language Generation (NLG)</strong> beschreibt die Fähigkeit von Computern, aus Daten oder abstrakten Informationen automatisch fließende Sprache zu erzeugen. <ul><li><strong>Anwendungen:</strong> Berichtsgenerierung, Chatbots, Textzusammenfassungen.</li><li><strong>Modelle:</strong> Sequenz-zu-Sequenz-Netze, Transformer.</li><li><strong>Herausforderung:</strong> Kohärenz, Faktentreue, Stilsteuerung.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.610906 +00:00",
      "updated_at": "2025-11-01 13:12:03.610941 +00:00",
      "translation_group": "19c37c81-ae8e-4916-b062-a8a00704b56c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 37,
    "fields": {
      "term": "Named Entity Recognition (NER)",
      "slug": "named-entity-recognition-ner",
      "short_definition": "Erkennung benannter Entitäten (Person, Ort, Organisation).",
      "long_definition": "<strong>Named Entity Recognition (NER)</strong> identifiziert und klassifiziert Eigennamen in Texten, etwa Personen, Orte oder Unternehmen. <ul><li><strong>Nutzen:</strong> Strukturierung unstrukturierter Texte für Suche oder Analyse.</li><li><strong>Beispiele:</strong> Extraktion von Firmennamen in Nachrichtenartikeln.</li><li><strong>Verfahren:</strong> Sequence Labeling, CRFs, BiLSTM-CRF, Transformer-Modelle.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.611714 +00:00",
      "updated_at": "2025-11-01 13:12:03.611718 +00:00",
      "translation_group": "c34c4b8d-4567-46d9-b38d-a21e5df3e545"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 38,
    "fields": {
      "term": "Sentimentanalyse",
      "slug": "sentimentanalyse",
      "short_definition": "Bewertung von Stimmung und Meinung in Texten.",
      "long_definition": "<strong>Sentimentanalyse</strong> erkennt emotionale oder bewertende Inhalte in Texten, z.B. ob Aussagen positiv, negativ oder neutral sind. <ul><li><strong>Anwendungsgebiete:</strong> Produktbewertungen, Social Media, Marktforschung.</li><li><strong>Techniken:</strong> Wortlisten, maschinelles Lernen, Transformer-basierte Modelle.</li><li><strong>Herausforderungen:</strong> Ironie, Kontextabhängigkeit, Mehrdeutigkeit.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.612580 +00:00",
      "updated_at": "2025-11-01 13:12:03.612620 +00:00",
      "translation_group": "99666f31-9423-4f44-b9b5-5191dee4db2f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 39,
    "fields": {
      "term": "Retrieval-Augmented Generation (RAG)",
      "slug": "retrieval-augmented-generation-rag",
      "short_definition": "Kombiniert Informationssuche mit Texterzeugung.",
      "long_definition": "<strong>Retrieval-Augmented Generation (RAG)</strong> verbindet eine Suchkomponente mit einem Sprachmodell, um faktenbasiert Texte zu erzeugen. <ul><li><strong>Funktionsweise:</strong> Relevante Dokumente werden abgerufen und als Kontext in die Generierung eingespeist.</li><li><strong>Vorteil:</strong> geringere Halluzinationsrate, aktuellere Antworten.</li><li><strong>Beispiele:</strong> Wissensbasierte Chatbots, Dokumenten-Q&A-Systeme.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.613476 +00:00",
      "updated_at": "2025-11-01 13:12:03.613481 +00:00",
      "translation_group": "21b142ce-3d7e-4ac9-88d2-2e03a44dc1d0"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 40,
    "fields": {
      "term": "Prompt Engineering",
      "slug": "prompt-engineering",
      "short_definition": "Gestaltung effektiver Eingaben für Sprachmodelle.",
      "long_definition": "<strong>Prompt Engineering</strong> bezeichnet die Kunst, Eingaben für Sprachmodelle so zu formulieren, dass sie präzise, relevante und konsistente Ergebnisse liefern. <ul><li><strong>Techniken:</strong> Zero-Shot, Few-Shot, Chain-of-Thought, Rollenbeschreibungen.</li><li><strong>Ziel:</strong> Kontrolle über Stil, Struktur und Genauigkeit der Antworten.</li><li><strong>Praxis:</strong> Iteratives Testen und systematisches Prompt-Design.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.614114 +00:00",
      "updated_at": "2025-11-01 13:12:03.614118 +00:00",
      "translation_group": "0f086a5f-764c-4b90-8d5f-ca298d3ba8ee"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 41,
    "fields": {
      "term": "Few-Shot Learning",
      "slug": "few-shot-learning",
      "short_definition": "Lernen aus wenigen Beispielen.",
      "long_definition": "<strong>Few-Shot Learning</strong> ermöglicht es einem Modell, neue Aufgaben mit nur wenigen Beispielen zu lösen. Das Modell nutzt sein vorhandenes Wissen und passt es kontextuell an. <ul><li><strong>Beispiele:</strong> Klassifizieren neuer Kategorien, Texttransformationen.</li><li><strong>Methoden:</strong> In-Context Learning, Feintuning, Meta-Learning.</li><li><strong>Nutzen:</strong> Effizienz bei begrenzten Daten.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.614655 +00:00",
      "updated_at": "2025-11-01 13:12:03.614658 +00:00",
      "translation_group": "72711f26-5788-42d7-9f92-b77a888343d4"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 42,
    "fields": {
      "term": "Zero-Shot Learning",
      "slug": "zero-shot-learning",
      "short_definition": "Lösen neuer Aufgaben ohne Trainingsbeispiele.",
      "long_definition": "<strong>Zero-Shot Learning</strong> erlaubt es einem Modell, Aufgaben anhand einer textuellen Beschreibung zu bewältigen, ohne zuvor Beispiele gesehen zu haben. <ul><li><strong>Beispiel:</strong> Ein Modell beantwortet Fragen zu einem neuen Thema nur mithilfe seiner Weltkenntnis.</li><li><strong>Vorteil:</strong> hohe Flexibilität, keine Datensammlung nötig.</li><li><strong>Grenzen:</strong> Fehler bei unklaren Instruktionen oder unbekannten Konzepten.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.615149 +00:00",
      "updated_at": "2025-11-01 13:12:03.615152 +00:00",
      "translation_group": "50c6c96b-cdd1-4f11-b99d-52e7f71412c1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 43,
    "fields": {
      "term": "Token (NLP)",
      "slug": "token-nlp",
      "short_definition": "Kleinste Verarbeitungseinheit für Sprachmodelle.",
      "long_definition": "Ein <strong>Token</strong> ist die kleinste Verarbeitungseinheit, die ein Sprachmodell versteht – meist ein Wortteil oder Symbol. <ul><li><strong>Arten:</strong> Wörter, Subwörter, Satzzeichen.</li><li><strong>Einfluss:</strong> Tokenisierung bestimmt Kontextlänge und Genauigkeit.</li><li><strong>Beispiel:</strong> „ChatGPT“ kann in die Tokens „Chat“ und „GPT“ zerlegt werden.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.615767 +00:00",
      "updated_at": "2025-11-01 13:12:03.615772 +00:00",
      "translation_group": "cd960ca1-5e68-4c24-a836-c076ad57de25"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 44,
    "fields": {
      "term": "Temperature (Sampling)",
      "slug": "temperature-sampling",
      "short_definition": "Parameter, der die Zufälligkeit der Ausgabe steuert.",
      "long_definition": "<strong>Temperature</strong> ist ein Hyperparameter beim Sampling, der beeinflusst, wie zufällig oder deterministisch ein Sprachmodell antwortet. <ul><li><strong>Wirkung:</strong> Hohe Werte → kreativ/variabel, niedrige Werte → präzise/stabil.</li><li><strong>Verwendung:</strong> bei Textgenerierung, Dialogsystemen, Kreativanwendungen.</li><li><strong>Tipp:</strong> Typisch sind Werte zwischen 0.2 und 0.9 je nach gewünschtem Stil.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.616378 +00:00",
      "updated_at": "2025-11-01 13:12:03.616381 +00:00",
      "translation_group": "f4f11663-5207-4779-b72f-b01da82c3c1f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 45,
    "fields": {
      "term": "Systemprompt",
      "slug": "systemprompt",
      "short_definition": "Grundanweisung, die Verhalten und Ton eines Modells steuert.",
      "long_definition": "Der <strong>Systemprompt</strong> ist die anfängliche Instruktion, die definiert, wie ein Sprachmodell generell reagieren soll. Er legt Rolle, Tonfall und Grenzen fest. <ul><li><strong>Beispiele:</strong> „Du bist ein hilfreicher Assistent.“ oder „Antworte nur mit Fakten.“</li><li><strong>Ziel:</strong> Konsistenz und gewünschte Persönlichkeit im Dialog.</li><li><strong>Praxis:</strong> Systemprompts werden häufig in Chatbots oder APIs konfiguriert.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.616891 +00:00",
      "updated_at": "2025-11-01 13:12:03.616894 +00:00",
      "translation_group": "f98987c2-a9d5-48ee-bfd9-e84d4b46c355"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 46,
    "fields": {
      "term": "Halluzination",
      "slug": "halluzination",
      "short_definition": "Falschinformationen, die ein Modell plausibel darstellt.",
      "long_definition": "<strong>Halluzination</strong> bezeichnet die Tendenz eines Sprachmodells, erfundene oder falsche Informationen zu präsentieren, als wären sie wahr. <ul><li><strong>Ursachen:</strong> fehlender Kontext, unzureichende Trainingsdaten, probabilistische Generierung.</li><li><strong>Risiken:</strong> Fehlinformation, Vertrauensverlust, rechtliche Folgen.</li><li><strong>Strategien:</strong> RAG, Quellenzitate, Validierungsschritte und Faktenchecks.</li></ul>",
      "category": "NLP & Sprachmodelle",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.617556 +00:00",
      "updated_at": "2025-11-01 13:12:03.617561 +00:00",
      "translation_group": "979622eb-3de6-4ec6-adcf-27345df117ff"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 47,
    "fields": {
      "term": "Computer Vision",
      "slug": "computer-vision",
      "short_definition": "Automatisierte Bild- und Videoverarbeitung.",
      "long_definition": "<strong>Computer Vision</strong> bezeichnet das Teilgebiet der künstlichen Intelligenz, das Computern beibringt, digitale Bilder und Videos zu interpretieren. Systeme analysieren visuelle Daten, um Objekte, Personen, Bewegungen oder Szenen zu erkennen. <ul><li><strong>Anwendungen:</strong> Gesichtserkennung, Verkehrsüberwachung, Qualitätskontrolle, medizinische Bildanalyse.</li><li><strong>Ziel:</strong> Maschinen sollen die visuelle Wahrnehmung des Menschen nachbilden oder ergänzen.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.622106 +00:00",
      "updated_at": "2025-11-01 13:12:03.622113 +00:00",
      "translation_group": "42e525c1-d368-46ba-bcd2-aa0bcf847e0b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 48,
    "fields": {
      "term": "Bildklassifikation",
      "slug": "bildklassifikation",
      "short_definition": "Zuordnung eines Labels zu einem Bild.",
      "long_definition": "<strong>Bildklassifikation</strong> ist ein Verfahren, bei dem ein Modell ein vollständiges Bild einer oder mehreren vordefinierten Klassen zuordnet, etwa „Katze“ oder „Auto“. Dazu werden neuronale Netze wie Convolutional Neural Networks (CNNs) trainiert, um charakteristische Muster und Strukturen zu erkennen. <ul><li><strong>Beispiele:</strong> Erkennung von Hautkrankheiten in Fotos, Kategorisierung von Produktbildern.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.624230 +00:00",
      "updated_at": "2025-11-01 13:12:03.624237 +00:00",
      "translation_group": "58aacbda-e17d-4646-99a0-3ecb61c91b69"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 49,
    "fields": {
      "term": "Objekterkennung",
      "slug": "objekterkennung",
      "short_definition": "Lokalisierung und Klassifikation von Objekten.",
      "long_definition": "<strong>Objekterkennung</strong> erweitert die Bildklassifikation um die Lokalisierung. Das Modell erkennt, welche Objekte sich im Bild befinden, und markiert sie meist mit sogenannten Bounding Boxes. <ul><li><strong>Beispiele:</strong> Erkennung von Fußgängern in autonomen Fahrzeugen oder Waren in Lagerrobotern.</li><li><strong>Typische Modelle:</strong> YOLO, Faster R-CNN, SSD.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.625029 +00:00",
      "updated_at": "2025-11-01 13:12:03.625033 +00:00",
      "translation_group": "e70a0ac6-2abb-4f0f-b14a-c85d57b08510"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 50,
    "fields": {
      "term": "Bildsegmentierung",
      "slug": "bildsegmentierung",
      "short_definition": "Pixelgenaue Aufteilung in Regionen/Klassen.",
      "long_definition": "<strong>Bildsegmentierung</strong> teilt ein Bild in sinnvolle Bereiche ein, sodass jedem Pixel eine bestimmte Klasse zugeordnet wird – beispielsweise Straße, Gebäude oder Person. Sie wird häufig in Medizin, Robotik und autonomem Fahren verwendet. <ul><li><strong>Arten:</strong> Semantische, Instanz- und Panoptische Segmentierung.</li><li><strong>Ziel:</strong> Präzise Erkennung von Formen und Strukturen.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.625622 +00:00",
      "updated_at": "2025-11-01 13:12:03.625625 +00:00",
      "translation_group": "689bc7e6-65e4-4895-ae95-1d0287ff8f23"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 51,
    "fields": {
      "term": "Text-to-Image",
      "slug": "text-to-image",
      "short_definition": "Bilderzeugung aus Textbeschreibungen.",
      "long_definition": "<strong>Text-to-Image</strong> bezeichnet generative Modelle, die aus einer Textbeschreibung („Prompt“) ein neues, realistisches Bild erzeugen. Moderne Ansätze wie DALL·E, Midjourney oder Stable Diffusion nutzen Diffusionsmodelle oder Transformer-Netzwerke. <ul><li><strong>Beispiel:</strong> „Ein Fuchs mit Sonnenbrille im Stil von Van Gogh.“</li><li><strong>Hinweis:</strong> Erfordert sorgfältige Promptgestaltung und Beachtung von Urheberrechten.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.626137 +00:00",
      "updated_at": "2025-11-01 13:12:03.626140 +00:00",
      "translation_group": "1b08f35a-7071-44b0-9a54-c6f231f09d8f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 52,
    "fields": {
      "term": "Deepfake",
      "slug": "deepfake",
      "short_definition": "Realistisch manipulierte Medien mit KI.",
      "long_definition": "<strong>Deepfakes</strong> sind durch KI erzeugte oder manipulierte Bilder, Videos oder Audiodateien, die echte Personen täuschend echt imitieren. Sie nutzen Deep-Learning-Techniken wie Generative Adversarial Networks (GANs). <ul><li><strong>Anwendungsfelder:</strong> Unterhaltung, Filmproduktion, aber auch Desinformation und Identitätsmissbrauch.</li><li><strong>Risiken:</strong> Datenschutz, Missbrauch, Verlust von Vertrauen in digitale Medien.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.626915 +00:00",
      "updated_at": "2025-11-01 13:12:03.626968 +00:00",
      "translation_group": "9e19fb83-9e80-4775-8fb3-a5e801be6c1b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 53,
    "fields": {
      "term": "Text-to-Video",
      "slug": "text-to-video",
      "short_definition": "Videogenerierung aus Text.",
      "long_definition": "<strong>Text-to-Video</strong> beschreibt die Fähigkeit von KI-Systemen, aus Textbeschreibungen kurze Videosequenzen zu erzeugen. Dabei werden Bild-zu-Bild-Übergänge modelliert, um Bewegung und zeitliche Dynamik zu simulieren. <ul><li><strong>Beispiel:</strong> „Ein Sonnenuntergang über dem Meer mit einer fliegenden Möwe.“</li><li><strong>Bekannte Modelle:</strong> Runway Gen-2, Pika Labs, Sora (OpenAI).</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.628164 +00:00",
      "updated_at": "2025-11-01 13:12:03.628170 +00:00",
      "translation_group": "d9bc0d0c-8715-481f-82c4-0e76ed158864"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 55,
    "fields": {
      "term": "Spracherkennung (ASR)",
      "slug": "spracherkennung-asr",
      "short_definition": "Automatische Umwandlung von Sprache in Text.",
      "long_definition": "<strong>Automatic Speech Recognition (ASR)</strong> wandelt gesprochene Sprache mithilfe akustischer und linguistischer Modelle in Text um. Moderne Systeme nutzen Deep-Learning-Modelle wie Transformer oder Recurrent Neural Networks. <ul><li><strong>Beispiele:</strong> Diktierfunktionen, Sprachsteuerung, Transkription von Meetings.</li><li><strong>Herausforderungen:</strong> Dialekte, Hintergrundgeräusche, Mehrsprachigkeit.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.629585 +00:00",
      "updated_at": "2025-11-01 13:12:03.629589 +00:00",
      "translation_group": "85d70715-d4db-4a48-b989-cd55d33926f9"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 56,
    "fields": {
      "term": "Musikgenerierung",
      "slug": "musikgenerierung",
      "short_definition": "Erzeugung neuer Musik durch Modelle.",
      "long_definition": "<strong>Musikgenerierung</strong> bezeichnet die automatische Komposition von Melodien, Harmonien oder ganzen Musikstücken durch KI. Sie basiert auf der Analyse bestehender Musikdaten und kann Stil, Stimmung oder Tempo berücksichtigen. <ul><li><strong>Beispiele:</strong> Hintergrundmusik für Spiele, personalisierte Playlists, KI-Komponisten wie AIVA.</li><li><strong>Risiken:</strong> Urheberrechtsfragen und kreative Authentizität.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.630113 +00:00",
      "updated_at": "2025-11-01 13:12:03.630116 +00:00",
      "translation_group": "5094e3f2-d787-4729-a7ac-1c48e310d680"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 57,
    "fields": {
      "term": "Style Transfer",
      "slug": "style-transfer",
      "short_definition": "Überträgt Stil eines Bildes auf ein anderes.",
      "long_definition": "<strong>Style Transfer</strong> ist eine Technik, bei der der künstlerische Stil eines Bildes (z. B. Gemälde von Van Gogh) auf den Inhalt eines anderen Bildes übertragen wird. Dadurch entsteht ein neues Bild, das Inhalt und Stil kombiniert. <ul><li><strong>Technik:</strong> Nutzung neuronaler Netze, insbesondere Convolutional Neural Networks.</li><li><strong>Anwendungen:</strong> Kunst, Design, Filter in Foto-Apps.</li></ul>",
      "category": "Bild/Audio/Video",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.630592 +00:00",
      "updated_at": "2025-11-01 13:12:03.630594 +00:00",
      "translation_group": "5d0d2b1f-127d-4425-bc93-d4daa9ffa8ac"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 58,
    "fields": {
      "term": "Empfehlungssystem",
      "slug": "empfehlungssystem",
      "short_definition": "Personalisierte Vorschläge auf Basis von Nutzerdaten.",
      "long_definition": "<strong>Empfehlungssysteme</strong> analysieren das Verhalten, die Präferenzen und Kontexte von Nutzern, um personalisierte Vorschläge zu machen – etwa für Filme, Produkte oder Inhalte. Sie basieren häufig auf kollaborativem Filtern, Inhaltsanalyse oder hybriden Ansätzen. <ul><li><strong>Beispiele:</strong> Netflix-Empfehlungen, Amazon-Produktempfehlungen, Musikvorschläge in Spotify.</li><li><strong>Ziel:</strong> Nutzererlebnis verbessern und Relevanz steigern.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.644738 +00:00",
      "updated_at": "2025-11-01 13:12:03.644745 +00:00",
      "translation_group": "4f43c429-0ebb-4e35-a932-8eb3bc05aaf2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 59,
    "fields": {
      "term": "Autonomes Fahren",
      "slug": "autonomes-fahren",
      "short_definition": "Fahrzeuge mit Umfeldwahrnehmung und Planung.",
      "long_definition": "<strong>Autonomes Fahren</strong> beschreibt Fahrzeuge, die ihre Umgebung mithilfe von Sensoren, Kameras und KI wahrnehmen und eigenständig Fahrentscheidungen treffen können. Das System kombiniert Wahrnehmung, Entscheidungslogik und Steuerung in Echtzeit. <ul><li><strong>Technologien:</strong> Computer Vision, Sensorfusion, Deep Reinforcement Learning.</li><li><strong>Ziele:</strong> Sicherheit, Komfort, Reduktion menschlicher Fehler.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.645790 +00:00",
      "updated_at": "2025-11-01 13:12:03.645798 +00:00",
      "translation_group": "103fba6c-3a8f-40df-b332-9e3706b2c84e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 60,
    "fields": {
      "term": "Robotik",
      "slug": "robotik",
      "short_definition": "Interaktive Maschinen mit Wahrnehmung und Steuerung.",
      "long_definition": "<strong>Robotik</strong> verbindet künstliche Intelligenz mit Mechanik und Steuerungstechnik, um Maschinen zu entwickeln, die Aufgaben selbstständig oder kooperativ mit Menschen ausführen. <ul><li><strong>Anwendungsfelder:</strong> Industrieautomation, Servicerobotik, Medizinrobotik, Logistik.</li><li><strong>KI-Rolle:</strong> Wahrnehmung, Entscheidungsfindung und adaptive Bewegung.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.646822 +00:00",
      "updated_at": "2025-11-01 13:12:03.646827 +00:00",
      "translation_group": "031bffae-2649-40db-94e9-d3989706e288"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 61,
    "fields": {
      "term": "Medizinische Diagnostik",
      "slug": "medizinische-diagnostik",
      "short_definition": "Unterstützung bei Befundung und Risikoabschätzung.",
      "long_definition": "<strong>Medizinische Diagnostik mit KI</strong> unterstützt Ärztinnen und Ärzte bei der Erkennung von Krankheiten, der Analyse medizinischer Bilder und der Einschätzung von Risiken. <ul><li><strong>Beispiele:</strong> Erkennung von Tumoren in Röntgenbildern, Analyse von EKGs oder Hautbildern.</li><li><strong>Vorteile:</strong> Schnellere Diagnosen, höhere Genauigkeit, bessere Vorsorge.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.647611 +00:00",
      "updated_at": "2025-11-01 13:12:03.647615 +00:00",
      "translation_group": "29151851-c6d9-4742-95f4-0cd07e718d08"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 62,
    "fields": {
      "term": "Betrugserkennung",
      "slug": "betrugserkennung",
      "short_definition": "Erkennung verdächtiger Muster in Transaktionen.",
      "long_definition": "<strong>Betrugserkennung</strong> (Fraud Detection) nutzt KI-Modelle, um ungewöhnliche oder betrügerische Aktivitäten in Finanz-, Versicherungs- oder E-Commerce-Systemen zu erkennen. Die Systeme lernen typische Muster und weichen bei Abweichungen Alarm aus. <ul><li><strong>Beispiele:</strong> Kreditkartenbetrug, Versicherungsbetrug, Identitätsmissbrauch.</li><li><strong>Techniken:</strong> Anomalieerkennung, Clustering, neuronale Netze.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.648325 +00:00",
      "updated_at": "2025-11-01 13:12:03.648329 +00:00",
      "translation_group": "07cad714-b083-4632-a308-5a5213f5c0e5"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 63,
    "fields": {
      "term": "Kundensupport-Chatbot",
      "slug": "kundensupport-chatbot",
      "short_definition": "Automatisierte Dialogsysteme im Service.",
      "long_definition": "<strong>Kundensupport-Chatbots</strong> führen automatisch Gespräche mit Nutzerinnen und Nutzern, um häufige Fragen zu beantworten oder Probleme zu lösen. Sie verwenden Natural Language Processing (NLP), um Eingaben zu verstehen und passende Antworten zu geben. <ul><li><strong>Beispiele:</strong> Support-Chat auf Webseiten, Bestellstatus-Auskunft, FAQ-Automatisierung.</li><li><strong>Ziel:</strong> 24/7-Unterstützung und Entlastung menschlicher Support-Teams.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.648924 +00:00",
      "updated_at": "2025-11-01 13:12:03.648933 +00:00",
      "translation_group": "b892f282-b6fc-4553-9293-71e7612def5a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 64,
    "fields": {
      "term": "Übersetzungssystem",
      "slug": "ubersetzungssystem",
      "short_definition": "Automatische Übertragung von Text/Sprache.",
      "long_definition": "<strong>Maschinelle Übersetzung</strong> wandelt Texte oder gesprochene Sprache mithilfe neuronaler Netzwerke in eine andere Sprache um. Moderne Systeme berücksichtigen Kontext, Grammatik und Stil, um natürlich klingende Übersetzungen zu erzeugen. <ul><li><strong>Beispiele:</strong> DeepL, Google Translate, Speech-to-Text-Dolmetscher.</li><li><strong>Technologien:</strong> Transformer-Modelle, Attention-Mechanismen.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.649482 +00:00",
      "updated_at": "2025-11-01 13:12:03.649485 +00:00",
      "translation_group": "ce304152-e446-41d4-a28f-8aeb27f631b8"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 65,
    "fields": {
      "term": "Text-/Bildgenerierung",
      "slug": "text-bildgenerierung",
      "short_definition": "Content-Erzeugung für Marketing/Kreativarbeit.",
      "long_definition": "<strong>Text- und Bildgenerierung</strong> umfasst KI-Systeme, die eigenständig kreative Inhalte wie Texte, Bilder oder Videos erstellen. Diese Modelle lernen aus riesigen Datensätzen und erzeugen neue, stilistisch ähnliche Ergebnisse. <ul><li><strong>Beispiele:</strong> Blogartikel, Social-Media-Posts, Illustrationen, Kampagnenbilder.</li><li><strong>Bekannte Modelle:</strong> GPT, DALL·E, Stable Diffusion.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.650003 +00:00",
      "updated_at": "2025-11-01 13:12:03.650006 +00:00",
      "translation_group": "7ac152b4-35d0-4299-824b-7e24de49a1a7"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 66,
    "fields": {
      "term": "Codegenerierung",
      "slug": "codegenerierung",
      "short_definition": "Programmcode aus Beschreibungen oder Beispielen.",
      "long_definition": "<strong>Codegenerierung</strong> nutzt KI, um Programmcode aus natürlichen Sprachbeschreibungen, Beispielen oder unvollständigen Funktionen zu erzeugen. Diese Systeme beschleunigen Entwicklungsprozesse und helfen beim Debugging oder Refactoring. <ul><li><strong>Beispiele:</strong> GitHub Copilot, ChatGPT Code Interpreter, Amazon CodeWhisperer.</li><li><strong>Nutzen:</strong> Produktivitätssteigerung und Qualitätsverbesserung.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.650501 +00:00",
      "updated_at": "2025-11-01 13:12:03.650504 +00:00",
      "translation_group": "246d0573-d62c-4b38-a922-e6c2afbb8367"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 67,
    "fields": {
      "term": "Predictive Maintenance",
      "slug": "predictive-maintenance",
      "short_definition": "Vorausschauende Wartung basierend auf Sensordaten.",
      "long_definition": "<strong>Predictive Maintenance</strong> (vorausschauende Wartung) nutzt Sensordaten und KI-Modelle, um den Zustand von Maschinen zu überwachen und Ausfälle frühzeitig vorherzusagen. Dadurch können Wartungsarbeiten geplant und Stillstandzeiten reduziert werden. <ul><li><strong>Beispiele:</strong> Industrieanlagen, Windkraftanlagen, Fahrzeugflotten.</li><li><strong>Technologien:</strong> Zeitreihenanalyse, Anomalieerkennung, Machine Learning.</li></ul>",
      "category": "Anwendungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.651198 +00:00",
      "updated_at": "2025-11-01 13:12:03.651204 +00:00",
      "translation_group": "de86f93c-e12f-47b5-8c78-a8474fe53bcf"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 68,
    "fields": {
      "term": "Datenannotation",
      "slug": "datenannotation",
      "short_definition": "Beschriftung von Daten für das Training.",
      "long_definition": "<strong>Datenannotation</strong> ist der Prozess, bei dem Rohdaten – etwa Bilder, Texte oder Audio – mit aussagekräftigen Labels versehen werden. Diese Labels sind notwendig, um Modelle im überwachten Lernen zu trainieren. <ul><li><strong>Arten:</strong> Klassifikationslabels, Bounding Boxes, Transkriptionen, Sentiment-Tags.</li><li><strong>Wichtig:</strong> Qualität und Konsistenz der Annotation beeinflussen direkt die Genauigkeit des Modells.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.678828 +00:00",
      "updated_at": "2025-11-01 13:12:03.678833 +00:00",
      "translation_group": "f7e1c833-8825-4e4d-b8bc-9f03af6b038c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 69,
    "fields": {
      "term": "Datenqualität",
      "slug": "datenqualitat",
      "short_definition": "Vollständigkeit, Korrektheit, Relevanz von Daten.",
      "long_definition": "<strong>Datenqualität</strong> beschreibt, wie zuverlässig und repräsentativ Trainingsdaten sind. Hohe Qualität bedeutet korrekte, vollständige und nicht verzerrte Daten. <ul><li><strong>Kriterien:</strong> Genauigkeit, Konsistenz, Aktualität, Vollständigkeit, Fairness.</li><li><strong>Einfluss:</strong> Schlechte Daten führen zu fehlerhaften oder voreingenommenen Modellen.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.679843 +00:00",
      "updated_at": "2025-11-01 13:12:03.679847 +00:00",
      "translation_group": "2542ba79-b816-4637-ba62-dfa92646b476"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 70,
    "fields": {
      "term": "Feature Engineering",
      "slug": "feature-engineering",
      "short_definition": "Gezielte Merkmalsbildung aus Rohdaten.",
      "long_definition": "<strong>Feature Engineering</strong> bezeichnet die Auswahl, Transformation oder Kombination von Rohdaten in aussagekräftige Eingabemerkmale für maschinelles Lernen. <ul><li><strong>Ziel:</strong> Modelle mit relevanten, informativen Variablen zu versorgen.</li><li><strong>Beispiele:</strong> Extraktion statistischer Kennzahlen, Skalierung, One-Hot-Encoding, PCA.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.680461 +00:00",
      "updated_at": "2025-11-01 13:12:03.680464 +00:00",
      "translation_group": "44e6c2d5-541c-43e2-b07c-9cfc21c45649"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 71,
    "fields": {
      "term": "Batch / Epoch",
      "slug": "batch-epoch",
      "short_definition": "Minibatches & Trainingsdurchläufe über Datensatz.",
      "long_definition": "Ein <strong>Batch</strong> ist eine Teilmenge des Trainingsdatensatzes, die gleichzeitig verarbeitet wird. Eine <strong>Epoch</strong> beschreibt einen vollständigen Durchlauf durch den gesamten Datensatz. <ul><li><strong>Nutzen:</strong> Reduzierung von Speicherbedarf und stabilere Gradientenaktualisierung.</li><li><strong>Typisch:</strong> Mehrere Epochen werden benötigt, um Konvergenz zu erreichen.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.680990 +00:00",
      "updated_at": "2025-11-01 13:12:03.680993 +00:00",
      "translation_group": "96711e37-33de-46d3-ab68-9661446c2bff"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 72,
    "fields": {
      "term": "Loss Function",
      "slug": "loss-function",
      "short_definition": "Zielfunktion, die Trainingsfehler misst.",
      "long_definition": "<strong>Loss-Funktionen</strong> bewerten, wie stark die Vorhersagen eines Modells von den tatsächlichen Werten abweichen. Das Ziel des Trainings ist, diesen Fehler zu minimieren. <ul><li><strong>Beispiele:</strong> Mean Squared Error (MSE), Cross-Entropy, Hinge Loss.</li><li><strong>Bedeutung:</strong> Die Wahl der Loss-Funktion beeinflusst Lernverhalten und Genauigkeit stark.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.681492 +00:00",
      "updated_at": "2025-11-01 13:12:03.681495 +00:00",
      "translation_group": "6661a67e-0ac4-4cf4-aaff-e8d66e1c674c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 73,
    "fields": {
      "term": "Optimierer (Optimizer)",
      "slug": "optimierer-optimizer",
      "short_definition": "Verfahren zur Parameteraktualisierung.",
      "long_definition": "<strong>Optimierer</strong> steuern, wie die Modellparameter während des Trainings angepasst werden, um den Loss zu minimieren. Sie basieren auf Gradientenabstiegen und Varianten davon. <ul><li><strong>Beispiele:</strong> Stochastic Gradient Descent (SGD), Adam, RMSprop.</li><li><strong>Ziel:</strong> Effizientes, stabiles und schnelles Lernen.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.682010 +00:00",
      "updated_at": "2025-11-01 13:12:03.682014 +00:00",
      "translation_group": "4a1030c3-d467-47e7-bd75-59546ec5f2b2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 74,
    "fields": {
      "term": "Gradient Descent",
      "slug": "gradient-descent",
      "short_definition": "Schrittweise Minimierung der Loss.",
      "long_definition": "<strong>Gradient Descent</strong> (Gradientenabstieg) ist ein Optimierungsverfahren, das die Gewichte eines Modells in Richtung des steilsten Gefälles des Fehlers anpasst. So wird der Verlust schrittweise minimiert. <ul><li><strong>Varianten:</strong> Batch, Stochastic, Mini-Batch.</li><li><strong>Parameter:</strong> Lernrate bestimmt Schrittgröße und Stabilität.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.682561 +00:00",
      "updated_at": "2025-11-01 13:12:03.682565 +00:00",
      "translation_group": "794908c9-c454-494e-b1b7-cc8ef64ad1fd"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 75,
    "fields": {
      "term": "Aktivierungsfunktion",
      "slug": "aktivierungsfunktion",
      "short_definition": "Nichtlinearität in Neuronen (ReLU, Sigmoid, Tanh).",
      "long_definition": "<strong>Aktivierungsfunktionen</strong> führen Nichtlinearität in neuronale Netze ein und ermöglichen es, komplexe Zusammenhänge zu modellieren. Ohne sie wären neuronale Netze einfache lineare Modelle. <ul><li><strong>Beispiele:</strong> ReLU, Sigmoid, Tanh, Softmax.</li><li><strong>Einfluss:</strong> Stabilität des Lernprozesses und Fähigkeit, komplexe Muster zu erkennen.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.683123 +00:00",
      "updated_at": "2025-11-01 13:12:03.683126 +00:00",
      "translation_group": "03a9504f-59c8-4c36-975c-f747e0ae69f9"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 76,
    "fields": {
      "term": "Regularisierung",
      "slug": "regularisierung",
      "short_definition": "Techniken gegen Overfitting (z.B. Dropout).",
      "long_definition": "<strong>Regularisierung</strong> bezeichnet Methoden, die Überanpassung (Overfitting) an Trainingsdaten verhindern. Sie kontrollieren die Modellkomplexität und verbessern die Generalisierungsfähigkeit. <ul><li><strong>Beispiele:</strong> L1/L2-Regularisierung, Dropout, Datenaugmentation.</li><li><strong>Ziel:</strong> Balance zwischen Genauigkeit und Robustheit.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.683617 +00:00",
      "updated_at": "2025-11-01 13:12:03.683620 +00:00",
      "translation_group": "2135b662-656c-4d70-9523-fb3439afa116"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 77,
    "fields": {
      "term": "Evaluierungsmetriken",
      "slug": "evaluierungsmetriken",
      "short_definition": "Kennzahlen zur Leistungsbewertung.",
      "long_definition": "<strong>Evaluierungsmetriken</strong> messen die Leistung eines Modells anhand bestimmter Kriterien. Sie helfen zu beurteilen, ob ein Modell zuverlässig arbeitet. <ul><li><strong>Beispiele:</strong> Accuracy, Precision, Recall, F1-Score, ROC-AUC.</li><li><strong>Kontextabhängig:</strong> Klassifikation, Regression und Clustering nutzen unterschiedliche Metriken.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.684111 +00:00",
      "updated_at": "2025-11-01 13:12:03.684114 +00:00",
      "translation_group": "4a1cb251-0e85-426f-a9d7-4638e3c7f0af"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 78,
    "fields": {
      "term": "Cross-Validation",
      "slug": "cross-validation",
      "short_definition": "Wiederholtes Train/Test-Splitting zur robusten Schätzung.",
      "long_definition": "<strong>Cross-Validation</strong> ist ein Verfahren zur Bewertung der Modellleistung, bei dem die Daten mehrfach in Trainings- und Testmengen aufgeteilt werden. Das Ergebnis ist eine robustere Schätzung der Generalisierungsfähigkeit. <ul><li><strong>Beispiele:</strong> k-Fold, Leave-One-Out, Stratified Cross-Validation.</li><li><strong>Vorteil:</strong> Reduziert Zufallseinflüsse einzelner Datensplits.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.684707 +00:00",
      "updated_at": "2025-11-01 13:12:03.684713 +00:00",
      "translation_group": "ed5c1c1b-bc5f-45e1-bc75-d4547ac9b378"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 79,
    "fields": {
      "term": "Hyperparameter",
      "slug": "hyperparameter",
      "short_definition": "Einstellgrößen außerhalb des Trainings (z.B. Lernrate).",
      "long_definition": "<strong>Hyperparameter</strong> sind vordefinierte Einstellungen, die das Lernverhalten eines Modells steuern, aber nicht direkt während des Trainings gelernt werden. <ul><li><strong>Beispiele:</strong> Lernrate, Anzahl der Layer, Batchgröße, Regularisierungsstärke.</li><li><strong>Optimierung:</strong> Grid Search, Random Search oder Bayesian Optimization.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.685538 +00:00",
      "updated_at": "2025-11-01 13:12:03.685544 +00:00",
      "translation_group": "619c2e6f-126c-41b9-af12-75e0338c2a34"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 80,
    "fields": {
      "term": "Transfer Learning",
      "slug": "transfer-learning",
      "short_definition": "Wissen aus Vortraining auf neue Aufgabe übertragen.",
      "long_definition": "<strong>Transfer Learning</strong> nutzt Wissen aus einem bereits trainierten Modell, um eine neue, ähnliche Aufgabe schneller und mit weniger Daten zu lösen. <ul><li><strong>Beispiel:</strong> Ein vortrainiertes Bildnetz (z. B. ResNet) für medizinische Bildklassifikation anpassen.</li><li><strong>Vorteil:</strong> Spart Rechenzeit und Trainingsdaten.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.686470 +00:00",
      "updated_at": "2025-11-01 13:12:03.686478 +00:00",
      "translation_group": "18f00a47-51a4-4b7c-ae6d-6f0b4a1644fe"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 81,
    "fields": {
      "term": "Fine-Tuning",
      "slug": "fine-tuning",
      "short_definition": "Weitertraining eines vortrainierten Modells.",
      "long_definition": "<strong>Fine-Tuning</strong> ist ein spezieller Fall des Transfer Learnings, bei dem ein vortrainiertes Modell gezielt auf neue Daten angepasst wird. Nur ausgewählte Schichten oder alle Parameter werden dabei weiter trainiert. <ul><li><strong>Anwendung:</strong> Sprachmodelle, Bildklassifikatoren, Audioerkennung.</li><li><strong>Ziel:</strong> Anpassung an spezifische Daten ohne vollständiges Neutraining.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.687298 +00:00",
      "updated_at": "2025-11-01 13:12:03.687303 +00:00",
      "translation_group": "8b40397b-8105-459d-94e5-be610f6d8af7"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 82,
    "fields": {
      "term": "Modellkompression",
      "slug": "modellkompression",
      "short_definition": "Pruning/Quantisierung zur Beschleunigung.",
      "long_definition": "<strong>Modellkompression</strong> umfasst Verfahren, die Größe und Rechenaufwand eines neuronalen Netzes verringern, ohne die Genauigkeit stark zu beeinträchtigen. Ziel ist der effiziente Einsatz auf Geräten mit begrenzten Ressourcen. <ul><li><strong>Techniken:</strong> Pruning, Quantisierung, Knowledge Distillation.</li><li><strong>Anwendungsgebiete:</strong> Mobile KI, Edge Computing, eingebettete Systeme.</li></ul>",
      "category": "Daten/Training/Evaluierung",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.687968 +00:00",
      "updated_at": "2025-11-01 13:12:03.687973 +00:00",
      "translation_group": "752b62d8-6df7-4e50-937b-5f446b2bf07c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 83,
    "fields": {
      "term": "KI-Ethik",
      "slug": "ki-ethik",
      "short_definition": "Leitlinien für verantwortungsvolle Entwicklung/Nutzung.",
      "long_definition": "<strong>KI-Ethik</strong> befasst sich mit moralischen, gesellschaftlichen und rechtlichen Fragen rund um den Einsatz von Künstlicher Intelligenz. Sie stellt sicher, dass Systeme im Einklang mit menschlichen Werten, Grundrechten und sozialer Verantwortung entwickelt werden. <ul><li><strong>Schwerpunkte:</strong> Fairness, Transparenz, Verantwortung, Schadensvermeidung.</li><li><strong>Ziel:</strong> Vertrauen schaffen und gesellschaftlich akzeptable KI fördern.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.702338 +00:00",
      "updated_at": "2025-11-01 13:12:03.702344 +00:00",
      "translation_group": "de758c7e-8344-406b-8441-bb083fac5fa2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 84,
    "fields": {
      "term": "Transparenz",
      "slug": "transparenz",
      "short_definition": "Nachvollziehbarkeit von Daten, Modellen, Entscheidungen.",
      "long_definition": "<strong>Transparenz</strong> bedeutet, dass Funktionsweise, Entscheidungsprozesse und Datengrundlagen eines KI-Systems nachvollziehbar und überprüfbar sind. Sie ist Voraussetzung für Vertrauen und Rechenschaftspflicht. <ul><li><strong>Umsetzung:</strong> Dokumentation von Trainingsdaten, erklärbare Modelle, Offenlegung von Limitationen.</li><li><strong>Vorteil:</strong> Ermöglicht Audits, Fehleranalyse und verantwortliche Nutzung.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.703302 +00:00",
      "updated_at": "2025-11-01 13:12:03.703308 +00:00",
      "translation_group": "26608972-2f48-4b28-b9e4-af0069d6ae1f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 85,
    "fields": {
      "term": "Datenschutz (DSGVO)",
      "slug": "datenschutz-dsgvo",
      "short_definition": "Schutz personenbezogener Daten in EU-Kontext.",
      "long_definition": "<strong>Datenschutz</strong> nach der DSGVO schützt personenbezogene Daten vor Missbrauch und unrechtmäßiger Verarbeitung. Organisationen müssen rechtliche Grundlagen, Zweckbindung, Datenminimierung und Betroffenenrechte sicherstellen. <ul><li><strong>Prinzipien:</strong> Transparenz, Sicherheit, Verantwortlichkeit.</li><li><strong>Rechte:</strong> Auskunft, Löschung, Widerspruch, Datenübertragbarkeit.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.703978 +00:00",
      "updated_at": "2025-11-01 13:12:03.703981 +00:00",
      "translation_group": "877f187f-0d42-443a-8bef-c7be69d1807c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 86,
    "fields": {
      "term": "Anonymisierung",
      "slug": "anonymisierung",
      "short_definition": "Entfernung identifizierender Merkmale.",
      "long_definition": "<strong>Anonymisierung</strong> bezeichnet die Verarbeitung von Daten, sodass eine Identifizierung einzelner Personen dauerhaft ausgeschlossen ist. Im Gegensatz zur Pseudonymisierung kann die Zuordnung auch mit Zusatzwissen nicht mehr hergestellt werden. <ul><li><strong>Ziel:</strong> Schutz der Privatsphäre und Einhaltung gesetzlicher Vorgaben.</li><li><strong>Verfahren:</strong> Aggregation, Maskierung, Rauschen, Generalisierung.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.704629 +00:00",
      "updated_at": "2025-11-01 13:12:03.704633 +00:00",
      "translation_group": "f2ee8213-6936-4ffd-9f80-decc4895d77c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 87,
    "fields": {
      "term": "Einwilligung",
      "slug": "einwilligung",
      "short_definition": "Zustimmung der betroffenen Person zur Datenverarbeitung.",
      "long_definition": "<strong>Einwilligung</strong> ist ein Grundprinzip des Datenschutzrechts und beschreibt die freiwillige, informierte und eindeutige Zustimmung einer Person zur Verarbeitung ihrer Daten. <ul><li><strong>Anforderungen:</strong> Transparent, zweckgebunden, jederzeit widerrufbar.</li><li><strong>Beispiel:</strong> Zustimmung zur Nutzung von Sprachdaten für Trainingszwecke.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.705604 +00:00",
      "updated_at": "2025-11-01 13:12:03.705610 +00:00",
      "translation_group": "37e1b41e-335b-460f-a112-e8fad451f87d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 88,
    "fields": {
      "term": "Explainable AI (XAI)",
      "slug": "explainable-ai-xai",
      "short_definition": "Erklärbarkeit komplexer Modelle.",
      "long_definition": "<strong>Explainable AI (XAI)</strong> bezeichnet Methoden, die Entscheidungen von KI-Systemen nachvollziehbar machen. Dadurch können Nutzer verstehen, warum ein Modell eine bestimmte Ausgabe liefert. <ul><li><strong>Techniken:</strong> SHAP, LIME, Feature-Importance, Visualisierungen neuronaler Aktivierungen.</li><li><strong>Ziel:</strong> Vertrauen, Fehlersuche und regulatorische Nachvollziehbarkeit.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.706316 +00:00",
      "updated_at": "2025-11-01 13:12:03.706320 +00:00",
      "translation_group": "658f3046-c960-416c-b4b9-6329fb34e576"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 89,
    "fields": {
      "term": "Responsible AI",
      "slug": "responsible-ai",
      "short_definition": "Praktiken für sichere, faire und robuste KI.",
      "long_definition": "<strong>Responsible AI</strong> steht für die verantwortungsbewusste Entwicklung, Einführung und Überwachung von KI-Systemen. Ziel ist es, Risiken zu minimieren und den gesellschaftlichen Nutzen zu maximieren. <ul><li><strong>Bestandteile:</strong> Ethikrichtlinien, Fairness-Prüfungen, Bias-Analysen, kontinuierliches Monitoring.</li><li><strong>Ansatz:</strong> Kombination aus Technik, Recht und Organisation.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.706948 +00:00",
      "updated_at": "2025-11-01 13:12:03.706951 +00:00",
      "translation_group": "6c0070dd-4d2e-4d99-835e-bbc61a32024e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 90,
    "fields": {
      "term": "EU AI Act (KI-Verordnung)",
      "slug": "eu-ai-act-ki-verordnung",
      "short_definition": "Rechtlicher Rahmen der EU mit Risikoklassen.",
      "long_definition": "Der <strong>EU AI Act</strong> (KI-Verordnung) ist das erste umfassende Gesetz zur Regulierung von Künstlicher Intelligenz in Europa. Er teilt KI-Systeme in Risikoklassen ein und definiert Pflichten für Anbieter und Nutzer. <ul><li><strong>Risikostufen:</strong> Unannehmbares Risiko, hohes Risiko, begrenztes Risiko, minimales Risiko.</li><li><strong>Ziel:</strong> Sicherstellung von Sicherheit, Transparenz und Grundrechtsschutz.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.707486 +00:00",
      "updated_at": "2025-11-01 13:12:03.707489 +00:00",
      "translation_group": "332a335b-d51d-4b14-b217-abaea75f7f15"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 91,
    "fields": {
      "term": "Sicherheit (Safety)",
      "slug": "sicherheit-safety",
      "short_definition": "Vermeidung schädlicher Ergebnisse/Fehlfunktionen.",
      "long_definition": "<strong>Sicherheit (Safety)</strong> beschreibt Maßnahmen, die verhindern, dass KI-Systeme unbeabsichtigte Schäden oder gefährliche Fehlentscheidungen verursachen. Sie umfasst sowohl technische Robustheit als auch Schutz vor Missbrauch. <ul><li><strong>Aspekte:</strong> Fehlertoleranz, Testabdeckung, Redundanz, Angriffssicherheit.</li><li><strong>Ziel:</strong> Vermeidung physischer, digitaler und gesellschaftlicher Risiken.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.708061 +00:00",
      "updated_at": "2025-11-01 13:12:03.708066 +00:00",
      "translation_group": "f61ce5bb-3cc3-41fe-b284-482776a26b94"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 93,
    "fields": {
      "term": "KI-Governance",
      "slug": "ki-governance",
      "short_definition": "Strukturen/Prozesse zur Steuerung von KI.",
      "long_definition": "<strong>KI-Governance</strong> umfasst organisatorische und regulatorische Rahmenbedingungen zur Steuerung von KI über ihren gesamten Lebenszyklus hinweg. Sie legt Verantwortlichkeiten, Prüfprozesse und Berichtswege fest. <ul><li><strong>Komponenten:</strong> Richtlinien, Rollenverteilung, Risikoanalyse, Compliance-Monitoring.</li><li><strong>Ziel:</strong> Transparente, sichere und regelkonforme Nutzung von KI-Systemen.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.709186 +00:00",
      "updated_at": "2025-11-01 13:12:03.709190 +00:00",
      "translation_group": "52395a8e-837a-403c-8f0e-db666a68452d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 94,
    "fields": {
      "term": "Green AI",
      "slug": "green-ai",
      "short_definition": "Ressourcenschonende, nachhaltige KI.",
      "long_definition": "<strong>Green AI</strong> beschreibt Ansätze zur Entwicklung und Nutzung von KI-Systemen, die Energieverbrauch und ökologische Auswirkungen minimieren. Ziel ist eine nachhaltige Digitalisierung. <ul><li><strong>Strategien:</strong> Effiziente Algorithmen, Hardwareoptimierung, Einsatz erneuerbarer Energien.</li><li><strong>Bedeutung:</strong> Verbindung von technologischem Fortschritt und Umweltschutz.</li></ul>",
      "category": "Ethik/Sicherheit/Datenschutz",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.710003 +00:00",
      "updated_at": "2025-11-01 13:12:03.710011 +00:00",
      "translation_group": "7b944a3c-5a79-4925-9b8c-9c33e2be8615"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 95,
    "fields": {
      "term": "Python",
      "slug": "python",
      "short_definition": "Hauptsprache für Daten/ML-Ökosysteme.",
      "long_definition": "<strong>Python</strong> ist die meistgenutzte Programmiersprache für maschinelles Lernen, Datenanalyse und KI-Entwicklung. Durch ihre einfache Syntax und die große Anzahl an Bibliotheken ermöglicht sie schnellen Prototypenbau und produktionsreife Lösungen. <ul><li><strong>Wichtige Bibliotheken:</strong> NumPy, pandas, TensorFlow, PyTorch, scikit-learn.</li><li><strong>Stärken:</strong> Lesbarkeit, Community, Integration mit Cloud- und MLOps-Tools.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.713993 +00:00",
      "updated_at": "2025-11-01 13:12:03.714000 +00:00",
      "translation_group": "c037ec03-f75f-4fb8-a310-ca4a221f1919"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 96,
    "fields": {
      "term": "TensorFlow",
      "slug": "tensorflow",
      "short_definition": "Framework für Deep Learning & Deployment.",
      "long_definition": "<strong>TensorFlow</strong> ist ein Open-Source-Framework von Google für maschinelles und tiefes Lernen. Es unterstützt Training, Modelloptimierung und Bereitstellung auf Servern, Mobilgeräten oder im Browser. <ul><li><strong>Komponenten:</strong> Keras API, TensorBoard, TensorFlow Lite, TensorFlow Serving.</li><li><strong>Einsatz:</strong> Klassifikation, Computer Vision, Text- und Sprachverarbeitung.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.714947 +00:00",
      "updated_at": "2025-11-01 13:12:03.714951 +00:00",
      "translation_group": "ac884880-5a60-4aa4-8330-85ce0de2624a"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 97,
    "fields": {
      "term": "PyTorch",
      "slug": "pytorch",
      "short_definition": "Framework für dynamische Deep-Learning-Workflows.",
      "long_definition": "<strong>PyTorch</strong> ist ein von Meta entwickeltes Deep-Learning-Framework mit dynamischer Rechengraph-Erstellung. Es eignet sich besonders für Forschung und schnelle Prototypenentwicklung. <ul><li><strong>Merkmale:</strong> Einfache Syntax, GPU-Unterstützung, starke Integration mit Hugging Face.</li><li><strong>Einsatz:</strong> Computer Vision, NLP, Reinforcement Learning.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.715600 +00:00",
      "updated_at": "2025-11-01 13:12:03.715604 +00:00",
      "translation_group": "03c199a7-0a27-4beb-a197-1e08762b46b2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 98,
    "fields": {
      "term": "Scikit-learn",
      "slug": "scikit-learn",
      "short_definition": "Bibliothek für klassisches ML.",
      "long_definition": "<strong>scikit-learn</strong> ist eine weit verbreitete Python-Bibliothek für maschinelles Lernen mit klassischen Verfahren wie Regression, Klassifikation und Clustering. <ul><li><strong>Funktionen:</strong> Datenvorverarbeitung, Modelltraining, Evaluierung und Pipelines.</li><li><strong>Vorteil:</strong> Einfache Anwendung und Integration in Datenanalyse-Workflows.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.716184 +00:00",
      "updated_at": "2025-11-01 13:12:03.716187 +00:00",
      "translation_group": "769bb114-620d-4623-a2e7-a1c90cfe1081"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 99,
    "fields": {
      "term": "Jupyter Notebook",
      "slug": "jupyter-notebook",
      "short_definition": "Interaktive Umgebung für Datenanalyse & Demos.",
      "long_definition": "<strong>Jupyter Notebooks</strong> sind interaktive Entwicklungsumgebungen, in denen Code, Text, Visualisierungen und Ergebnisse kombiniert werden. Sie sind Standard in der Datenwissenschaft. <ul><li><strong>Nutzung:</strong> Prototyping, Lehre, Forschung, Reporting.</li><li><strong>Formate:</strong> .ipynb-Dateien, die im Browser ausgeführt werden können.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.716838 +00:00",
      "updated_at": "2025-11-01 13:12:03.716842 +00:00",
      "translation_group": "5b20153a-55cd-40f0-83a4-627ebd1c8c21"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 100,
    "fields": {
      "term": "API",
      "slug": "api",
      "short_definition": "Schnittstelle zwischen Softwarekomponenten.",
      "long_definition": "Eine <strong>API</strong> (Application Programming Interface) definiert, wie Softwarekomponenten miteinander kommunizieren. Im KI-Kontext werden APIs genutzt, um Modelle, Datendienste oder Analysefunktionen bereitzustellen. <ul><li><strong>Typen:</strong> REST, GraphQL, WebSocket.</li><li><strong>Vorteil:</strong> Standardisierte Integration und Wiederverwendbarkeit.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.717441 +00:00",
      "updated_at": "2025-11-01 13:12:03.717444 +00:00",
      "translation_group": "4e8711a0-d9da-4a81-b873-d5b36f52cd9f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 101,
    "fields": {
      "term": "GPU / TPU",
      "slug": "gpu-tpu",
      "short_definition": "Spezialhardware für beschleunigtes Training/Inference.",
      "long_definition": "<strong>GPUs</strong> (Graphics Processing Units) und <strong>TPUs</strong> (Tensor Processing Units) sind spezialisierte Prozessoren, die massiv parallele Berechnungen ermöglichen. Sie beschleunigen Training und Inferenz neuronaler Netze erheblich. <ul><li><strong>GPU:</strong> Universell, flexibel, von NVIDIA und AMD.</li><li><strong>TPU:</strong> Google-Chip, optimiert für TensorFlow-Operationen.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.718131 +00:00",
      "updated_at": "2025-11-01 13:12:03.718135 +00:00",
      "translation_group": "637e0a1c-52af-447f-8531-0b5d9e6860ea"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 102,
    "fields": {
      "term": "Cloud Computing",
      "slug": "cloud-computing",
      "short_definition": "Skalierbare Rechen-/Speicherressourcen on demand.",
      "long_definition": "<strong>Cloud Computing</strong> stellt Rechenleistung, Speicher und Dienste über das Internet bereit. Für KI ermöglicht es skalierbares Training, Datenmanagement und Bereitstellung von Modellen. <ul><li><strong>Beispiele:</strong> AWS SageMaker, Google Vertex AI, Azure ML.</li><li><strong>Vorteile:</strong> Skalierbarkeit, Flexibilität, Kostenkontrolle.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.718879 +00:00",
      "updated_at": "2025-11-01 13:12:03.718884 +00:00",
      "translation_group": "e3e54f25-e222-4792-a34a-9e0aadd649c6"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 103,
    "fields": {
      "term": "Edge AI",
      "slug": "edge-ai",
      "short_definition": "Ausführung von Modellen am Rand (Gerät/Sensor).",
      "long_definition": "<strong>Edge AI</strong> bezeichnet die lokale Ausführung von KI-Modellen direkt auf Endgeräten oder Sensoren, ohne Daten an Cloudserver zu senden. <ul><li><strong>Vorteile:</strong> Geringere Latenz, Datenschutz, Offline-Fähigkeit.</li><li><strong>Beispiele:</strong> Gesichtserkennung auf Smartphones, IoT-Sensoranalyse.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.719723 +00:00",
      "updated_at": "2025-11-01 13:12:03.719729 +00:00",
      "translation_group": "7c32654f-a784-4a94-ad5e-60b8a491255c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 104,
    "fields": {
      "term": "Model Deployment",
      "slug": "model-deployment",
      "short_definition": "Bereitstellung eines trainierten Modells in Produktion.",
      "long_definition": "<strong>Model Deployment</strong> umfasst alle Schritte, um ein trainiertes Modell in einer produktiven Umgebung bereitzustellen, damit es Vorhersagen in Echtzeit liefern kann. <ul><li><strong>Aspekte:</strong> Containerisierung, API-Bereitstellung, Skalierung, Monitoring.</li><li><strong>Ziel:</strong> Zuverlässige Nutzung von KI-Modellen im Betrieb.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.720412 +00:00",
      "updated_at": "2025-11-01 13:12:03.720417 +00:00",
      "translation_group": "f1bc0ca3-bb09-4c74-9a8a-a973006bb070"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 105,
    "fields": {
      "term": "Inferenz (Inference)",
      "slug": "inferenz-inference",
      "short_definition": "Ausführung eines Modells auf neuen Daten.",
      "long_definition": "<strong>Inference</strong> bezeichnet die Anwendung eines trainierten KI-Modells auf neue, unbekannte Daten, um Vorhersagen oder Klassifikationen zu treffen. <ul><li><strong>Beispiele:</strong> Spracherkennung, Bildklassifikation, Textgenerierung.</li><li><strong>Optimierung:</strong> Batch-Inferenz, Quantisierung, Hardwarebeschleunigung.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.721041 +00:00",
      "updated_at": "2025-11-01 13:12:03.721046 +00:00",
      "translation_group": "62352d34-62b8-4e7e-bc10-e836ccc31fd1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 106,
    "fields": {
      "term": "Hugging Face",
      "slug": "hugging-face",
      "short_definition": "Hub & Tools für Modelle, Datasets, Pipelines.",
      "long_definition": "<strong>Hugging Face</strong> ist eine offene Plattform für KI-Modelle, Datensätze und Bibliotheken im Bereich Natural Language Processing und multimodaler KI. <ul><li><strong>Kernkomponenten:</strong> Transformers, Datasets, Tokenizers, Model Hub.</li><li><strong>Ziel:</strong> Demokratisierung von KI durch offene Modelle und Community-Beiträge.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.721975 +00:00",
      "updated_at": "2025-11-01 13:12:03.721980 +00:00",
      "translation_group": "aa3c14b5-7e0c-4f26-8da2-473e925ab885"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 107,
    "fields": {
      "term": "MLOps",
      "slug": "mlops",
      "short_definition": "Methoden/Tools für Betrieb von ML-Systemen.",
      "long_definition": "<strong>MLOps</strong> (Machine Learning Operations) kombiniert DevOps-Prinzipien mit Machine Learning. Es umfasst Automatisierung, Versionierung, Überwachung und Bereitstellung von Modellen. <ul><li><strong>Komponenten:</strong> CI/CD, Feature Stores, Model Registry, Monitoring.</li><li><strong>Nutzen:</strong> Stabiler, wiederholbarer und sicherer KI-Betrieb.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.722690 +00:00",
      "updated_at": "2025-11-01 13:12:03.722694 +00:00",
      "translation_group": "348181c3-d4bc-471e-881e-b88664d0146c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 108,
    "fields": {
      "term": "Datenpipeline",
      "slug": "datenpipeline",
      "short_definition": "Ablauf von Erhebung bis Bereitstellung von Daten.",
      "long_definition": "<strong>Datenpipelines</strong> automatisieren den Fluss von Rohdaten über Reinigung und Transformation bis zur Bereitstellung für Analyse oder Training. <ul><li><strong>Werkzeuge:</strong> Apache Airflow, Prefect, Luigi.</li><li><strong>Ziel:</strong> Reproduzierbarkeit, Skalierbarkeit und Datenqualität sichern.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.723316 +00:00",
      "updated_at": "2025-11-01 13:12:03.723319 +00:00",
      "translation_group": "4eb6cea9-771e-4582-8db7-86f8ae42550b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 109,
    "fields": {
      "term": "Modellversionierung",
      "slug": "modellversionierung",
      "short_definition": "Nachverfolgung von Modellständen/Artefakten.",
      "long_definition": "<strong>Modellversionierung</strong> bezeichnet das strukturierte Verwalten und Nachverfolgen verschiedener Modellstände und Trainingsartefakte. Sie ermöglicht Transparenz, Rollbacks und reproduzierbare Experimente. <ul><li><strong>Tools:</strong> MLflow, DVC, Weights & Biases.</li><li><strong>Nutzen:</strong> Kontrolle und Nachvollziehbarkeit im Lebenszyklus von Modellen.</li></ul>",
      "category": "Tech & Tools",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.723894 +00:00",
      "updated_at": "2025-11-01 13:12:03.723897 +00:00",
      "translation_group": "42012254-cddd-45d3-84fa-c33fdb164c67"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 110,
    "fields": {
      "term": "Künstliche Generalintelligenz (AGI)",
      "slug": "kunstliche-generalintelligenz-agi",
      "short_definition": "Hypothetische KI mit menschenähnlicher Allgemeinintelligenz.",
      "long_definition": "<strong>AGI</strong> bezeichnet hypothetische Systeme, die wie Menschen flexibel Wissen erwerben, übertragen und in neuen Situationen anwenden können. <ul><li><strong>Abgrenzung:</strong> Im Unterschied zu schmaler KI (z.B. Übersetzen) sollen AGI-Systeme <em>domänenübergreifend</em> lernen und planen.</li><li><strong>Kernfähigkeiten:</strong> Sprach- und Weltverständnis, langfristiges Planen, Transferlernen, Selbstüberwachung (Self-Monitoring).</li><li><strong>Status:</strong> Gegenwärtig gibt es keine allgemein anerkannte AGI; heutige Systeme sind leistungsfähig, aber spezial- bzw. eng-generalisiert.</li><li><strong>Chancen:</strong> Automatisierung komplexer Wissensarbeit, beschleunigte Forschung, neue Werkzeuge für Bildung und Medizin.</li><li><strong>Risiken:</strong> Fehlanreize, Kontrollprobleme, Sicherheitsfragen, Machtkonzentration, gesellschaftliche Verwerfungen.</li><li><strong>Governance:</strong> Sicherheitsstandards, Audits, Evaluierungen, Zugriffskontrollen und Rechenschaftspflichten.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.741958 +00:00",
      "updated_at": "2025-11-01 13:12:03.741964 +00:00",
      "translation_group": "ec7657a3-9fd9-4ebe-ab34-b400364af43c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 111,
    "fields": {
      "term": "Künstliche Superintelligenz (ASI)",
      "slug": "kunstliche-superintelligenz-asi",
      "short_definition": "KI, die Menschen in allen Domänen übertrifft.",
      "long_definition": "<strong>ASI</strong> ist ein spekulatives Konzept für Systeme, die <em>in praktisch allen kognitiven Aufgaben</em> Menschen übertreffen. <ul><li><strong>Mögliche Eigenschaften:</strong> übermenschliche Problemlösefähigkeit, strategische Planung, rasanter Wissenszuwachs.</li><li><strong>Diskurs:</strong> Chancen (medizinische Durchbrüche) vs. Risiken (Sicherheits- und Kontrollverlust).</li><li><strong>Forschungsschwerpunkte heute:</strong> Robustheit, Ausrichtung (Alignment), Interpretierbarkeit, Notfallabschaltung (Kill-Switch) und Governance-Modelle.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.742831 +00:00",
      "updated_at": "2025-11-01 13:12:03.742835 +00:00",
      "translation_group": "7c788a4b-e02b-47a0-8f69-f7392ea605c3"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 113,
    "fields": {
      "term": "Mensch-Maschine-Interaktion",
      "slug": "mensch-maschine-interaktion",
      "short_definition": "Gestaltung der Zusammenarbeit zwischen Mensch und System.",
      "long_definition": "<strong>Mensch-Maschine-Interaktion (MMI)</strong> umfasst die nutzerzentrierte Gestaltung von Schnittstellen zu (KI-)Systemen. <ul><li><strong>Ziele:</strong> Effizienz, Sicherheit, Vertrauen, Nachvollziehbarkeit.</li><li><strong>Gestaltungsprinzipien:</strong> klare Feedbacks, Erklärungen (Warum ein Ergebnis?), kontrollierbare Automatikgrade, Barrierefreiheit.</li><li><strong>Beispiele:</strong> erklärbare Empfehlungen im Dashboard, Vorschläge mit Begründung, leicht zurückzunehmende Aktionen.</li><li><strong>Risiken:</strong> Automationsbias (Blindes Vertrauen), Überforderung durch zu viele Optionen, Dark Patterns.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.744565 +00:00",
      "updated_at": "2025-11-01 13:12:03.744579 +00:00",
      "translation_group": "4028d409-589c-4d73-8309-cf114dc3552d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 114,
    "fields": {
      "term": "Digitale Transformation",
      "slug": "digitale-transformation",
      "short_definition": "Tiefer Wandel durch digitale Technologien.",
      "long_definition": "<strong>Digitale Transformation</strong> ist der langfristige Umbau von Prozessen, Produkten und Kultur mithilfe digitaler Technologien. <ul><li><strong>Dimensionen:</strong> Geschäftsmodell (z.B. Abo statt Einmalverkauf), Prozesse (Automatisierung, Datenflüsse), Organisation (Rollen, Kompetenzen), Technologie (Cloud, APIs, KI).</li><li><strong>Erfolgsfaktoren:</strong> klare Zielbilder, Iteration, Datenstrategie, Change-Management, IT-Sicherheit.</li><li><strong>Fallstricke:</strong> Tool-Zentrierung statt Nutzenfokus, fehlende Datenqualität, Silos, \"Proof-of-Concept-Friedhöfe\" ohne Rollout.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.745552 +00:00",
      "updated_at": "2025-11-01 13:12:03.745558 +00:00",
      "translation_group": "8985984f-864c-440b-9119-bf74ea45d373"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 115,
    "fields": {
      "term": "Urheberrecht und KI",
      "slug": "urheberrecht-und-ki",
      "short_definition": "Rechte an KI-Input/Output und Trainingsdaten.",
      "long_definition": "<strong>Urheberrecht & KI</strong> berührt die Nutzung geschützter Werke im Training, die Rechte an generierten Outputs sowie Lizenz- und Haftungsfragen. <ul><li><strong>Training:</strong> Je nach Rechtsraum gelten Ausnahmen/Einwilligungen (z.B. Text- und Datamining-Regeln); Rechteinhaber können Nutzungen beschränken.</li><li><strong>Output:</strong> Schutzfähigkeit hängt oft von menschlicher Mitwirkung ab; rein maschinell erzeugte Inhalte sind teils nicht urheberrechtlich geschützt.</li><li><strong>Lizenzierung:</strong> Modell- und Datensätze unter Open-Source- bzw. Modelllizenzen haben Bedingungen (Zweckbindung, Attribution, Nutzungsgrenzen).</li><li><strong>Compliance:</strong> Dokumentation von Quellen, Opt-Out-Signalen, Nutzungsbedingungen und Rechteketten.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.746306 +00:00",
      "updated_at": "2025-11-01 13:12:03.746309 +00:00",
      "translation_group": "e7e3c8ec-e3e5-4910-b076-d064fcf05818"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 116,
    "fields": {
      "term": "Haftung für KI-Entscheidungen",
      "slug": "haftung-fur-ki-entscheidungen",
      "short_definition": "Rechtsfragen bei fehlerhaften Ergebnissen.",
      "long_definition": "<strong>Haftung</strong> klärt, wer für Schäden durch KI-gestützte Entscheidungen einsteht. <ul><li><strong>Ansatzpunkte:</strong> Produkt-/Herstellerhaftung, Betreiber-/Verkehrssicherungspflichten, Sorgfaltspflichten bei Auswahl und Überwachung.</li><li><strong>Nachweis:</strong> Protokolle, Erklärungen, Audit-Trails und Datenhaltung unterstützen Beweisführung.</li><li><strong>Prävention:</strong> Risikobewertungen, Tests/V&V, Human-in-the-Loop, Notfallprozesse, regelmäßige Re-Zertifizierung.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.746885 +00:00",
      "updated_at": "2025-11-01 13:12:03.746889 +00:00",
      "translation_group": "e90daf4b-6bba-46d4-98cd-55d06496c035"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 117,
    "fields": {
      "term": "Open-Source-KI",
      "slug": "open-source-ki",
      "short_definition": "Offen lizenzierte Modelle/Daten/Tools.",
      "long_definition": "<strong>Open-Source-KI</strong> umfasst frei lizenzierte Modelle, Datensätze und Werkzeuge. <ul><li><strong>Vorteile:</strong> Transparenz, Prüfbarkeit, Community-Innovation, Kostenkontrolle, Portabilität.</li><li><strong>Beachtung:</strong> Lizenzbedingungen (z.B. MIT, Apache-2.0, modell-spezifische Lizenzen), Markenzeichen, verantwortungsvolle Nutzung.</li><li><strong>Praxis:</strong> Reproduzierbare Trainings-/Eval-Pipelines, Model Cards, Datenkarten, Security-Reviews.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.747387 +00:00",
      "updated_at": "2025-11-01 13:12:03.747390 +00:00",
      "translation_group": "84a58740-4145-413c-8342-491d48a5819e"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 118,
    "fields": {
      "term": "Kommerzielle KI",
      "slug": "kommerzielle-ki",
      "short_definition": "Proprietäre Modelle, Dienste und Plattformen.",
      "long_definition": "<strong>Kommerzielle KI</strong> bezeichnet proprietäre Angebote mit Support, SLAs und Integrationen. <ul><li><strong>Vorteile:</strong> Verfügbarkeit, Skalierung, Sicherheit, Ökosystem/Plugins, Haftungsrahmen.</li><li><strong>Nachteile:</strong> Kosten, Vendor-Lock-in, geringere Transparenz.</li><li><strong>Entscheidungskriterien:</strong> Datenschutz, Datenresidenz, Preis/Leistung, Ausfallsicherheit, Exportpfade/Portabilität.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.747881 +00:00",
      "updated_at": "2025-11-01 13:12:03.747884 +00:00",
      "translation_group": "e5294eb4-6265-48b7-b2d1-f99611da392b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 119,
    "fields": {
      "term": "KI-Forschung",
      "slug": "ki-forschung",
      "short_definition": "Wissenschaftliche Entwicklung neuer Methoden/Anwendungen.",
      "long_definition": "<strong>KI-Forschung</strong> reicht von Grundlagen (Lernen, Repräsentation, Optimierung) bis zu Anwendungen (Medizin, Bildung, Industrie). <ul><li><strong>Methoden:</strong> neue Architekturen, Trainingsverfahren, Evaluationsmetriken, Sicherheitsansätze.</li><li><strong>Transfer:</strong> Open-Source-Modelle, Benchmarks, verantwortliche Veröffentlichung (Responsible Disclosure).</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.748467 +00:00",
      "updated_at": "2025-11-01 13:12:03.748473 +00:00",
      "translation_group": "378a0d90-6bd8-4d99-8771-85195348479c"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 120,
    "fields": {
      "term": "Singularität",
      "slug": "singularitat",
      "short_definition": "Hypothetischer Punkt rapiden, unkontrollierten Fortschritts.",
      "long_definition": "<strong>Technologische Singularität</strong> bezeichnet das Szenario, in dem die Verbesserung intelligenter Systeme sich selbst stark beschleunigt und gesellschaftliche Strukturen grundlegend verändert. <ul><li><strong>Argumente dafür:</strong> positive Rückkopplung von Forschung durch KI, exponentielle Trends.</li><li><strong>Argumente dagegen:</strong> physikalische/ökonomische Grenzen, Daten-/Energie-/Sicherheits-Engpässe, Governance.</li><li><strong>Praxisnutzen heute:</strong> Als Denkmodell sensibilisiert der Begriff für Skalierungs- und Sicherheitsfragen.</li></ul>",
      "category": "Gesellschaft & Recht",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.749099 +00:00",
      "updated_at": "2025-11-01 13:12:03.749103 +00:00",
      "translation_group": "03f216ea-4a3b-45f5-b226-cc5b73b12598"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 121,
    "fields": {
      "term": "KI-Agent",
      "slug": "ki-agent",
      "short_definition": "Modell mit Autonomie, Zielen und Werkzeugnutzung.",
      "long_definition": "<strong>KI-Agenten</strong> kombinieren Modelle mit Planungs-, Wahrnehmungs-, Tool- und Feedback-Schleifen, um Ziele weitgehend selbständig zu verfolgen. <ul><li><strong>Bausteine:</strong> Zielzerlegung, Tool-Aufrufe (APIs), Gedächtnis, Evaluations-/Korrekturschleifen.</li><li><strong>Einsatz:</strong> Recherche-Flows, Datenpipelines, Support-Autopiloten, DevOps-Routinen.</li><li><strong>Kontrollen:</strong> Rechte-/Kostenlimits, Prüfregeln, menschliche Freigaben.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.776677 +00:00",
      "updated_at": "2025-11-01 13:12:03.776683 +00:00",
      "translation_group": "a039929f-2a29-4d0d-8332-4eb2e44707df"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 122,
    "fields": {
      "term": "Multi-Agent-System",
      "slug": "multi-agent-system",
      "short_definition": "Kooperierende/konkurrierende Agentenpopulationen.",
      "long_definition": "<strong>Multi-Agent-Systeme</strong> koordinieren mehrere spezialisierte Agenten mit Rollen (z.B. Planer, Prüfer, Ausführer). <ul><li><strong>Koordination:</strong> Aushandeln, Blackboard-/Nachrichten-Bus, Abstimmungen.</li><li><strong>Vorteile:</strong> Arbeitsteilung, Fehlertoleranz, bessere Ergebnisse durch Peer-Review.</li><li><strong>Herausforderungen:</strong> Kosten, Latenzen, Stabilität, Rollen-Drift.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.777843 +00:00",
      "updated_at": "2025-11-01 13:12:03.777849 +00:00",
      "translation_group": "86c8be84-9142-4c1e-89bd-ed440bb13263"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 123,
    "fields": {
      "term": "Tool-Use",
      "slug": "tool-use",
      "short_definition": "Externe Werkzeuge (APIs) in Modellketten verwenden.",
      "long_definition": "<strong>Tool-Use</strong> erweitert Modelle um Zugriff auf Funktionen wie Suche, Datenbanken oder Aktoren. <ul><li><strong>Nutzen:</strong> aktuelle Daten, Aktionen ausführen, Rechen-/Domänen-Offloading.</li><li><strong>Risiken:</strong> Sicherheitsfreigaben, Kostenkontrolle, Korrektheit externer Antworten.</li><li><strong>Good Practices:</strong> Whitelists, Sandboxing, Quittungen/Logs, Rate-Limits.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.778526 +00:00",
      "updated_at": "2025-11-01 13:12:03.778533 +00:00",
      "translation_group": "e38efee1-ed51-4e27-8629-ba2d7a1acc4f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 124,
    "fields": {
      "term": "Chain-of-Thought",
      "slug": "chain-of-thought",
      "short_definition": "Explizite Gedankenschritte zur Problemlösung.",
      "long_definition": "<strong>Chain-of-Thought (CoT)</strong> bedeutet, dass Modelle Zwischenschritte explizit formulieren (z.B. Rechenwege, Begründungen). <ul><li><strong>Vorteile:</strong> bessere Genauigkeit bei komplexen Aufgaben, Prüfbarkeit.</li><li><strong>Beachtung:</strong> potenzielles Leaken sensibler Infos; deshalb oft nur intern/verdeckt eingesetzt.</li><li><strong>Alternativen:</strong> strukturierte Pläne, Scratchpads, Program-Aided Reasoning.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.779052 +00:00",
      "updated_at": "2025-11-01 13:12:03.779055 +00:00",
      "translation_group": "95422eb4-b3d2-4f97-ad97-8478f5fa1320"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 125,
    "fields": {
      "term": "Self-Consistency",
      "slug": "self-consistency",
      "short_definition": "Mehrfach-Abtastung zur stabileren Lösung.",
      "long_definition": "<strong>Self-Consistency</strong> generiert mehrere Lösungsvorschläge und wählt per Abstimmung/Konsens die konsistenteste Antwort. <ul><li><strong>Nutzen:</strong> geringere Zufallsschwankungen, robustere Ergebnisse.</li><li><strong>Kosten:</strong> mehr Rechenaufwand und Latenz.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.779573 +00:00",
      "updated_at": "2025-11-01 13:12:03.779575 +00:00",
      "translation_group": "cb870f89-d3b5-4ea7-828e-868594bf8b91"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 126,
    "fields": {
      "term": "Planning / Reasoning",
      "slug": "planning-reasoning",
      "short_definition": "Planen und schlussfolgern über mehrere Schritte.",
      "long_definition": "<strong>Planning & Reasoning</strong> zerlegen Aufgaben in Teilprobleme und verknüpfen Zwischenergebnisse logisch. <ul><li><strong>Techniken:</strong> Aufgabenbäume, Zielzerlegung, Suchverfahren, Verifikation.</li><li><strong>Einsatz:</strong> Workflow-Orchestrierung, Debugging, Datenaufbereitung, Entscheidungsunterstützung.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.780068 +00:00",
      "updated_at": "2025-11-01 13:12:03.780071 +00:00",
      "translation_group": "92983899-0e83-463a-a4ba-37e79993d040"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 127,
    "fields": {
      "term": "Langzeitgedächtnis",
      "slug": "langzeitgedachtnis",
      "short_definition": "Persistente Speicherung von Kontext/Präferenzen.",
      "long_definition": "<strong>Langzeitgedächtnis</strong> speichert Informationen über Sitzungen hinaus (z.B. Projekte, Präferenzen, Fakten). <ul><li><strong>Umsetzung:</strong> Vektorspeicher, Notiz-Datenbanken, Profile.</li><li><strong>Datenschutz:</strong> Zweckbindung, Löschkonzepte, Transparenz und Opt-Out.</li><li><strong>Qualität:</strong> Einträge versionieren, altern, validieren (Feedback-Schleifen).</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.780598 +00:00",
      "updated_at": "2025-11-01 13:12:03.780601 +00:00",
      "translation_group": "4305c67f-1570-41a4-a571-08758938d645"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 128,
    "fields": {
      "term": "RAG-Pipeline",
      "slug": "rag-pipeline",
      "short_definition": "Ablauf: Index → Retrieval → Generation.",
      "long_definition": "<strong>Retrieval-Augmented Generation (RAG)</strong> verknüpft eine Ähnlichkeitssuche mit der Generierung. <ul><li><strong>Schritte:</strong> Dokumente vektorisieren → abrufen → als Kontext einspeisen → Antwort generieren.</li><li><strong>Stärken:</strong> Quellenbezug, Aktualität, geringerer Halluzinationsdruck.</li><li><strong>Wichtig:</strong> Index-Hygiene, Chunking, Zitationsstrategie, Evaluation (Recall/Precision).</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.781091 +00:00",
      "updated_at": "2025-11-01 13:12:03.781094 +00:00",
      "translation_group": "1cdcf640-d975-4872-9500-ef1463e4984f"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 129,
    "fields": {
      "term": "Vektordatenbank",
      "slug": "vektordatenbank",
      "short_definition": "Index für Ähnlichkeitssuche in Embedding-Räumen.",
      "long_definition": "<strong>Vektordatenbanken</strong> speichern Embeddings und unterstützen schnelle Ähnlichkeitssuchen. <ul><li><strong>Indexstrukturen:</strong> HNSW, IVF-PQ, DiskANN u.a.</li><li><strong>Parameter:</strong> Dimensionszahl, Distanzmaß, Recall/Speed-Trade-offs.</li><li><strong>Praxis:</strong> Deduplizieren, Metadaten-Filter, Re-Indexierung, Observability.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.781627 +00:00",
      "updated_at": "2025-11-01 13:12:03.781630 +00:00",
      "translation_group": "2a25db24-d921-4d36-9faf-ffe3e70bdb67"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 130,
    "fields": {
      "term": "Semantische Suche",
      "slug": "semantische-suche",
      "short_definition": "Suche über Bedeutung statt Keywords.",
      "long_definition": "<strong>Semantische Suche</strong> vergleicht Bedeutungen (Embeddings) statt exakter Schlüsselwörter. <ul><li><strong>Vorteile:</strong> robuste Treffer bei Synonymen, Rechtschreibfehlern, Kontextvarianten.</li><li><strong>Grenzen:</strong> Domänenspezifische Begriffe erfordern gute Trainingsdaten/Modelle.</li><li><strong>Qualitätssicherung:</strong> Offline-Benchmarks + Online-A/B-Tests, manuelle Urteile, Erklärungen/Zitate.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.782109 +00:00",
      "updated_at": "2025-11-01 13:12:03.782112 +00:00",
      "translation_group": "22a791be-c288-4350-ae0f-9b90000549d2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 132,
    "fields": {
      "term": "Continual Learning",
      "slug": "continual-learning",
      "short_definition": "Fortlaufendes Lernen ohne Vergessen.",
      "long_definition": "<strong>Continual Learning</strong> ermöglicht Lernen über Zeit bei Erhalt früherer Fähigkeiten. <ul><li><strong>Ansätze:</strong> Regularisierung (z.B. EWC), Rehearsal/Replay, dynamische Architekturen.</li><li><strong>Herausforderungen:</strong> Catastrophic Forgetting, Datenverfügbarkeit, Verifikation über Versionen.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.783065 +00:00",
      "updated_at": "2025-11-01 13:12:03.783068 +00:00",
      "translation_group": "8512cd56-93cf-42d2-83d6-f0c96f0dedc1"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 133,
    "fields": {
      "term": "Federated Learning",
      "slug": "federated-learning",
      "short_definition": "Dezentrales Lernen über viele Geräte mit Datenschutz.",
      "long_definition": "<strong>Federated Learning</strong> trainiert lokal auf Endgeräten/Standorten und aggregiert nur Modell-Updates zentral. <ul><li><strong>Vorteile:</strong> bessere Datenhoheit, geringerer Rohdatenabfluss.</li><li><strong>Ergänzungen:</strong> Sichere Aggregation, Differential Privacy, Geräte-Heterogenität managen.</li><li><strong>Einsatz:</strong> Mobilgeräte, Gesundheitsdaten, Industrie-IoT.</li></ul>",
      "category": "10. Trends & Konzepte",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.783552 +00:00",
      "updated_at": "2025-11-01 13:12:03.783555 +00:00",
      "translation_group": "d591ab01-72f3-471c-9f04-d4e18f81b8b0"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 135,
    "fields": {
      "term": "Daten",
      "slug": "daten",
      "short_definition": "Rohinformationen, aus denen Modelle lernen.",
      "long_definition": "<strong>Daten</strong> sind Zahlen, Texte, Bilder, Audio oder Log-Ereignisse, die Sachverhalte abbilden. <ul><li><strong>Qualität:</strong> Vollständigkeit, Richtigkeit, Relevanz, Aktualität, geringe Verzerrungen.</li><li><strong>Vorbereitung:</strong> Bereinigung, Anreicherung, Labeling, Anonymisierung.</li><li><strong>Einfluss:</strong> Schlechte Daten → schlechte Modelle; gute Daten sind der größte Hebel.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.798106 +00:00",
      "updated_at": "2025-11-01 13:12:03.798111 +00:00",
      "translation_group": "b403e54e-87dd-4fc3-8577-d9c9d0ba847d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 137,
    "fields": {
      "term": "Chatbot",
      "slug": "chatbot",
      "short_definition": "Programm, das per Sprache/Text mit Menschen interagiert.",
      "long_definition": "<strong>Chatbots</strong> führen Dialoge, beantworten Fragen und erledigen Aufgaben. <ul><li><strong>Arten:</strong> regelbasiert (vordefinierte Flows) und KI-basiert (Generierung, Verständnis).</li><li><strong>Funktionen:</strong> FAQ, Support-Tickets, Buchungen, Assistenten im Arbeitsalltag.</li><li><strong>Wichtig:</strong> klare Eskalation zu Menschen, Protokolle, Datenschutz-Hinweise.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.798724 +00:00",
      "updated_at": "2025-11-01 13:12:03.798728 +00:00",
      "translation_group": "046534d0-546f-452d-a19c-4025bcb4bcf2"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 138,
    "fields": {
      "term": "Modelltraining",
      "slug": "modelltraining",
      "short_definition": "Anpassung der Gewichte eines Modells an Daten.",
      "long_definition": "<strong>Training</strong> passt Modellparameter so an, dass Vorhersagefehler sinken. <ul><li><strong>Ablauf:</strong> Daten → Vorhersage → Fehler messen → Gewichte aktualisieren.</li><li><strong>Begriffe:</strong> Lernrate, Overfitting, Validierung, Testset, Checkpoints.</li><li><strong>Praxis:</strong> gute Daten-Splits, Monitoring der Metriken, reproduzierbare Pipelines.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.799394 +00:00",
      "updated_at": "2025-11-01 13:12:03.799398 +00:00",
      "translation_group": "692709cb-b89f-4c44-b329-7bc4c84d7beb"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 139,
    "fields": {
      "term": "Prompt",
      "slug": "prompt",
      "short_definition": "Eingabeanweisung an ein Modell.",
      "long_definition": "<strong>Prompt</strong> ist die genaue Aufgabenbeschreibung für ein Modell. <ul><li><strong>Bausteine:</strong> Rolle/Ziel, Kontext/Beispiele, Format-Vorgaben, Kriterien.</li><li><strong>Tipps:</strong> konkret formulieren, Beispiele geben, Ausgabeformat festlegen, Qualitätskriterien nennen.</li><li><strong>Varianten:</strong> Zero-/Few-Shot, System- vs. Nutzer-Anweisungen, Tool-Prompts.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.799953 +00:00",
      "updated_at": "2025-11-01 13:12:03.799957 +00:00",
      "translation_group": "9b52de5d-af54-47db-8b69-7a90259b237b"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 140,
    "fields": {
      "term": "KI-Tool",
      "slug": "ki-tool",
      "short_definition": "Anwendung, die KI-Funktionen bereitstellt.",
      "long_definition": "<strong>KI-Tools</strong> sind Anwendungen oder Dienste, die z.B. Texte, Bilder, Code oder Vorhersagen generieren. <ul><li><strong>Kategorien:</strong> Assistenten, Bild-/Audio-Generatoren, Analytik, Low-Code-Integrationen.</li><li><strong>Auswahl:</strong> Kosten, Sicherheit, Datenresidenz, Bedienbarkeit, Export/Integration.</li><li><strong>Einführung:</strong> kleine Piloten, Feedback sammeln, Governance klären.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.800769 +00:00",
      "updated_at": "2025-11-01 13:12:03.800773 +00:00",
      "translation_group": "9b4bd8a7-fe72-41b0-b091-915de4f7312d"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 141,
    "fields": {
      "term": "Transparenz (Allgemein)",
      "slug": "transparenz-allgemein",
      "short_definition": "Klare Offenlegung von Funktionsweise und Grenzen.",
      "long_definition": "<strong>Transparenz</strong> macht nachvollziehbar, <em>wie</em> ein System arbeitet und <em>wo</em> seine Grenzen liegen. <ul><li><strong>Instrumente:</strong> Daten-/Modellkarten, Erklärungen, Unsicherheits-Hinweise, Nutzungsprotokolle.</li><li><strong>Nutzen:</strong> Vertrauen, bessere Fehlerbehebung, Compliance.</li><li><strong>Balance:</strong> Schutz von Geschäftsgeheimnissen vs. Informationsbedarf der Nutzer.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.801392 +00:00",
      "updated_at": "2025-11-01 13:12:03.801395 +00:00",
      "translation_group": "4d848af6-27f5-465d-bf85-6be274f0e210"
    }
  },
  {
    "model": "glossary.glossaryterm",
    "pk": 134,
    "fields": {
      "term": "Algorithmus",
      "slug": "algorithmus",
      "short_definition": "Schritt-für-Schritt-Vorschrift zur Problemlösung.",
      "long_definition": "<strong>Algorithmus</strong> ist eine eindeutige Abfolge von Anweisungen, die Eingaben in Ergebnisse überführt. <ul><li><strong>Eigenschaften:</strong> endlich, reproduzierbar, bestimmbar.</li><li><strong>Beispiele:</strong> Sortieren von Listen, Routenberechnung, Spam-Erkennung.</li><li><strong>Rolle in KI:</strong> Trainings-, Such- und Optimierungsverfahren bestehen aus vielen Algorithmen.</li></ul>",
      "category": "Einsteigerfreundliche Ergänzungen",
      "language": "de",
      "created_at": "2025-11-01 13:12:03.797288 +00:00",
      "updated_at": "2025-11-01 13:12:03.797294 +00:00",
      "translation_group": "44343d60-3e16-4683-8c68-d901be9f962f"
    }
  }
]